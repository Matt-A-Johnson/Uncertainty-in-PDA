---
title: "BARG simulation_PRL_18.10.24"
format: html
editor: visual
---

# Package installation

```{r}
#Install packages and libraries:
packages <- c("groundhog", "tidyr", "INLA", "tidyverse", "plotrix", 
              "rstatix", "gridExtra", "tidybayes", "modelsummary", 
              "rstatix", "brms", "coda", "mvtnorm", "devtools", "dagitty", "StanHeaders", 
              "rstan", "V8", "bayesplot", "correlation", "patchwork")

#Install packages if not already installed:
packages_to_install <- packages[!packages %in% installed.packages()]
if(length(packages_to_install)) install.packages(packages_to_install, dependencies = TRUE)

#If not already installed, install rethinking() separately:
#install.packages("rethinking", 
#                 repos=c(cran="https://cloud.r-project.org",
#                         rethinking="http://xcelab.net/R"))

#Remove and reinstall loo if experiencing issues with add_criterion():
remove.packages("loo")
remotes::install_github("stan-dev/loo")

#Rstan might need a bit of extra attention. If it doesn't install with the above code, remove any existing RStan via:
remove.packages("rstan")
if (file.exists(".RData")) file.remove(".RData")

#Set up compiler flags:
dotR <- file.path(Sys.getenv("HOME"), ".R")
if (!file.exists(dotR)) dir.create(dotR)
M <- file.path(dotR, "Makevars")
if (!file.exists(M)) file.create(M)
cat("\nCXX17FLAGS=-O3 -march=native -mtune=native -fPIC",
    "CXX17=g++", # or clang++ but you may need a version postfix
    file = M, sep = "\n", append = TRUE)

#This code is for the development version of rstan- I've been told that this might function better than the up-to-date version:
install.packages("StanHeaders", repos = c("https://mc-stan.org/r-packages/", getOption("repos")))
install.packages("rstan", repos = c("https://mc-stan.org/r-packages/", getOption("repos")))

#To verify your installation, you can run the RStan example/test model:
example(stan_model, package = "rstan", run.dontrun = TRUE)
```

```{r}
#Once installed, load libraries using groundhog():
library(groundhog)

#Specify packages:
packages <- c("groundhog", "tidyr", "INLA", "tidyverse", "plotrix", 
              "rstatix", "gridExtra", "tidybayes", "modelsummary", 
              "rstatix", "brms", "coda", "mvtnorm", "devtools", "dagitty", "StanHeaders", 
              "rstan", "V8", "bayesplot", "correlation", "patchwork")

#Load packages:
groundhog.library(packages, "2024-06-28", tolerate.R.version='4.4.0')
```

```{r}
#If that doesn't work, load packages manually:
library(rstan)
library(cmdstanr)
library(devtools)
library(rethinking) #Add download above
library(V8)
library(brms)
library(tidyverse) 
library(plotrix)
library(gridExtra)
library(tidybayes)
library(modelsummary)
library(bayesplot)
library(correlation)
library(patchwork)
```

# Preamble

## Why Bayesian?

Global autism prevalence is estimated at approx. 1 in 100 (Zeidan et al., 2022). Little is known about Pathological Demand Avoidance (PDA) and its prevalence. However, it seems reasonable to assume that if PDA represents a proportion of the autistic population, prevalence of PDA is likely \<1 in 100. Additionally, the percentage of PDA and/or autistic individuals willing and able to participate in research is likely smaller still. Compared to frequentist methods that require large samples to produce precise, well-powered results, Bayesian approaches rely on estimates that have a clear and valid interpretation, no matter the sample size- though it is important to note that Bayesian estimates are dependent upon the initial plausibilities assigned to them (i.e., priors), which is especially true for estimates derived from small sample sizes. In this regard, Bayesian modelling offers us a powerful tool with which to better understand individuals from underrepresented groups, providing the priors we fit to our model are well justified- this will be explained and exemplified in our prior predictive checks and sensitivity analysis.

Furthermore, the autistic population is renowned for its heterogeneity (for an overview of heterogeneity in autism, see Masi et al., 2017), which often produces noisy data that is difficult to interpret. Though data generated by PDA individuals (not third-party report) is limited, its potential relationship to autism means that PDA data may be noisy, too. Again, Bayesian analyses allow us to incorporate prior knowledge about the parameters in the form of priors. This can be particularly useful when dealing with noisy data, as prior information can help regularize the estimates and improve model stability. In addition, Bayesian methods provide a way to quantify uncertainty in parameter estimates through posterior distributions. This is especially important when dealing with noisy data, as it allows us to assess the reliability of estimates and make more informed decisions.

## Goals of analysis

We were interested in how PDA, autism, and anxierty are associated with probabilistic learning. We leveraged a probabilistic reversal learning task in which shapes were probabilistically associated with reward and loss: reward contingencies were set at 80:20 and randomised for shape stimuli across participants (e.g., either a triangle or a circle would earn points 80% of the time and lose points 20% of the time, and vice versa). Participants completed two blocks: a stable block in which reward contingencies remained constant throughout (e.g., a circle would reward points 80% and lose points 20%, and vice versa for a triangle), and a volatilie block in which reward contingencies would reverse every 20 trials (e.g.  a circle would reward points 80% and lose points 20%, and vice versa for a triangle for 20 trials, then a triangle would reward points 80% and lose points 20%, and vice versa for a circle).

We have two primary goals:

1\) To better understand probabilistic learning in the context of PDA. We wanted to know if PDA is associated with a tendency to learn similarly in both stable and volatile conditions (i.e., reduced RLLR values). We predicted that autism, anxiety, and PDA would be negatively associated with RLLR and positively associated with lose-shift behaviours.

[***\[2) To examine the relationship between PDA, autism, and anxiety. We aimed to determine whether PDA is associated with behavioural patterns similar to those observed in autism and anxiety. We predicted that, for neurotypical participants, PDA and anxiety would be associated with fewer perseverative and regressive behaviours. In contrast, we predicted that autism would be linked to elevated perseverative and regressive behaviours, regardless of PDA or anxiety.\]***]{.underline}

## Causal model

Below is a directed acyclical graphic (DAG) representation of our causal model. "SensoryProcessing" refers to sensory processing differences thought to underpin perception, cognition, and behaviour in autism (Palmer et al., 2017; Van de Cruys et al., 2014); probabilistic learning is thought to represent one facet of these sensory processing differences, and the facet we attempt to probe in this study. "Autism" here refers to a binary category- possessing a formal, clinical diagnosis of autism, or not. Finally, "PDA" refers to a spectrum of behavioural characteristics thought to be associated with PDA.

```{r}
dag_m <- dagitty( "dag {
    Autism -> PDA
    SensoryProcessing -> PDA
    SensoryProcessing -> Autism
}")
coordinates( dag_m ) <- list( x=c(Autism=0, PDA=1, SensoryProcessing=-1) , y=c(Autism=-0.5, PDA=1, SensoryProcessing=1) )
drawdag(dag_m)
```

Previous research suggests that aberrant probability learning is associated with autism (Lawson et al., 2017; Reisli et al., 2023). This compliments predictive processing theories that suggest aberrant handling of sensory information relative to prior knowledge might underpin autistic development (for review, see Cannon et al., 2021 and Chrysaitis & Series, 2023). Thus, a latent measure of probabilistic learning should causally influence an autism diagnosis. The relationship between PDA and autism is contentious- some view PDA as an autism subgroup (Christie, 2007), others posit that PDA is not different from autism (Milton, 2013; Moore, 2020), while others argue that PDA is a common mental health condition prevalent in the general population (Woods, 2018). Given that autism might underpin the development of PDA behaviours, we include a causal link between autism and PDA. The relationship between probabilistic learning (under the umbrella of sensory processing differences, labelled in the DAG above as SensoryProcessing) and PDA has yet to be empirically questioned- this relationship represents our primary interest.

# Data simulation

## Background

It has been theorised that autism is underpinned by a tendency to treat all prediction errors, including those arising from noise, as meaningful and reducible information (Van de Cruys et al., 2014). Consequently, it is thought that autistic individuals may overestimate environmental volatility, which influences how probabilistic associations are learnt (Palmer et al., 2017). By assuming that the world is more changeable than it actually is, autistic individuals theoretically attempt to disproportionately reduce environmental uncertainty at the cost of learning about probabilistic associations. (Lawson et al., 2017; Palmer et al., 2017; Van de Cruys et al., 2014). Motivated by evidence that suggests a mechanistic association between PDA and uncertainty (Johnson & Saunderson, 2023; Stuart et al., 2020 – and *Chapter 2* of this thesis), the previous chapter aimed to understand if PDA is associated with aberrant probabilistic learning. While results from *Chapter 3* support prior research demonstrating an association been autism and aberrant probabilistic learning (Lawson et al., 2017; Reisli et al., 2023), PDA individuals were seemingly sensitive to changing probabilistic associations, comparable to neurotypical controls. The present study aimed to further investigate probabilistic learning in PDA by exploring learning in stable and volatile contexts.

The paradigm used in the previous chapter comprised four conditions with defined probabilistic contingencies and three change points (i.e., shifts to new contingencies). However, in both autism and anxiety it is thought that probabilistic learning differences are most pronounced when compared between stable and volatile contexts (Browning et al., 2015; Crawley et al., 2020; Piray & Daw, 2021; Sapey-Triomphe et al., 2022). If aberrant probabilistic learning stems from a tendency to misjudge volatility – as has been hypothesised in both autism (Palmer et al., 2017) and anxiety (Piray & Daw, 2021) – any deviation from expectation is likely to be treated as indicative of a meaningful change in the underlying process. In this instance, a stable condition provides a crucial baseline – if an individual continues to treat stable conditions as volatile (e.g., rapidly adjusting their behaviour to minor deviations), it suggests that volatility may be overestimated. Again, in theory, overestimating volatility could influence how probabilistic associations are learnt – environmental uncertainty is reduced at the cost of reducing expected uncertainty. If, as is proposed in autism and anxiety, probabilistic learning in PDA is influenced by a tendency to overestimate volatility, comparing learning in both stable and volatile contexts may offer a clearer understanding of whether PDA is associated with typical probabilistic learning. Examining how individuals respond to relative environmental stability and volatility could clarify whether PDA shares learning characteristics with autism and anxiety.

In the present study, we fitted a simple Rescorla-Wagner (RW) learning model to data derived from a probabilistic reversal learning (PRL) task that included stable and volatile conditions. By fitting a RW learning model, we aimed to better understand how PDA individuals learn probabilistic associations in stable an volatile contexts - if the ability to aggregate sensory information across trials is not absent but diminished, a learning model is better suited to discern any potential group differences in how environmental probabilistic associations are learnt.

Our task and modelling approach was based on that of Browning et al. (2015). Our PRL task consisted of a stable and a volatile condition. In both conditions participants were tasked with choosing between two stimuli in order to maximise their reward; one stimuli would reward points, the other would lose points. In the stable conditions, probability of reward was set at 80:20. In the volatile conditions, this probability contingency would reverse every 20 trials. Participants' choice and RT data was recorded; a RW learning model was fitted to stable and volatile condition choice data. Both neurotypical and autistic samples were recruited.

NOTE: studies of probabilistic learning, without subsequent reversals to assess behavioural flexibility, have reported that autistic individuals can acquire response preferences as quickly as controls when 80% of correct responses are reinforced (Solomon et al., 2011), which was the reinforcement probability used for correct responses in the present study.

## Simulation

We simulate nine variables:

id - a categorical variable that represents individual participant IDs.

neurotype - a categorical variable consisting of ASC, and NT categories.

RLLR - the relative log learning rate for each participant - this was calculated as log(LR in volatile) - log(LR in stable).

loseShift - a categorial variable indicating whether or not a participant shifted their decision strategy after receiving negative feedback.

perseveration - a continuous variable that represents the number of perseverative behaviours a participant makes. Here, we define perseverative behaviours as the number of continued responses to the old rule after each reversal before making a correct choice.

regression - a continuous variable that represents the number of perseverative behaviours a participant makes. Here, we define regressive behaviours as the number of responses to the old rule after each reversal after making a correct choice.

EDAQ - represents a total score on the EDA-QA, a descriptive measure of PDA.

MASQ - represents a total score on the MASQ, a descriptive measure of anxious symptoms.

blockorder - a categorical variable with two levels (S/V and V/S) representing what order participants completed task conditions, stable then volatile, or volatile then stable.

Create function to simulate data:

```{r}
#Specify a function to generate simulated data as per the specifications above:
simulate_data <- function(n_participants = 200) {
  set.seed(123) #Set seeds for reproducibility
  
  #Generate a tibble with participant IDs and neurotype variable:
  data <- tibble(
    id = 1:n_participants,
    neurotype = factor(sample(c("ASC", "NT"), n_participants, replace = TRUE)), #ASC signifies an autism diagnosis; NT stands for neurotypical.
    blockorder = factor(sample(c("S/V","V/S"), n_participants, replace = TRUE)) #Randomly assign a block order to each participant - this should have no impact on any of the other variables.
  ) 
  
  #Generate variables as functions of EDAQ and MASQ scores:
  data <- data %>%
    mutate(
      MASQ = rnorm(n_participants, mean = ifelse(neurotype == "ASC", 0.2, 0), sd = 0.5), #Here, we assume that anxiety is higher in the autistic population, this MASQ scores are higher for ASC.
      EDAQ = 1.5 * MASQ + rnorm(n_participants), #Here, we make the assumption that PDA is underpinned by anxiety, thus EDA-QA scores are derived from MASQ scores.
      RLLR = ifelse(neurotype == "NT", #RLLR is smaller for ASC and as a function of MASQ and EDA-QA scores; ASC are less affected by the influence of MASQ and EDA-QA scores.
                    rnorm(n_participants, mean = 0.1 - 0.5 * MASQ - 0.5 * EDAQ, sd = 0.5),  
                    rnorm(n_participants, mean = -1.5 - 0.1 * MASQ - 0.1 * EDAQ, sd = 0.5)),
      perseveration = rnorm(n_participants, #Perseveration is greater for ASC and smaller as a function of MASQ and EDA-QA scores; ASC are less affected by the influence of MASQ and EDA-QA scores.
                        mean = ifelse(neurotype == "NT", -1, 1) - 
                        (ifelse(neurotype == "ASC", 0.1, 0.9) * (MASQ - mean(MASQ))) - 
                        (ifelse(neurotype == "ASC", 0.1, 0.9) * (EDAQ - mean(EDAQ))), 
                        sd = 0.5),
      regression = rnorm(n_participants, #Regression, much like perseveration, is greater for ASC and smaller as a function of MASQ and EDA-QA scores; ASC are less affected by the influence of MASQ and EDA-QA scores.
                        mean = ifelse(neurotype == "NT", -1, 1) - 
                        (ifelse(neurotype == "ASC", 0.1, 0.9) * (MASQ - mean(MASQ))) - 
                        (ifelse(neurotype == "ASC", 0.1, 0.9) * (EDAQ - mean(EDAQ))), 
                        sd = 0.5),
      loseShift = rnorm(n_participants, #Lose-shift is greater for ASC and as a function of MASQ and EDA-QA scores; ASC are less affected by the influence of MASQ and EDA-QA scores.
                        mean = ifelse(neurotype == "NT", -1, 1) + 
                        (ifelse(neurotype == "ASC", 0.1, 0.9) * (MASQ - mean(MASQ))) + 
                        (ifelse(neurotype == "ASC", 0.1, 0.9) * (EDAQ - mean(EDAQ))),
                        sd = 0.5)
      #anxiety = factor(ifelse(MASQ > median(MASQ), "high", "low")) #THIS IS USED FOR SPECIFYING RELATIONSHIP VALUES ONLY; NOT USED IN MODEL.
    
      )
  
  return(data)
}

#Generate and inspect the data frame:
simulated_data <- simulate_data()
print(head(simulated_data))
```

Inspect structure and write the simulated data to a .csv file:

```{r}
#Check simulated data structure:
str(simulated_data)

#Write data to csv for modelling (change name of file as appropriate):
write.table(simulated_data, file="Sim_Data.csv",sep=",",row.names=F)
```

## Visualisation

### Behaviour plotted by neurotype, PDA and anxiety

#### Lose-shift behaviour

Visualise the expected relationship between lose-shift behaviours and MASQ and EDA-QA scores:

```{r}
#Read in saved data file:
sim_data <- read.csv("Sim_Data.csv")

#Plotting lose-shift as a funciton or EDA-QA and MASQ scores:

#Plot total scores (without neurotype):
ggplot(data = sim_data, aes(x = EDAQ, y = loseShift, color = "#336666")) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE, aes(y = loseShift), fill = "#336666") +
  labs(x = "EDA-QA scores", y = "Number of Lose-Shift") +
  ggtitle("Simulated data demonstrating the predicted relationship between 
Lose-Shift and EDA-QA scores") +
  theme_minimal() +
  scale_color_identity()

ggplot(data = sim_data, aes(x = MASQ, y = loseShift, color = "#336666")) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE, aes(y = loseShift), fill = "#336666") +
  labs(x = "MASQ scores", y = "Number of Lose-Shift") +
  ggtitle("Simulated data demonstrating the predicted relationship between 
Lose-Shift and MASQ scores") +
  theme_minimal() +
  scale_color_identity()

#Plot by neurotype:
ggplot(data = sim_data, aes(x = EDAQ, y = loseShift, color = neurotype)) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE, aes(y = loseShift, fill = neurotype),  show.legend = FALSE) +
  labs(x = "EDA-QA scores", y = "Number of Lose-Shift", color = "Neurotype") +
  ggtitle("Simulated data demonstrating the predicted relationship between 
Lose-Shift and EDA-QA scores") +
  scale_color_manual(values = c("NT" = "#66cccc", "ASC" = "#cc99ff"), breaks = c("NT", "ASC")) +
  scale_fill_manual(values = c("NT" = "#66cccc", "ASC" = "#cc99ff"), breaks = c("NT", "ASC")) +
  theme_minimal() +
  theme(
    axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14),
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 12),
    plot.title = element_text(size = 16)
  )
ggsave( 'LS_M_plot.png', plot = last_plot(), dpi = 300)


ggplot(data = sim_data, aes(x = MASQ, y = loseShift, color = neurotype)) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE, aes(y = loseShift, fill = neurotype), show.legend = FALSE) +
  labs(x = "MASQ scores", y = "Number of Lose-Shift", color = "Neurotype") +
  ggtitle("Simulated data demonstrating the predicted relationship between 
Lose-Shift and MASQ scores") +
  scale_color_manual(values = c("NT" = "#66cccc", "ASC" = "#cc99ff"), breaks = c("NT", "ASC"))+
  scale_fill_manual(values = c("NT" = "#66cccc", "ASC" = "#cc99ff"), breaks = c("NT", "ASC"))+
  theme_minimal() +
  theme(
    axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14),
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 12),
    plot.title = element_text(size = 16)
  )
ggsave( 'LS_E_plot.png', plot = last_plot(), dpi = 300)
```

The plots above depict 1) that we expect the number of lose-shift behaviours (i.e., a response switch made after receiving negative feedback, reported as a proportion of total negative feedback trials) to be greater for the ASC group compared to the NT group - this is based on Crawley et al. (2020) and D'Crus et al. (2013). Similarly, 2) we expect that the number of lose-shift behaviours will be positively associated with anxiety - this is based on Piray and Daw (2021) theoretical model, as well as findings from Huang et al. (2017) and [Hein et al. (2023)](http://nature.com/articles/s42003-023-04628-1.pdf). 3) We predict that the number of lose-shift behaviours produced by the ASC group will be similar irrespective of anxiety - this reflects previous findings that suggest autism is associated with lose-shift behaviours (Crawley et al., 2020; D'Crus et al., 2013). For the NT group, we predict that lose-shift behaviours will be positively associated with anxiety - this is supported by literature that suggests anxiety is associated with more lose-shift behaviours (Huang et al., 2017; [Hein et al. (2023](http://nature.com/articles/s42003-023-04628-1.pdf))*.* We predict a similar pattern of lose-shift behaviours as a function of PDA behaviours, such that the number of lose-shift behaviours produced by the ASC group will be similar irrespective of PDA behaviours, while for the NT gorup, lose-shift behaviours will be positively associated with PDA behaviours - we assume that PDA is underpinned by anxiety and thus, findings that suggest anxiety is associated with more lose-shift behaviours may be true for PDA also.

#### Perseverative behaviour

Visualise the expected relationship between perseveration and MASQ and EDA-QA scores:

```{r}
#Read in saved data file:
sim_data <- read.csv("Sim_Data.csv")

#Plotting perseveration as a funciton or EDA-QA and MASQ scores:

#Plot total scores (without neurotype):
ggplot(data = sim_data, aes(x = EDAQ, y = perseveration, color = "#336666")) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE, aes(y = perseveration), fill = "#336666") +
  labs(x = "EDA-QA scores", y = "Number of Perseveration") +
  ggtitle("Simulated data demonstrating the predicted relationship between 
perseveration and EDA-QA scores") +
  theme_minimal() +
  scale_color_identity()

ggplot(data = sim_data, aes(x = MASQ, y = perseveration, color = "#336666")) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE, aes(y = perseveration), fill = "#336666") +
  labs(x = "MASQ scores", y = "Number of Perseveration") +
  ggtitle("Simulated data demonstrating the predicted relationship between 
perseveration and MASQ scores") +
  theme_minimal() +
  scale_color_identity()

#Plot by neurotype:
ggplot(data = sim_data, aes(x = EDAQ, y = perseveration, color = neurotype)) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE, aes(y = perseveration, fill = neurotype),  show.legend = FALSE) +
  labs(x = "EDA-QA scores", y = "Number of Perseveration", color = "Neurotype") +
  ggtitle("Simulated data demonstrating the predicted relationship between 
perseveration and EDA-QA scores") +
  scale_color_manual(values = c("NT" = "#66cccc", "ASC" = "#cc99ff"), breaks = c("NT", "ASC")) +
  scale_fill_manual(values = c("NT" = "#66cccc", "ASC" = "#cc99ff"), breaks = c("NT", "ASC")) +
  theme_minimal() +
  theme(
    axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14),
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 12),
    plot.title = element_text(size = 16)
  )
ggsave( 'P_M_plot.png', plot = last_plot(), dpi = 300)

ggplot(data = sim_data, aes(x = MASQ, y = perseveration, color = neurotype)) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE, aes(y = perseveration, fill = neurotype), show.legend = FALSE) +
  labs(x = "MASQ scores", y = "Number of Perseveration", color = "Neurotype") +
  ggtitle("Simulated data demonstrating the predicted relationship between 
perseveration and MASQ scores") +
  scale_color_manual(values = c("NT" = "#66cccc", "ASC" = "#cc99ff"), breaks = c("NT", "ASC")) +
  scale_fill_manual(values = c("NT" = "#66cccc", "ASC" = "#cc99ff"), breaks = c("NT", "ASC")) +
  theme_minimal() +
  theme(
    axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14),
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 12),
    plot.title = element_text(size = 16)
  )
ggsave( 'P_E_plot.png', plot = last_plot(), dpi = 300)
```

The plots above depict 1) that we expect the number of perseverative behaviours (i.e., the number of errors made after the first reversal before a correct response) to be greater for the ASC group compared to the NT gorup - this is based on Crawley et al. (2020) and Coldren & Halloran (2010). Similarly, 2) we expect that anxiety will be negatively associated with perseverative behaviours - this is based on Fang et al. (2024) and Zhukovsky et al. (2017) who both found perseveration to be negatively correlated with anxiety, with the former noting that the severity of anxiety symptoms was negatively associated wiht a tendency for perseverative strategies. Because PDA is thought to be underpinned by anxiety (Johnson & Saunderson, 2023; Stuart et al., 2020), we assume PDA behaviours will also be negatively associated with perseverative behaviours. It is important to note that there is a dearth of literature that reports perseverative tendencies (positive or negative) in anxious cohorts. Importantly, If ASC is associated with more perseverative behaviours, and anxiety is associated with fewer perseverative behaviours, this might provide a means to better understand PDA and it's categorical placement; if PDA behaviours are associated with fewer perseverative behaviours in the NT group compared to ASC individuals, it might indicate that PDA represents an anxiety condition that is not exclusively associated with autism.

#### Regressive behaviour

Visualise the expected relationship between regression and MASQ and EDA-QA scores:

```{r}
#Read in saved data file:
sim_data <- read.csv("Sim_Data.csv")

#Plotting regression as a funciton or EDA-QA and MASQ scores:

#Plot total scores (without neurotype):
ggplot(data = sim_data, aes(x = EDAQ, y = regression, color = "#336666")) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE, aes(y = regression), fill = "#336666") +
  labs(x = "EDA-QA scores", y = "Number of Regressions") +
  ggtitle("Simulated data demonstrating the predicted relationship between 
regression and EDA-QA scores") +
  theme_minimal() +
  scale_color_identity() 

ggplot(data = sim_data, aes(x = MASQ, y = regression, color = "#336666")) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE, aes(y = regression), fill = "#336666") +
  labs(x = "MASQ scores", y = "Number of Regressions") +
  ggtitle("Simulated data demonstrating the predicted relationship between 
regression and MASQ scores") +
  theme_minimal() +
  scale_color_identity()

#Plot by neurotype:
ggplot(data = sim_data, aes(x = EDAQ, y = regression, color = neurotype)) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE, aes(y = regression, fill = neurotype),  show.legend = FALSE) +
  labs(x = "EDA-QA scores", y = "Number of Regressions", color = "Neurotype") +
  ggtitle("Simulated data demonstrating the predicted relationship between 
regression and EDA-QA scores") +
  scale_color_manual(values = c("NT" = "#66cccc", "ASC" = "#cc99ff"), breaks = c("NT", "ASC")) +
  scale_fill_manual(values = c("NT" = "#66cccc", "ASC" = "#cc99ff"), breaks = c("NT", "ASC")) +
  theme_minimal() +
  theme(
    axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14),
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 12),
    plot.title = element_text(size = 16)
  )
ggsave( 'R_M_plot.png', plot = last_plot(), dpi = 300)

ggplot(data = sim_data, aes(x = MASQ, y = regression, color = neurotype)) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE, aes(y = regression, fill = neurotype), show.legend = FALSE) +
  labs(x = "MASQ scores", y = "Number of Regressions", color = "Neurotype") +
  ggtitle("Simulated data demonstrating the predicted relationship between 
regression and MASQ scores") +
  scale_color_manual(values = c("NT" = "#66cccc", "ASC" = "#cc99ff"), breaks = c("NT", "ASC")) +
  scale_fill_manual(values = c("NT" = "#66cccc", "ASC" = "#cc99ff"), breaks = c("NT", "ASC")) +
  theme_minimal() +
  theme(
    axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14),
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 12),
    plot.title = element_text(size = 16)
  )
ggsave( 'R_E_plot.png', plot = last_plot(), dpi = 300)
```

Much like perseverative behaviours, 1) we expect the number of regressive behaviours (i.e., the number of errors made after the first reversal after at least one correct response) to be greater for the ASC group compared to the NT group - this is based on Crawley et al. (2020), Coldren & Halloran (2010) and Goris et al., (2021; who found no difference in learning rates between autistic traits and stable/volatile conditions, but did find a primacy bias - a tendency for higher autistic traits to be associated with a return to previously rewarded stimuli after reversal). Similarly, 2) we expect that anxiety will be negatively associated with regressive behaviours - this is based on Fang et al. (2024) and Zhukovsky et al. (2017). Because PDA is thought to be underpinned by anxiety (Johnson & Saunderson, 2023; Stuart et al., 2020), we assume PDA behaviours will also be negatively associated with regressive behaviours. Again, much like perseverative behaviours, it is important to note that there is a dearth of literature that reports regressive tendencies (positive or negative) in anxious cohorts. Importantly, If ASC is associated with more regressive behaviours, and anxiety is associated with fewer regressive behaviours, this might provide a means to better understand PDA and it's categorical placement; if PDA behaviours are associated with fewer regressive behaviours in the NT group compared to ASC individuals, it might indicate that PDA represents an anxiety condition that is not exclusively associated with autism.

### Learning rate predicted by neurotype, PDA and anxiety

Visualise the expected relationship between relative log learning rates (RLLR) and MASQ and EDA-QA scores:

```{r}
#Read in saved data file:
sim_data <- read.csv("Sim_Data.csv")

#Plot total scores (without neurotype):
ggplot(data = sim_data, aes(x = EDAQ, y = RLLR, color = "#336666")) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE, aes(y = RLLR), fill = "#336666") +
  labs(x = "EDA-QA scores", y = "Relative Log Learning Rate") +
  ggtitle("Simulated data demonstrating the predicted relationship between RLLR and 
EDA-QA scores") +
  theme_minimal() +
  scale_color_identity()

ggplot(data = sim_data, aes(x = MASQ, y = RLLR, color = "#336666")) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE, aes(y = RLLR), fill = "#336666") +
  labs(x = "MASQ scores", y = "Relative Log Learning Rate") +
  ggtitle("Simulated data demonstrating the predicted relationship between RLLR and 
MASQ scores") +
  theme_minimal() +
  scale_color_identity()

#Plot by neurotype:
ggplot(data = sim_data, aes(x = EDAQ, y = RLLR, color = neurotype)) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE, aes(y = RLLR, fill = neurotype),  show.legend = FALSE) +
  labs(x = "EDA-QA scores", y = "Relative Log Learning Rate", color = "Neurotype") +
  ggtitle("Simulated data demonstrating the predicted relationship between 
RLLR and EDA-QA scores by Neurotype") +
  scale_color_manual(values = c("NT" = "#66cccc", "ASC" = "#cc99ff"), breaks = c("NT", "ASC")) +
  scale_fill_manual(values = c("NT" = "#66cccc", "ASC" = "#cc99ff"), breaks = c("NT", "ASC")) +
  theme_minimal() +
  theme(
    axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14),
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 12),
    plot.title = element_text(size = 16)
  )
ggsave( 'RLLR_M_plot.png', plot = last_plot(), dpi = 300)

ggplot(data = sim_data, aes(x = MASQ, y = RLLR, color = neurotype)) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE, aes(y = RLLR, fill = neurotype), show.legend = FALSE) +
  labs(x = "MASQ scores", y = "Relative Log Learning Rate", color = "Neurotype") +
  ggtitle("Simulated data demonstrating the predicted relationship between
RLLR and MASQ scores by Neurotype") +
  scale_color_manual(values = c("NT" = "#66cccc", "ASC" = "#cc99ff"), breaks = c("NT", "ASC")) +
  scale_fill_manual(values = c("NT" = "#66cccc", "ASC" = "#cc99ff"), breaks = c("NT", "ASC")) +
  theme_minimal() +
  theme(
    axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14),
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 12),
    plot.title = element_text(size = 16)
  )
ggsave( 'RLLR_E_plot.png', plot = last_plot(), dpi = 300)
```

Based on Browning et al. (2015) - and the assumption that PDA is underpinned by anxiety (Johnson & Saunderson 2023; Stuart et al., 2020) - the plots above demonstrate our prediction that both EDA-QA and MASQ scores will negatively correlate with relative log learning rates (i.e., log(LR in volatile block) - log(LR in stable block)). This assumes that PDA and anxiety are associated with reduced change in learning rates (i.e., learning rates for stable and volatile conditions are similar), indicating reduced flexibility. Because autism is associated with overall higher learning rates (Crawley et al., 2020; D’Cruz et al., 2013), simulated RLLR do not vary as a function of EDA-QA or MASQ scores for ASC individuals. Rather, RLLR for ASC individuals are consistently low, reflecting less variability in learning rates for stable and volatile conditions. Plots 3 and 4 above show the same relationships plotted by nerutoyep; ASC, anxiety, and PDA behaviours are all associated with lower RLLRs.

We can also plot these relationships by blockorder - as noted by Browning et al. (2015), if there is an effect of block (i.e., learning rates are higher in the volatile compared to the stable condition) there should not be an effect of blockorder, so the plots should be similar for both S/V and V/S:

```{r}
#Read in saved data file:
sim_data <- read.csv("Sim_Data.csv")

#Plot total scores (without neurotype):
ggplot(data = sim_data, aes(x = EDAQ, y = RLLR, color = "#336666")) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE, aes(y = RLLR), fill = "#336666") +
  labs(x = "EDA-QA scores", y = "Relative Log Learning Rate") +
  ggtitle("Simulated data demonstrating the predicted relationship between 
RLLR and EDA-QA scores") +
  theme_minimal() +
  scale_color_identity() +
  facet_grid(. ~ blockorder)
  

ggplot(data = sim_data, aes(x = MASQ, y = RLLR, color = "#336666")) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE, aes(y = RLLR), fill = "#336666") +
  labs(x = "MASQ scores", y = "Relative Log Learning Rate") +
  ggtitle("Simulated data demonstrating the predicted relationship between 
RLLR and MASQ scores") +
  theme_minimal() +
  scale_color_identity() +
  facet_grid(. ~ blockorder)

#Plot by neurotype:
ggplot(data = sim_data, aes(x = EDAQ, y = RLLR, color = neurotype)) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE, aes(y = RLLR, fill = neurotype),  show.legend = FALSE) +
  labs(x = "EDA-QA scores", y = "Relative Log Learning Rate", color = "Neurotype") +
  ggtitle("Simulated data demonstrating the predicted relationship between 
RLLR and EDA-QA scores by Neurotype") +
  scale_color_manual(values = c("NT" = "#66cccc", "ASC" = "#cc99ff"), breaks = c("NT", "ASC")) +
  scale_fill_manual(values = c("NT" = "#66cccc", "ASC" = "#cc99ff"), breaks = c("NT", "ASC")) +
  theme_minimal() +
  theme(
    axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14),
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 12),
    plot.title = element_text(size = 16)
  ) +
  facet_grid(. ~ blockorder)

ggplot(data = sim_data, aes(x = MASQ, y = RLLR, color = neurotype)) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE, aes(y = RLLR, fill = neurotype), show.legend = FALSE) +
  labs(x = "MASQ scores", y = "Relative Log Learning Rate", color = "Neurotype") +
  ggtitle("Simulated data demonstrating the predicted relationship between 
RLLR and MASQ scores by Neurotype") +
  scale_color_manual(values = c("NT" = "#66cccc", "ASC" = "#cc99ff"), breaks = c("NT", "ASC")) +
  scale_fill_manual(values = c("NT" = "#66cccc", "ASC" = "#cc99ff"), breaks = c("NT", "ASC")) +
  theme_minimal() +
  theme(
    axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14),
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 12),
    plot.title = element_text(size = 16)
  ) +
  facet_grid(. ~ blockorder)
```

Indeed, the plots above show that the predicted relationship between EDA-QA and MASQ scores and RLLR is similar, irrespective of blockorder. In other words, regardless of which block participants complete first, the relationship between RLLRs, autism, PDA, and anxiety remain the same.

# Model checking

For those unfamiliar with brms() (specifically with brms() syntax), chapter 12 of the following webpage provides some useful guidance on how to specify a brms() model: [Chapter 12 Bayesian estimation with brms \| An R companion to Statistics: data analysis and modelling (mspeekenbrink.github.io)](https://mspeekenbrink.github.io/sdam-r-companion/bayesian-estimation-with-brms.html)

## Correlating EDA-QA and MASQ scores

Begin by checking that EDA-QA and MASQ scores are correlated - this will be important for interpreting the results of the regression models below:

```{r}
#Read in saved data file:
sim_data <- read.csv("Sim_Data.csv")

#Prepare and standardise variables:
data <- sim_data %>%
  mutate(
    EDAQ = standardize(EDAQ),
    MASQ = standardize(MASQ),
    RLLR = standardize(RLLR),
    perseveration = standardize(perseveration),
    regression = standardize(regression),
    loseShift = standardize(loseShift)
  ) %>%
  select(id, EDAQ, MASQ, RLLR, loseShift, perseveration, regression, neurotype) %>%
  distinct()

#Calculate Bayesian correlation between EDAQ and MASQ:
sim_EDAQ_MASQ_cor <- brm(
  EDAQ ~ 0 + MASQ,
  data = data,
  backend = "cmdstan",
  family = gaussian(),
  prior = c(
    prior(normal(0, 1), class = "b"),
    prior(exponential(1), class = "sigma")
  ),
  control = list(adapt_delta = 0.99),
  cores = 4,
  file = "sim_EDAQ_MASQ_cor.rds"
  )
```

Load in and inspect model output:

```{r}
#Load the model output from a file:
sim_EDAQ_MASQ_cor <- readRDS("sim_EDAQ_MASQ_cor.rds")

#Return model output:
summary(sim_EDAQ_MASQ_cor)

#Extract the posterior samples for the correlation:
sim_EDAQ_MASQ_cor_posterior <- posterior_samples(sim_EDAQ_MASQ_cor)

#Visualize the posterior distribution:
plot_title <- ggtitle("Posterior distributions",
                      "with means and 89% compatibility intervals")
color_scheme_set("mix-teal-pink")
mcmc_areas(sim_EDAQ_MASQ_cor_posterior, pars = "b_MASQ", "sigma", point_est = "mean",
           border_size = 0.1,
           prob = 0.89) + plot_title + xlab("Parameter estimates") + ylab("Parameters")
```

Informed by Johnson and Saunderson (2023) who report a correlation of *r*=0.57 between the EDA-QA and the MASQ-D30 (a short form version of the MASQ), we simulate a similar correlation between MASQ and EDA-QA scores. EDA-QA and MASQ scores are highly correlated with fairly tight intervals (a range of approx. 0.1) - we can be fairly certain about this relationship.

We can also plot this correlation:

```{r}
#Load the model output from a file:
sim_EDAQ_MASQ_cor <- readRDS("sim_EDAQ_MASQ_cor.rds")

#First, extract predicted values:
sim_EDAQ_MASQ_cor_preds <- data.frame(fitted(sim_EDAQ_MASQ_cor))

#Add EDA-QA and MASQ scores to the predicted values:
sim_EDAQ_MASQ_cor_preds <- sim_EDAQ_MASQ_cor_preds %>%
  mutate( 
    EDAQ = data$EDAQ,
    MASQ = data$MASQ
)

#Plot correlation between EDA-QA and MASQ scores with a line representing predicted values and HDI:
ggplot(data = sim_EDAQ_MASQ_cor_preds, aes(x = MASQ, y = EDAQ, color = "#66cccc")) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE, aes(y = Estimate)) +
  geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5), alpha = 0.3, fill = "#66cccc", color = NA) +
  labs(x = "EDA-QA scores (std)", y = "MASQ scores (std)") +
  ggtitle("Estimated correlation between simulated EDA-QA and MASQ scores") +
  theme_minimal() +
  scale_color_identity()
```

MASQ and EDA-QA scores are highly correlated. Ultimately, we want to know how the relationship between probabilistic learning in the context of PDA compares to that of probabilistic learning in the context of anxiety. Establishing a correlation between PDA (EDA-QA) and anxiety (MASQ) helps us to interpret any comparisons drawn between how probabilistic learning relates to each construct. For example, if probabilistic learning relates to PDA and anxiety in similar ways, it is possible that model purposed to explain aberrant probabilistic learning in anxiety (e.g., Piray & Daw, 2021) might apply to PDA also. Indeed, it might be that PDA is best understood as an anxiety condition (e.g., Johnson & Saunderson 2023; Stuart et al., 2020), though obviously further exploration would be required to draw such a conclusion. Conversely, if the relationship between probabilistic learning and PDA and anxiety are disparate, this too would be informative. I might be that PDA, though related to anxiety, is better conceptualised as an autism spectrum condition. In this case, we might expect differences in the way probabilistic learning relates to PDA and anxiety, namely, PDA might be associate with more perseverative behaviours - a behavioural departure from Piray and Daw's (2021) explanatory model of probabilistic learning in anxiety. Scenarios like these allow us to identify areas of difficulty, which may help us better understand the underlying facets driving PDA behaviours.

## Behaviour predicted by neurotype, PDA and anxiety

### Lose-shift behaviour

To better understand the relationship between PDA and probabilistic learning, we will run a set of Bayesian regression models, 1) will model lose-shift behaviours predicted by neurotype x MASQ scores, 2) will model lose-shift behaviours predicted by neurotype x MASQ and neurotype x EDA-QA scores. We will perform model selection analysis (LOOCV) to discern which model better accounts for our data. This will help us infer if the EDA-QA is explaining any additional variance in lose-shift behaviours over and above MASQ scores:

$$ loseShift_i \sim Normal( \mu_1, \sigma_1 )  \\ \mu_{ij} = \alpha + \beta_1 \text{MASQ}_i + \beta_2 \text{neurotype}_j + \beta_3 (\text{MASQ}_i \times \text{neurotype}_j)\\ \alpha \sim {Normal}(0, 1) \quad \\ \beta_1, \beta_2, \beta_3  \sim {Normal}(0, 1) \quad  \\ \sigma \sim \text{Exponential}(1) $$ And for comparison:

$$
loseShift_i \sim \text{Normal}( \mu_i, \sigma ) \\
\mu_{ij} = \alpha + \beta_1 \text{MASQ}_i + \beta_2 \text{neurotype}_j + \beta_3 (\text{MASQ}_i \times \text{neurotype}_j) + \beta_4 \text{EDAQ}_i + \beta_5 (\text{EDAQ}_i \times \text{neurotype}_j) \\
\alpha \sim {Normal}(0, 1) \quad \\
\beta_1, \beta_2, \beta_3, \beta_4, \beta_5  \sim {Normal}(0, 1) \quad  \\
\sigma \sim \text{Exponential}(1)
$$

Soon we will perform prior predictive checks and sensitivity analysis to justify our choice of priors, but for now, we will use uninformative flat priors to check the simulation is working- because we simulate standardised variables we will assume $Normal(0,1)$.

Now fit the models to the simulated data- again, in lieu of justified priors, we will assume $Normal(0,1)$:

```{r}
#Read in saved data file:
sim_data <- read.csv("Sim_Data.csv")

#Prepare and standardise variables:
data <- sim_data %>%
  mutate(
    EDAQ = standardize(EDAQ),
    MASQ = standardize(MASQ),
    RLLR = standardize(RLLR),
    perseveration = standardize(perseveration),
    regression = standardize(regression),
    loseShift = standardize(loseShift)
  ) %>%
  select(id, EDAQ, MASQ, RLLR, loseShift, perseveration, regression, neurotype) %>%
  distinct()

#Fit the model where lose-shift behaviours are predicted by MASQ scores by neurotype:
sim_modLSM <- brm(
  loseShift ~ MASQ*neurotype,
  data = data,
  backend = "cmdstan",
  family = gaussian(),
  prior = c(
    prior(normal(0, 1), class = "Intercept"),
    prior(normal(0, 1), class = "b"),
    prior(exponential(1), class = "sigma")
  ),
  control = list(adapt_delta = 0.99),
  cores = 4,
  save_pars = save_pars(all = TRUE),
  sig_figs = 10,
  file = "sim_modLSM_output.rds"
  )

#Fit the model where lose-shift behaviours are predicted by a MASQ*neurotype and EDA-QA*neurotype:
sim_modLSME <- brm(
  loseShift ~ MASQ*neurotype + EDAQ*neurotype,
  data = data,
  backend = "cmdstan",
  family = gaussian(),
  prior = c(
    prior(normal(0, 1), class = "Intercept"),
    prior(normal(0, 1), class = "b"),
    prior(exponential(1), class = "sigma")
  ),
  control = list(adapt_delta = 0.99),
  cores = 4,
  file = "sim_modLSME_output.rds"
  )
```

Add LOO criterion for model comparison:

```{r}
#Add model LOO criterion (set reloo = TRUE if problematic observations are returned; IMPORTANT - make sure sig_figs = at least 10, otherwise add_criterion returns error: https://discourse.mc-stan.org/t/simplex-variable-error-during-bridgesampling/30811):  
sim_modLSM <- add_criterion(sim_modLSM, "loo", moment_match = TRUE, reloo = TRUE, recompile = TRUE)  
sim_modLSME <- add_criterion(sim_modLSME, "loo", moment_match = TRUE, reloo = TRUE, recompile = TRUE)
```

Inspect output:

```{r}
#Load the model output from a file:
sim_modLSM <- readRDS("sim_modLSM_output.rds")
sim_modLSME <- readRDS("sim_modLSME_output.rds")

#Return model output:
summary(sim_modLSM)
summary(sim_modLSME)

#We can also manually check the range of Pareto-k values; anything near or above 0.7 is likely problematic:
#range(loo(sim_modRM)$diagnostics$pareto_k)
#range(loo(sim_modRME)$diagnostics$pareto_k)

#Also, run model comparison:
loo_compare(sim_modLSM, sim_modLSME, criterion = "loo")
```

Interpreting the LOO output above - this will vary slightly each time the analysis is run:

-   **`elpd_diff`**: This is the difference in the expected log predictive density (elpd) between the two models. The higher the elpd, the better the model is at predicting new data. Here, `sim_modLSME` has an elpd difference of 0.0, which means it's used as the reference model. `sim_modLSM` has an elpd difference of -94.8, meaning it is 94.8 units worse in terms of predictive performance compared to `sim_modLSME`.

-   **`se_diff`**: This is the standard error of the elpd difference. It quantifies the uncertainty in the elpd difference. A standard error of 14.0 for `sim_modLSM` suggests that the estimate of the elpd difference has some variability, but the large difference (-94.8) still indicates that `sim_modLSME` is likely much better at predicting new data than `sim_modLSM`.

Plot parameter distributions with credible intervals:

```{r}
#Extract posterior samples:
sim_modLSM_posterior <- posterior_samples(sim_modLSM)
sim_modLSME_posterior <- posterior_samples(sim_modLSME)


#Filter out 'lprior' and 'lp__':
sim_modLSM_posterior <- sim_modLSM_posterior[, c("b_Intercept", "b_MASQ", "b_neurotypeNT", "b_MASQ:neurotypeNT", "sigma")]
sim_modLSME_posterior <- sim_modLSME_posterior[, c("b_Intercept", "b_MASQ", "b_neurotypeNT","b_EDAQ", "b_MASQ:neurotypeNT", "b_neurotypeNT:EDAQ", "sigma")]

#Convert the data frame to long format:
sim_modLSM_posterior_long <- pivot_longer(sim_modLSM_posterior, 
                                        cols = everything(), 
                                        names_to = "Parameter", 
                                        values_to = "Estimate")
sim_modLSME_posterior_long <- pivot_longer(sim_modLSME_posterior, 
                                        cols = everything(), 
                                        names_to = "Parameter", 
                                        values_to = "Estimate")

#Rename parameters to 'Intercept', 'MASQ', 'EDAQ', and 'sigma':
sim_modLSM_posterior_long$Parameter <- recode(sim_modLSM_posterior_long$Parameter,
                                            "b_Intercept" = "Intercept",
                                            "b_MASQ" = "MASQ", 
                                            "b_neurotypeNT" = "neurotypeNT",
                                            "b_EDAQ" = "EDAQ", 
                                            "b_MASQ:neurotypeNT" = "MASQ:neurotypeNT", 
                                            "b_neurotypeNT.EDAQ" = "neurotypeNT:EDAQ", 
                                            "sigma" = "Sigma")
sim_modLSME_posterior_long$Parameter <- recode(sim_modLSME_posterior_long$Parameter,
                                            "b_Intercept" = "Intercept",
                                            "b_MASQ" = "MASQ", 
                                            "b_neurotypeNT" = "neurotypeNT",
                                            "b_EDAQ" = "EDAQ", 
                                            "b_MASQ:neurotypeNT" = "MASQ:neurotypeNT", 
                                            "b_neurotypeNT:EDAQ" = "neurotypeNT:EDAQ", 
                                            "sigma" = "Sigma")

#Extract group information from parameter names:
sim_modLSM_posterior_long$Group <- sub(":.*", "", sim_modLSM_posterior_long$Parameter)
sim_modLSME_posterior_long$Group <- sub(":.*", "", sim_modLSME_posterior_long$Parameter)

#Reorder the parameters and flip the order:
sim_modLSM_posterior_long$Parameter <- factor(sim_modLSM_posterior_long$Parameter, 
                                            levels = rev(c("Intercept","MASQ","neurotypeNT","MASQ:neurotypeNT","Sigma")))
sim_modLSME_posterior_long$Parameter <- factor(sim_modLSME_posterior_long$Parameter, 
                                            levels = rev(c("Intercept","MASQ","neurotypeNT","EDAQ","MASQ:neurotypeNT","neurotypeNT:EDAQ","Sigma")))

#Plot marginal posterior distributions with specified colors:
plot_title <- ggtitle("Posterior distributions",
                      subtitle = "with means and 95% HDI")

ggplot(sim_modLSM_posterior_long, aes(x = Estimate, y = Parameter, fill = neurotype)) +
  stat_halfeye(point_interval = mean_hdi, .width = c(0.95), size = 0.5, , height = 3, fill = "#9ED4D1") +  # Adjusting the size of the points
  #scale_fill_manual(values = colors) +
  labs(x = "Parameter estimates", y = "Parameters", fill = "Neurotype") +
  plot_title +
  theme_minimal() +  # Using theme_minimal() instead of theme_clean()
  theme(legend.position = "right",
        panel.grid.major = element_blank(),  # Remove major grid lines
        panel.grid.minor = element_blank(),  # Remove minor grid lines
        axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14),
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 12),
    plot.title = element_text(size = 16),
    legend.title = element_text(size = 14),
    legend.text = element_text(size = 12)) +  # Increase font size of axis titles) +  # Add a single line at 0 on the x-axis
  geom_vline(xintercept = 0, linetype = "dashed")  # Add a dashed line at x = 0

ggplot(sim_modLSME_posterior_long, aes(x = Estimate, y = Parameter, fill = neurotype)) +
  stat_halfeye(point_interval = mean_hdi, .width = c(0.95), size = 0.5, , height = 3, fill = "#9ED4D1") +  # Adjusting the size of the points
  #scale_fill_manual(values = colors) +
  labs(x = "Parameter estimates", y = "Parameters", fill = "Neurotype") +
  plot_title +
  theme_minimal() +  # Using theme_minimal() instead of theme_clean()
  theme(legend.position = "right",
        panel.grid.major = element_blank(),  # Remove major grid lines
        panel.grid.minor = element_blank(),  # Remove minor grid lines
        axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14),
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 12),
    plot.title = element_text(size = 16),
    legend.title = element_text(size = 14),
    legend.text = element_text(size = 12)) +  # Increase font size of axis titles) +  # Add a single line at 0 on the x-axis
  geom_vline(xintercept = 0, linetype = "dashed")  # Add a dashed line at x = 0
```

Visualise model-predicted lose-shift behaviours as a function of MASQ and EDA-QA scores by neurotype:

```{r}
#Read in saved data file:
sim_data <- read.csv("Sim_Data.csv")

#Prepare and standardise variables:
data <- sim_data %>%
  mutate(
    EDAQ = standardize(EDAQ),
    MASQ = standardize(MASQ),
    RLLR = standardize(RLLR),
    perseveration = standardize(perseveration),
    regression = standardize(regression),
    loseShift = standardize(loseShift)
  ) %>%
  select(id, EDAQ, MASQ, RLLR, loseShift, perseveration, regression, neurotype) %>%
  distinct()

#Load the model output from a file:
sim_modLSM <- readRDS("sim_modLSM_output.rds")
sim_modLSME <- readRDS("sim_modLSME_output.rds")

#Extract conditional effects:
ce_LSM <- conditional_effects(sim_modLSM)
ce_LSME <- conditional_effects(sim_modLSME)

#Convert the specific effect to a data frames:
ce_LSM_MASQ <- as.data.frame(ce_LSM$`MASQ:neurotype`)
ce_LSME_MASQ <- as.data.frame(ce_LSME$`MASQ:neurotype`)
ce_LSME_EDAQ <- as.data.frame(ce_LSME$`EDAQ:neurotype`)

#Select relevant columns:
ce_LSM_MASQ <- ce_LSM_MASQ %>% 
  select(MASQ, neurotype, estimate__, lower__, upper__)
ce_LSME_MASQ <- ce_LSME_MASQ %>% 
  select(MASQ, neurotype, estimate__, lower__, upper__)
ce_LSME_EDAQ <- ce_LSME_EDAQ %>% 
  select(EDAQ, neurotype, estimate__, lower__, upper__)

#Plot for MASQ for sim_modRM:
ggplot(ce_LSM_MASQ, aes(x = MASQ, y = estimate__, color = neurotype)) +
  geom_point(data = data, aes(x = MASQ, y = loseShift, color = neurotype)) +
  geom_line(aes(y = estimate__),size = 1) +  # Line for estimated effects
  geom_ribbon(aes(ymin = lower__, ymax = upper__, fill = neurotype), alpha = 0.3, color = NA) +  # Ribbons for uncertainty
  theme_minimal() +  # Use a minimal theme
  labs(title = "Effect Of MASQ Scores On Lose-Shift Behaviour By Neurotype",
       x = "MASQ",
       y = "Estimated Effect") +
  scale_color_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) +
  scale_fill_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) 

#Plot for MASQ for sim_modRME:
LSMEplot_masq <- ggplot(ce_LSME_MASQ, aes(x = MASQ, y = estimate__, color = neurotype)) +
  geom_point(data = data, aes(x = MASQ, y = loseShift, color = neurotype)) +
  geom_line(aes(y = estimate__),size = 1) +  # Line for estimated effects
  geom_ribbon(aes(ymin = lower__, ymax = upper__, fill = neurotype), alpha = 0.3, color = NA) +  # Ribbons for uncertainty
  theme_minimal() +  # Use a minimal theme
  labs(x = "MASQ",
       y = "Estimated Effect") +
  scale_color_manual(values = c("#cc99ff", "#66cccc"),  guide = "none") +
  scale_fill_manual(values = c("#cc99ff", "#66cccc"),  guide = "none") 

#Plot for EDAQ for sim_modRME:
LSMEplot_edaq <- ggplot(ce_LSME_EDAQ, aes(x = EDAQ, y = estimate__, color = neurotype)) +
  geom_point(data = data, aes(x = EDAQ, y = loseShift, color = neurotype)) +
  geom_line(aes(y = estimate__),size = 1) +  # Line for estimated effects
  geom_ribbon(aes(ymin = lower__, ymax = upper__, fill = neurotype), alpha = 0.3, color = NA) +  # Ribbons for uncertainty
  theme_minimal() +  # Use a minimal theme
  labs(x = "EDAQ",
       y = "") +
  scale_color_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) +
  scale_fill_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) 

#Combine the plots:
(LSMEplot_masq + LSMEplot_edaq) + plot_annotation(title = "Effect Of MASQ And EDAQ Scores On Lose-Shift behaviour By Neurotype")
```

The plots above depict the estimated effect of MASQ and EDA-QA scores on lose-shift behaviours. Again, we expect that 1) the number of lose-shift behaviours (i.e., a response switch made after receiving negative feedback, reported as a proportion of total negative feedback trials) to be greater for the ASC group compared to the NT group, 2) the number of lose-shift behaviours will be positively associated with anxiety and PDA, and 3) the number of lose-shift behaviours produced by the ASC group will be similar irrespective of anxiety and PDA. That these assumptions built into our simulated data are evident in our model's predictive output suggests that our model fits our simulated data well.

### Perseverative behaviour

To better understand the relationship between PDA and probabilistic learning, we will run a set of Bayesian regression models, 1) will model perseverative behaviours predicted by neurotype x MASQ scores, 2) will model perseverative behaviours predicted by neurotype x MASQ and neurotype x EDA-QA scores. We will perform model selection analysis (LOOCV) to discern which model better accounts for our data. This will help us infer if the EDA-QA is explaining any additional variance in perseverative behaviours over and above MASQ scores:

$$ perseveration_i \sim Normal( \mu_1, \sigma_1 )  \\ \mu_{ij} = \alpha + \beta_1 \text{MASQ}_i + \beta_2 \text{neurotype}_j + \beta_3 (\text{MASQ}_i \times \text{neurotype}_j)\\ \alpha \sim {Normal}(0, 1) \quad \\ \beta_1, \beta_2, \beta_3  \sim {Normal}(0, 1) \quad  \\ \sigma \sim \text{Exponential}(1) $$ And for comparison:

$$
perseveration_i ∼ Normal( μ_i, σ ) \\
\mu_{ij} = \alpha + \beta_1 \text{MASQ}_i + \beta_2 \text{neurotype}_j + \beta_3 (\text{MASQ}_i \times \text{neurotype}_j) + \beta_4 \text{EDAQ}_i + \beta_5 (\text{EDAQ}_i \times \text{neurotype}_j) \\
\alpha \sim {Normal}(0, 1) \quad \\
\beta_1, \beta_2, \beta_3, \beta_4, \beta_5  \sim {Normal}(0, 1) \quad  \\
\sigma \sim \text{Exponential}(1)
$$

Soon we will perform prior predictive checks and sensitivity analysis to justify our choice of priors, but for now, we will use uninformative flat priors to check the simulation is working - because we simulate standardised variables we will assume $Normal(0,1)$.

Now fit the models to the simulated data- again, in lieu of justified priors, we will assume $Normal(0,1)$:

```{r}
#Read in saved data file:
sim_data <- read.csv("Sim_Data.csv")

#Prepare and standardise variables:
data <- sim_data %>%
  mutate(
    EDAQ = standardize(EDAQ),
    MASQ = standardize(MASQ),
    RLLR = standardize(RLLR),
    perseveration = standardize(perseveration),
    regression = standardize(regression),
    loseShift = standardize(loseShift)
  ) %>%
  select(id, EDAQ, MASQ, RLLR, loseShift, perseveration, regression, neurotype) %>%
  distinct()

#Fit the model where perseverative behaviours are predicted by MASQ scores by neurotype:
sim_modPM <- brm(
  perseveration ~ MASQ*neurotype,
  data = data,
  backend = "cmdstan",
  family = gaussian(),
  prior = c(
    prior(normal(0, 1), class = "Intercept"),
    prior(normal(0, 1), class = "b"),
    prior(exponential(1), class = "sigma")
  ),
  control = list(adapt_delta = 0.99),
  cores = 4,
  save_pars = save_pars(all = TRUE),
  sig_figs = 10,
  file = "sim_modPM_output.rds"
  )

#Fit the model where perseverative behaviours are predicted by a MASQ*neurotype and EDA-QA*neurotype:
sim_modPME <- brm(
  perseveration ~ MASQ*neurotype + EDAQ*neurotype,
  data = data,
  backend = "cmdstan",
  family = gaussian(),
  prior = c(
    prior(normal(0, 1), class = "Intercept"),
    prior(normal(0, 1), class = "b"),
    prior(exponential(1), class = "sigma")
  ),
  control = list(adapt_delta = 0.99),
  cores = 4,
  save_pars = save_pars(all = TRUE),
  sig_figs = 10,
  file = "sim_modPME_output.rds"
  )
```

Add LOO criterion for model comparison:

```{r}
#Add model LOO criterion (set reloo = TRUE if problematic observations are returned; IMPORTANT - make sure sig_figs = at least 10, otherwise add_criterion returns error: https://discourse.mc-stan.org/t/simplex-variable-error-during-bridgesampling/30811): 
sim_modPM <- add_criterion(sim_modPM, "loo", moment_match = TRUE, reloo = TRUE, recompile = TRUE) 
sim_modPME <- add_criterion(sim_modPME, "loo", moment_match = TRUE, reloo = TRUE, recompile = TRUE)
```

Inspect output for both models:

```{r}
#Load the model output from a file:
sim_modPM <- readRDS("sim_modPM_output.rds")
sim_modPME <- readRDS("sim_modPME_output.rds")

#Return model output:
summary(sim_modPM)
summary(sim_modPME)

#We can also manually check the range of Pareto-k values; anything near or above 0.7 is likely problematic:
#range(loo(sim_modRM)$diagnostics$pareto_k)
#range(loo(sim_modRME)$diagnostics$pareto_k)

#Also, run model comparison:
loo_compare(sim_modPM, sim_modPME, criterion = "loo")
```

Interpreting the LOO output above - this will vary slightly each time the analysis is run:

-   **`elpd_diff`**: This is the difference in the expected log predictive density (elpd) between the two models. The higher the elpd, the better the model is at predicting new data. Here, `sim_modPME` has an elpd difference of 0.0, which means it's used as the reference model. `sim_modPM` has an elpd difference of -94.4, meaning it is 94.4 units worse in terms of predictive performance compared to `sim_modPME`.

-   **`se_diff`**: This is the standard error of the elpd difference. It quantifies the uncertainty in the elpd difference. A standard error of 13.6 for `sim_modPM` suggests that the estimate of the elpd difference has some variability, but the large difference (-94.4) still indicates that `sim_modPME` is likely much better at predicting new data than `sim_modPM`.

Plot parameter distributions with credible intervals:

```{r}
#Extract posterior samples:
sim_modPM_posterior <- posterior_samples(sim_modPM)
sim_modPME_posterior <- posterior_samples(sim_modPME)


#Filter out 'lprior' and 'lp__':
sim_modPM_posterior <- sim_modPM_posterior[, c("b_Intercept", "b_MASQ", "b_neurotypeNT", "b_MASQ:neurotypeNT", "sigma")]
sim_modPME_posterior <- sim_modPME_posterior[, c("b_Intercept", "b_MASQ", "b_neurotypeNT","b_EDAQ", "b_MASQ:neurotypeNT", "b_neurotypeNT:EDAQ", "sigma")]

#Convert the data frame to long format:
sim_modPM_posterior_long <- pivot_longer(sim_modPM_posterior, 
                                        cols = everything(), 
                                        names_to = "Parameter", 
                                        values_to = "Estimate")
sim_modPME_posterior_long <- pivot_longer(sim_modPME_posterior, 
                                        cols = everything(), 
                                        names_to = "Parameter", 
                                        values_to = "Estimate")

#Rename parameters to 'Intercept', 'MASQ', 'EDAQ', and 'sigma':
sim_modPM_posterior_long$Parameter <- recode(sim_modPM_posterior_long$Parameter,
                                            "b_Intercept" = "Intercept",
                                            "b_MASQ" = "MASQ", 
                                            "b_neurotypeNT" = "neurotypeNT",
                                            "b_EDAQ" = "EDAQ", 
                                            "b_MASQ:neurotypeNT" = "MASQ:neurotypeNT", 
                                            "b_neurotypeNT.EDAQ" = "neurotypeNT:EDAQ", 
                                            "sigma" = "Sigma")
sim_modPME_posterior_long$Parameter <- recode(sim_modPME_posterior_long$Parameter,
                                            "b_Intercept" = "Intercept",
                                            "b_MASQ" = "MASQ", 
                                            "b_neurotypeNT" = "neurotypeNT",
                                            "b_EDAQ" = "EDAQ", 
                                            "b_MASQ:neurotypeNT" = "MASQ:neurotypeNT", 
                                            "b_neurotypeNT:EDAQ" = "neurotypeNT:EDAQ", 
                                            "sigma" = "Sigma")

#Extract group information from parameter names:
sim_modPM_posterior_long$Group <- sub(":.*", "", sim_modPM_posterior_long$Parameter)
sim_modPME_posterior_long$Group <- sub(":.*", "", sim_modPME_posterior_long$Parameter)

#Reorder the parameters and flip the order:
sim_modPM_posterior_long$Parameter <- factor(sim_modPM_posterior_long$Parameter, 
                                            levels = rev(c("Intercept","MASQ","neurotypeNT","MASQ:neurotypeNT","Sigma")))
sim_modPME_posterior_long$Parameter <- factor(sim_modPME_posterior_long$Parameter, 
                                            levels = rev(c("Intercept","MASQ","neurotypeNT","EDAQ","MASQ:neurotypeNT","neurotypeNT:EDAQ","Sigma")))

#Plot marginal posterior distributions with specified colors:
plot_title <- ggtitle("Posterior distributions",
                      subtitle = "with means and 95% HDI")

ggplot(sim_modPM_posterior_long, aes(x = Estimate, y = Parameter, fill = neurotype)) +
  stat_halfeye(point_interval = mean_hdi, .width = c(0.95), size = 0.5, , height = 3, fill = "#9ED4D1") +  # Adjusting the size of the points
  #scale_fill_manual(values = colors) +
  labs(x = "Parameter estimates", y = "Parameters", fill = "Neurotype") +
  plot_title +
  theme_minimal() +  # Using theme_minimal() instead of theme_clean()
  theme(legend.position = "right",
        panel.grid.major = element_blank(),  # Remove major grid lines
        panel.grid.minor = element_blank(),  # Remove minor grid lines
        axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14),
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 12),
    plot.title = element_text(size = 16),
    legend.title = element_text(size = 14),
    legend.text = element_text(size = 12)) +  # Increase font size of axis titles) +  # Add a single line at 0 on the x-axis
  geom_vline(xintercept = 0, linetype = "dashed")  # Add a dashed line at x = 0

ggplot(sim_modPME_posterior_long, aes(x = Estimate, y = Parameter, fill = neurotype)) +
  stat_halfeye(point_interval = mean_hdi, .width = c(0.95), size = 0.5, , height = 3, fill = "#9ED4D1") +  # Adjusting the size of the points
  #scale_fill_manual(values = colors) +
  labs(x = "Parameter estimates", y = "Parameters", fill = "Neurotype") +
  plot_title +
  theme_minimal() +  # Using theme_minimal() instead of theme_clean()
  theme(legend.position = "right",
        panel.grid.major = element_blank(),  # Remove major grid lines
        panel.grid.minor = element_blank(),  # Remove minor grid lines
        axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14),
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 12),
    plot.title = element_text(size = 16),
    legend.title = element_text(size = 14),
    legend.text = element_text(size = 12)) +  # Increase font size of axis titles) +  # Add a single line at 0 on the x-axis
  geom_vline(xintercept = 0, linetype = "dashed")  # Add a dashed line at x = 0
```

Visualise model-predicted perseverative behaviours as a function of MASQ and EDA-QA scores by neurotype:

```{r}
#Read in saved data file:
sim_data <- read.csv("Sim_Data.csv")

#Prepare and standardise variables:
data <- sim_data %>%
  mutate(
    EDAQ = standardize(EDAQ),
    MASQ = standardize(MASQ),
    RLLR = standardize(RLLR),
    perseveration = standardize(perseveration),
    regression = standardize(regression),
    loseShift = standardize(loseShift)
  ) %>%
  select(id, EDAQ, MASQ, RLLR, loseShift, perseveration, regression, neurotype) %>%
  distinct()

#Load the model output from a file:
sim_modPM <- readRDS("sim_modPM_output.rds")
sim_modPME <- readRDS("sim_modPME_output.rds")

#Extract conditional effects:
ce_PM <- conditional_effects(sim_modPM)
ce_PME <- conditional_effects(sim_modPME)

#Convert the specific effect to a data frames:
ce_PM_MASQ <- as.data.frame(ce_PM$`MASQ:neurotype`)
ce_PME_MASQ <- as.data.frame(ce_PME$`MASQ:neurotype`)
ce_PME_EDAQ <- as.data.frame(ce_PME$`EDAQ:neurotype`)

#Select relevant columns:
ce_PM_MASQ <- ce_PM_MASQ %>% 
  select(MASQ, neurotype, estimate__, lower__, upper__)
ce_PME_MASQ <- ce_PME_MASQ %>% 
  select(MASQ, neurotype, estimate__, lower__, upper__)
ce_PME_EDAQ <- ce_PME_EDAQ %>% 
  select(EDAQ, neurotype, estimate__, lower__, upper__)

#Plot for MASQ for sim_modRM:
ggplot(ce_PM_MASQ, aes(x = MASQ, y = estimate__, color = neurotype)) +
  geom_point(data = data, aes(x = MASQ, y = perseveration, color = neurotype)) +
  geom_line(aes(y = estimate__),size = 1) +  # Line for estimated effects
  geom_ribbon(aes(ymin = lower__, ymax = upper__, fill = neurotype), alpha = 0.3, color = NA) +  # Ribbons for uncertainty
  theme_minimal() +  # Use a minimal theme
  labs(title = "Effect Of MASQ Scores On Perseverative behaviours By Neurotype",
       x = "MASQ",
       y = "Estimated Effect") +
  scale_color_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) +
  scale_fill_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) 

#Plot for MASQ for sim_modRME:
PMEplot_masq <- ggplot(ce_PME_MASQ, aes(x = MASQ, y = estimate__, color = neurotype)) +
  geom_point(data = data, aes(x = MASQ, y = perseveration, color = neurotype)) +
  geom_line(aes(y = estimate__),size = 1) +  # Line for estimated effects
  geom_ribbon(aes(ymin = lower__, ymax = upper__, fill = neurotype), alpha = 0.3, color = NA) +  # Ribbons for uncertainty
  theme_minimal() +  # Use a minimal theme
  labs(x = "MASQ",
       y = "Estimated Effect") +
  scale_color_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) +
  scale_fill_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) 

#Plot for EDAQ for sim_modRME:
PMEplot_edaq <- ggplot(ce_PME_EDAQ, aes(x = EDAQ, y = estimate__, color = neurotype)) +
  geom_point(data = data, aes(x = EDAQ, y = perseveration, color = neurotype)) +
  geom_line(aes(y = estimate__),size = 1) +  # Line for estimated effects
  geom_ribbon(aes(ymin = lower__, ymax = upper__, fill = neurotype), alpha = 0.3, color = NA) +  # Ribbons for uncertainty
  theme_minimal() +  # Use a minimal theme
  labs(x = "EDAQ",
       y = "") +
  scale_color_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) +
  scale_fill_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) 

#Combine the plots:
(PMEplot_masq + PMEplot_edaq) + plot_annotation(title = "Effect Of MASQ And EDAQ Scores On Perseverative behaviours By Neurotype")
```

The plots above depict the estimated effect of MASQ and EDA-QA scores on perseverative behaviours. We expect that 1) the number of perseverative behaviours (i.e., the number of errors made after the first reversal before a correct response) to be greater for the ASC group compared to the NT group, 2) anxiety and PDA will be negatively associated with perseverative behaviours, and 3) the number of perseverative behaviours produced by the ASC group will be similar irrespective of anxiety or PDA. Again, these assumptions built into our simulated data are evident in our model's predictive output - our model seemingly fits our simulated data well.

### Regressive behaviour

To better understand the relationship between PDA and probabilistic learning, we will run a set of Bayesian regression models, 1) will model regressive behaviours predicted by neurotype x MASQ scores, 2) will model regressive behaviours predicted by neurotype x MASQ and neurotype x EDA-QA scores. We will perform model selection analysis (LOOCV) to discern which model better accounts for our data. This will help us infer if the EDA-QA is explaining any additional variance in regressive behaviours over and above MASQ scores:

$$
regression_i \sim Normal( \mu_1, \sigma_1 )  \\
\mu_{ij} = \alpha + \beta_1 \text{MASQ}_i + \beta_2 \text{neurotype}_j + \beta_3 (\text{MASQ}_i \times \text{neurotype}_j)\\
\alpha \sim {Normal}(0, 1) \quad \\
\beta_1, \beta_2, \beta_3  \sim {Normal}(0, 1) \quad  \\
\sigma \sim \text{Exponential}(1)
$$ And for comparison:

$$ regression_i ∼ Normal( μ_i, σ ) \\ \mu_{ij} = \alpha + \beta_1 \text{MASQ}_i + \beta_2 \text{neurotype}_j + \beta_3 (\text{MASQ}_i \times \text{neurotype}_j) + \beta_4 \text{EDAQ}_i + \beta_5 (\text{EDAQ}_i \times \text{neurotype}_j) \\ \alpha \sim {Normal}(0, 1) \quad \\ \beta_1, \beta_2, \beta_3, \beta_4, \beta_5  \sim {Normal}(0, 1) \quad  \\ \sigma \sim \text{Exponential}(1) $$

Soon we will perform prior predictive checks and sensitivity analysis to justify our choice of priors, but for now, we will use uninformative flat priors to check the simulation is working - because we simulate standardised variables we will assume $Normal(0,1)$.

Now fit the models to the simulated data- again, in lieu of justified priors, we will assume $Normal(0,1)$:

```{r}
#Read in saved data file:
sim_data <- read.csv("Sim_Data.csv")

#Prepare and standardise variables:
data <- sim_data %>%
  mutate(
    EDAQ = standardize(EDAQ),
    MASQ = standardize(MASQ),
    RLLR = standardize(RLLR),
    perseveration = standardize(perseveration),
    regression = standardize(regression),
    loseShift = standardize(loseShift)
  ) %>%
  select(id, EDAQ, MASQ, RLLR, loseShift, perseveration, regression, neurotype) %>%
  distinct()

#Fit the model where regressive behaviours are predicted by MASQ scores by neurotype:
sim_modReM <- brm(
  regression ~ MASQ*neurotype,
  data = data,
  backend = "cmdstan",
  family = gaussian(),
  prior = c(
    prior(normal(0, 1), class = "Intercept"),
    prior(normal(0, 1), class = "b"),
    prior(exponential(1), class = "sigma")
  ),
  control = list(adapt_delta = 0.99),
  cores = 4,
  save_pars = save_pars(all = TRUE),
  sig_figs = 10,
  file = "sim_modReM_output.rds"
  )

#Fit the model where regressive behaviours are predicted by a MASQ*neurotype and EDA-QA*neurotype:
sim_modReME <- brm(
  regression ~ MASQ*neurotype + EDAQ*neurotype,
  data = data,
  backend = "cmdstan",
  family = gaussian(),
  prior = c(
    prior(normal(0, 1), class = "Intercept"),
    prior(normal(0, 1), class = "b"),
    prior(exponential(1), class = "sigma")
  ),
  control = list(adapt_delta = 0.99),
  cores = 4,
  save_pars = save_pars(all = TRUE),
  sig_figs = 10,
  file = "sim_modReME_output.rds"
  )
```

Add LOO criterion for model comparison:

```{r}
#Add model LOO criterion (set reloo = TRUE if problematic observations are returned; IMPORTANT - make sure sig_figs = at least 10, otherwise add_criterion returns error: https://discourse.mc-stan.org/t/simplex-variable-error-during-bridgesampling/30811):
sim_modReM <- add_criterion(sim_modReM, "loo", moment_match = TRUE, reloo = TRUE, recompile = TRUE)
sim_modReME <- add_criterion(sim_modReME, "loo", moment_match = TRUE, reloo = TRUE, recompile = TRUE)
```

Inspect output for both models:

```{r}
#Load the model output from a file:
sim_modReM <- readRDS("sim_modReM_output.rds")
sim_modReME <- readRDS("sim_modReME_output.rds")

#Return model output:
summary(sim_modReM)
summary(sim_modReME)

#We can also manually check the range of Pareto-k values; anything near or above 0.7 is likely problematic:
#range(loo(sim_modRM)$diagnostics$pareto_k)
#range(loo(sim_modRME)$diagnostics$pareto_k)

#Also, run model comparison:
loo_compare(sim_modReM, sim_modReME, criterion = "loo")
```

Interpreting the LOO output above - this will vary slightly each time the analysis is run:

-   **`elpd_diff`**: This is the difference in the expected log predictive density (elpd) between the two models. The higher the elpd, the better the model is at predicting new data. Here, `sim_modReME` has an elpd difference of 0.0, which means it's used as the reference model. `sim_modReM` has an elpd difference of -105.3, meaning it is 105.3 units worse in terms of predictive performance compared to `sim_modReME`.

-   **`se_diff`**: This is the standard error of the elpd difference. It quantifies the uncertainty in the elpd difference. A standard error of 14.6 for `sim_modReM` suggests that the estimate of the elpd difference has some variability, but the large difference (-105.3) still indicates that `sim_modReME` is likely much better at predicting new data than `sim_modReM`.

Plot parameter distributions with credible intervals:

```{r}
#Extract posterior samples:
sim_modReM_posterior <- posterior_samples(sim_modReM)
sim_modReME_posterior <- posterior_samples(sim_modReME)


#Filter out 'lprior' and 'lp__':
sim_modReM_posterior <- sim_modReM_posterior[, c("b_Intercept", "b_MASQ", "b_neurotypeNT", "b_MASQ:neurotypeNT", "sigma")]
sim_modReME_posterior <- sim_modReME_posterior[, c("b_Intercept", "b_MASQ", "b_neurotypeNT","b_EDAQ", "b_MASQ:neurotypeNT", "b_neurotypeNT:EDAQ", "sigma")]

#Convert the data frame to long format:
sim_modReM_posterior_long <- pivot_longer(sim_modReM_posterior, 
                                        cols = everything(), 
                                        names_to = "Parameter", 
                                        values_to = "Estimate")
sim_modReME_posterior_long <- pivot_longer(sim_modReME_posterior, 
                                        cols = everything(), 
                                        names_to = "Parameter", 
                                        values_to = "Estimate")

#Rename parameters to 'Intercept', 'MASQ', 'EDAQ', and 'sigma':
sim_modReM_posterior_long$Parameter <- recode(sim_modReM_posterior_long$Parameter,
                                            "b_Intercept" = "Intercept",
                                            "b_MASQ" = "MASQ", 
                                            "b_neurotypeNT" = "neurotypeNT",
                                            "b_EDAQ" = "EDAQ", 
                                            "b_MASQ:neurotypeNT" = "MASQ:neurotypeNT", 
                                            "b_neurotypeNT.EDAQ" = "neurotypeNT:EDAQ", 
                                            "sigma" = "Sigma")
sim_modReME_posterior_long$Parameter <- recode(sim_modReME_posterior_long$Parameter,
                                            "b_Intercept" = "Intercept",
                                            "b_MASQ" = "MASQ", 
                                            "b_neurotypeNT" = "neurotypeNT",
                                            "b_EDAQ" = "EDAQ", 
                                            "b_MASQ:neurotypeNT" = "MASQ:neurotypeNT", 
                                            "b_neurotypeNT:EDAQ" = "neurotypeNT:EDAQ", 
                                            "sigma" = "Sigma")

#Extract group information from parameter names:
sim_modReM_posterior_long$Group <- sub(":.*", "", sim_modReM_posterior_long$Parameter)
sim_modReME_posterior_long$Group <- sub(":.*", "", sim_modReME_posterior_long$Parameter)

#Reorder the parameters and flip the order:
sim_modReM_posterior_long$Parameter <- factor(sim_modReM_posterior_long$Parameter, 
                                            levels = rev(c("Intercept","MASQ","neurotypeNT","MASQ:neurotypeNT","Sigma")))
sim_modReME_posterior_long$Parameter <- factor(sim_modReME_posterior_long$Parameter, 
                                            levels = rev(c("Intercept","MASQ","neurotypeNT","EDAQ","MASQ:neurotypeNT","neurotypeNT:EDAQ","Sigma")))

#Plot marginal posterior distributions with specified colors:
plot_title <- ggtitle("Posterior distributions",
                      subtitle = "with means and 95% HDI")

ggplot(sim_modReM_posterior_long, aes(x = Estimate, y = Parameter, fill = neurotype)) +
  stat_halfeye(point_interval = mean_hdi, .width = c(0.95), size = 0.5, , height = 3, fill = "#9ED4D1") +  # Adjusting the size of the points
  #scale_fill_manual(values = colors) +
  labs(x = "Parameter estimates", y = "Parameters", fill = "Neurotype") +
  plot_title +
  theme_minimal() +  # Using theme_minimal() instead of theme_clean()
  theme(legend.position = "right",
        panel.grid.major = element_blank(),  # Remove major grid lines
        panel.grid.minor = element_blank(),  # Remove minor grid lines
        axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14),
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 12),
    plot.title = element_text(size = 16),
    legend.title = element_text(size = 14),
    legend.text = element_text(size = 12)) +  # Increase font size of axis titles) +  # Add a single line at 0 on the x-axis
  geom_vline(xintercept = 0, linetype = "dashed")  # Add a dashed line at x = 0

ggplot(sim_modReME_posterior_long, aes(x = Estimate, y = Parameter, fill = neurotype)) +
  stat_halfeye(point_interval = mean_hdi, .width = c(0.95), size = 0.5, , height = 3, fill = "#9ED4D1") +  # Adjusting the size of the points
  #scale_fill_manual(values = colors) +
  labs(x = "Parameter estimates", y = "Parameters", fill = "Neurotype") +
  plot_title +
  theme_minimal() +  # Using theme_minimal() instead of theme_clean()
  theme(legend.position = "right",
        panel.grid.major = element_blank(),  # Remove major grid lines
        panel.grid.minor = element_blank(),  # Remove minor grid lines
        axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14),
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 12),
    plot.title = element_text(size = 16),
    legend.title = element_text(size = 14),
    legend.text = element_text(size = 12)) +  # Increase font size of axis titles) +  # Add a single line at 0 on the x-axis
  geom_vline(xintercept = 0, linetype = "dashed")  # Add a dashed line at x = 0
```

Visualise model-predicted regressive behaviours as a function of MASQ and EDA-QA scores by neurotype:

```{r}
#Read in saved data file:
sim_data <- read.csv("Sim_Data.csv")

#Prepare and standardise variables:
data <- sim_data %>%
  mutate(
    EDAQ = standardize(EDAQ),
    MASQ = standardize(MASQ),
    RLLR = standardize(RLLR),
    perseveration = standardize(perseveration),
    regression = standardize(regression),
    loseShift = standardize(loseShift)
  ) %>%
  select(id, EDAQ, MASQ, RLLR, loseShift, perseveration, regression, neurotype) %>%
  distinct()

#Load the model output from a file:
sim_modReM <- readRDS("sim_modReM_output.rds")
sim_modReME <- readRDS("sim_modReME_output.rds")

#Extract conditional effects:
ce_ReM <- conditional_effects(sim_modReM)
ce_ReME <- conditional_effects(sim_modReME)

#Convert the specific effect to a data frames:
ce_ReM_MASQ <- as.data.frame(ce_ReM$`MASQ:neurotype`)
ce_ReME_MASQ <- as.data.frame(ce_ReME$`MASQ:neurotype`)
ce_ReME_EDAQ <- as.data.frame(ce_ReME$`EDAQ:neurotype`)

#Select relevant columns:
ce_ReM_MASQ <- ce_ReM_MASQ %>% 
  select(MASQ, neurotype, estimate__, lower__, upper__)
ce_ReME_MASQ <- ce_ReME_MASQ %>% 
  select(MASQ, neurotype, estimate__, lower__, upper__)
ce_ReME_EDAQ <- ce_ReME_EDAQ %>% 
  select(EDAQ, neurotype, estimate__, lower__, upper__)

#Plot for MASQ for sim_modRM:
ggplot(ce_ReM_MASQ, aes(x = MASQ, y = estimate__, color = neurotype)) +
  geom_point(data = data, aes(x = MASQ, y = regression, color = neurotype)) +
  geom_line(aes(y = estimate__),size = 1) +  # Line for estimated effects
  geom_ribbon(aes(ymin = lower__, ymax = upper__, fill = neurotype), alpha = 0.3, color = NA) +  # Ribbons for uncertainty
  theme_minimal() +  # Use a minimal theme
  labs(title = "Effect Of MASQ Scores On Regressive behaviours By Neurotype",
       x = "MASQ",
       y = "Estimated Effect") +
  scale_color_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) +
  scale_fill_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) 

#Plot for MASQ for sim_modRME:
ReMEplot_masq <- ggplot(ce_ReME_MASQ, aes(x = MASQ, y = estimate__, color = neurotype)) +
  geom_point(data = data, aes(x = MASQ, y = regression, color = neurotype)) +
  geom_line(aes(y = estimate__),size = 1) +  # Line for estimated effects
  geom_ribbon(aes(ymin = lower__, ymax = upper__, fill = neurotype), alpha = 0.3, color = NA) +  # Ribbons for uncertainty
  theme_minimal() +  # Use a minimal theme
  labs(x = "MASQ",
       y = "Estimated Effect") +
  scale_color_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) +
  scale_fill_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) 

#Plot for EDAQ for sim_modRME:
ReMEplot_edaq <- ggplot(ce_ReME_EDAQ, aes(x = EDAQ, y = estimate__, color = neurotype)) +
  geom_point(data = data, aes(x = EDAQ, y = regression, color = neurotype)) +
  geom_line(aes(y = estimate__),size = 1) +  # Line for estimated effects
  geom_ribbon(aes(ymin = lower__, ymax = upper__, fill = neurotype), alpha = 0.3, color = NA) +  # Ribbons for uncertainty
  theme_minimal() +  # Use a minimal theme
  labs(x = "EDAQ",
       y = "") +
  scale_color_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) +
  scale_fill_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) 

#Combine the plots:
(ReMEplot_masq + ReMEplot_edaq) + plot_annotation(title = "Effect Of MASQ And EDAQ Scores On Regressive behaviours By Neurotype")
```

The plots above depicts the estimated effect of MASQ and EDA-QA scores on regressive behaviours. Much like perseverative behaviours, we expect that 1) the number of regressive behaviours (i.e., the number of errors made after the first reversal before a correct response) to be greater for the ASC group compared to the NT group, 2) anxiety and PDA will be negatively associated with regressive behaviours, and 3) the number of regressive behaviours produced by the ASC group will be similar irrespective of anxiety or PDA. Again, these assumptions built into our simulated data are evident in our model's predictive output - our model seemingly fits our simulated data well.

## Learning rate predicted by neurotype, PDA and anxiety

### Effect of block order on RLLR

First, learning rates should be higher in the volatile compared to the stable condition irrespective of blockorder, so check that there is no effect of blockorder on RLL

$$
RLLR_i \sim Normal( \mu_1, \sigma_1 )  \\
\mu_{ij} = \alpha + \beta_1 \text{blocckOrder}_i + \beta_2 \text{neurotype}_j + \beta_3 (\text{blockOrder}_i \times \text{neurotype}_j)\\
\alpha \sim {Normal}(0, 1) \quad \\
\beta_1, \beta_2, \beta_3  \sim {Normal}(0, 1) \quad  \\
\sigma \sim \text{Exponential}(1)
$$

Soon we will perform prior predictive checks and sensitivity analysis to justify our choice of priors, but for now, we will use uninformative flat priors to check the simulation is working- because we simulate standardised variables we will assume $Normal(0,1)$.

Now fit the models to the simulated data- again, in lieu of justified priors, we will assume $Normal(0,1)$:

```{r}
#Read in saved data file:
sim_data <- read.csv("Sim_Data.csv")

#Prepare and standardise variables:
data <- sim_data %>%
  mutate(
    EDAQ = standardize(EDAQ),
    MASQ = standardize(MASQ),
    RLLR = standardize(RLLR),
    perseveration = standardize(perseveration),
    regression = standardize(regression),
    loseShift = standardize(loseShift)
  ) %>%
  select(id, EDAQ, MASQ, RLLR, loseShift, perseveration, regression, blockorder, neurotype) %>%
  distinct()

#Fit the model where relative log learning rate (RLLR) are predicted by blockorder by neurotype:
sim_modRB <- brm(
  RLLR ~ blockorder:neurotype,
  data = data,
  backend = "cmdstan",
  family = gaussian(),
  prior = c(
    prior(normal(0, 1), class = "Intercept"),
    prior(normal(0, 1), class = "b"),
    prior(exponential(1), class = "sigma")
  ),
  control = list(adapt_delta = 0.99),
  cores = 4,
  save_pars = save_pars(all = TRUE),
  sig_figs = 10,
  file = "sim_modRB_output.rds"
  )
```

Inspect output:

```{r}
#Load the model output from a file:
sim_modRB <- readRDS("sim_modRB_output.rds")

#Return model output:
summary(sim_modRB)
```

To plot parameter distributions, first extract posterior samples:

```{r}
#Extract posterior samples:
sim_modRB_posterior <- posterior_samples(sim_modRB)

#To visualise later, save to .csv:
write.table(sim_modRB_posterior, file="sim_modRB_posterior.csv",sep=",",row.names=F)
```

Plot parameter distributions with credible intervals:

```{r}
#Read in posterior samples .csv to data frame:
sim_modRB_posterior <- read.csv("sim_modRB_posterior.csv")


#Filter out 'lprior' and 'lp__':
sim_modRB_posterior <- sim_modRB_posterior[, c("b_blockorderSDV.neurotypeASC", "b_blockorderVDS.neurotypeASC", "b_blockorderSDV.neurotypeNT", "b_blockorderVDS.neurotypeNT", "sigma")]

#Convert the data frame to long format:
sim_modRB_posterior_long <- pivot_longer(sim_modRB_posterior, 
                                        cols = everything(), 
                                        names_to = "Parameter", 
                                        values_to = "Estimate")

#Rename parameters to 'Intercept', 'MASQ', 'EDAQ', and 'sigma':
sim_modRB_posterior_long$Parameter <- recode(sim_modRB_posterior_long$Parameter,
                                            "b_blockorderSDV.neurotypeASC" = "ASC:S/V", 
                                            "b_blockorderVDS.neurotypeASC" = "ASC:V/S",
                                            "b_blockorderSDV.neurotypeNT" = "NT:S/V", 
                                            "b_blockorderVDS.neurotypeNT" = "NT:V/S", 
                                            "sigma" = "Sigma")

#Extract group information from parameter names:
sim_modRB_posterior_long$Group <- sub(":.*", "", sim_modRB_posterior_long$Parameter)

#Reorder the parameters and flip the order:
sim_modRB_posterior_long$Parameter <- factor(sim_modRB_posterior_long$Parameter, 
                                            levels = rev(c("ASC:S/V","ASC:V/S","NT:S/V","NT:V/S", "Sigma")))

#Plot marginal posterior distributions with specified colors:
plot_title <- ggtitle("Posterior distributions",
                      subtitle = "with means and 95% HDI")

ggplot(sim_modRB_posterior_long, aes(x = Estimate, y = Parameter, fill = neurotype)) +
  stat_halfeye(point_interval = mean_hdi, .width = c(0.95), size = 0.5, , height = 3, fill = "#9ED4D1") +  # Adjusting the size of the points
  #scale_fill_manual(values = colors) +
  labs(x = "Parameter estimates", y = "Parameters", fill = "Neurotype") +
  plot_title +
  theme_minimal() +  # Using theme_minimal() instead of theme_clean()
  theme(legend.position = "right",
        panel.grid.major = element_blank(),  # Remove major grid lines
        panel.grid.minor = element_blank(),  # Remove minor grid lines
        axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14),
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 12),
    plot.title = element_text(size = 16),
    legend.title = element_text(size = 14),
    legend.text = element_text(size = 12)) +  # Increase font size of axis titles) +  # Add a single line at 0 on the x-axis
  geom_vline(xintercept = 0, linetype = "dashed")  # Add a dashed line at x = 0
```

Visualise model-predicted RLLR values by blockorder:

```{r}
#Read in saved data file:
sim_data <- read.csv("Sim_Data.csv")

#Prepare and standardise variables:
data <- sim_data %>%
  mutate(
    EDAQ = standardize(EDAQ),
    MASQ = standardize(MASQ),
    RLLR = standardize(RLLR),
    perseveration = standardize(perseveration),
    regression = standardize(regression),
    loseShift = standardize(loseShift)
  ) %>%
  select(id, EDAQ, MASQ, RLLR, loseShift, perseveration, regression, neurotype, blockorder) %>%
  distinct()

#Load the model output from a file:
sim_modRB <- readRDS("sim_modRB_output.rds")

#Extract conditional effects:
ce_RB <- conditional_effects(sim_modRB)

#Convert the specific effect to a data frames:
ce_RB <- as.data.frame(ce_RB$`blockorder:neurotype`)

#Select relevant columns:
ce_RB <- ce_RB %>% 
  select(blockorder, neurotype, estimate__, lower__, upper__)

#Calculate means for each condition:
mean_estimates <- ce_RB %>%
  group_by(blockorder, neurotype) %>%
  dplyr::summarize(mean_est = mean(estimate__, na.rm = TRUE))

#Plot for MASQ for sim_modRM:
ggplot(ce_RB, aes(x = factor(blockorder), y = estimate__, color = neurotype)) +
  geom_jitter(data = data, aes(x = factor(blockorder), y = RLLR, color = neurotype)) +
  geom_line(aes(group = interaction(neurotype, blockorder)),size = 1) +  # Line for estimated effects
  geom_ribbon(aes(ymin = lower__, ymax = upper__, fill = neurotype), alpha = 0.3, color = NA) +  # Ribbons for uncertainty
  theme_minimal() +  # Use a minimal theme
  labs(title = "Effect Of Block Order On Relative Log Learning Rate By Neurotype",
       x = "Block Order",
       y = "Estimated Effect") +
  scale_color_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) +
  scale_fill_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) +
  # Add error bars
  geom_errorbar(data = ce_RB, aes(x = blockorder, ymin = lower__, ymax = upper__), 
                width = 0.2, size = 1) +
  # Add lines connecting the mean points for each diagnostic neurotype
  geom_line(data = mean_estimates, aes(x = blockorder, y = mean_est, group = neurotype),
             size = 1) +
  # Add mean points for each diagnostic neurotype
  geom_point(data = mean_estimates, aes(x = blockorder, y = mean_est), 
             color = "#336666", size = 4, shape = 18)  # Shape 18 for diamond
```

The above plot shows model estimates for the effect of block order on RLLRs by neurotype - diamonds and lines show mean estimates for each block presentation by neurotype. Together with posterior distributions, it is evident that the order participants complete each condition (stable and volatile) does not impact learning rates. This is true for both NT and ASC groups.

### Effect of EDA-QA and MASQ on RLLR

To better understand the relationship between PDA and probabilistic learning, we will run a set of Bayesian regression models, 1) will model RLLR predicted by neurotype x MASQ scores, 2) will model RLLR predicted by neurotype x MASQ and neurtype x EDA-QA scores. We will perform model selection analysis (LOOCV) to discern which model better accounts for our data. This will help us infer if the EDA-QA is explaining any additional variance in RLLR over and above MASQ scores:

$$
RLLR_i \sim Normal( \mu_1, \sigma_1 )  \\
\mu_{ij} = \alpha + \beta_1 \text{MASQ}_i + \beta_2 \text{neurotype}_j + \beta_3 (\text{MASQ}_i \times \text{neurotype}_j)\\
\alpha \sim {Normal}(0, 1) \quad \\
\beta_1, \beta_2, \beta_3  \sim {Normal}(0, 1) \quad  \\
\sigma \sim \text{Exponential}(1)
$$

And for comparison:

$$
RLLR_i \sim Normal( \mu_1, \sigma_1 )  \\
\mu_{ij} = \alpha + \beta_1 \text{MASQ}_i + \beta_2 \text{neurotype}_j + \beta_3 (\text{MASQ}_i \times \text{neurotype}_j) + \beta_4 \text{EDAQ}_i + \beta_5 (\text{EDAQ}_i \times \text{neurotype}_j) \\
\alpha \sim {Normal}(0, 1) \quad \\
\beta_1, \beta_2, \beta_3, \beta_4, \beta_5  \sim {Normal}(0, 1) \quad  \\
\sigma \sim \text{Exponential}(1)
$$

Soon we will perform prior predictive checks and sensitivity analysis to justify our choice of priors, but for now, we will use uninformative flat priors to check the simulation is working- because we simulate standardised variables we will assume $Normal(0,1)$.

Now fit the models to the simulated data- again, in lieu of justified priors, we will assume $Normal(0,1)$:

```{r}
#Read in saved data file:
sim_data <- read.csv("Sim_Data.csv")

#Prepare and standardise variables:
data <- sim_data %>%
  mutate(
    EDAQ = standardize(EDAQ),
    MASQ = standardize(MASQ),
    RLLR = standardize(RLLR),
    perseveration = standardize(perseveration),
    regression = standardize(regression),
    loseShift = standardize(loseShift)
  ) %>%
  select(id, EDAQ, MASQ, RLLR, loseShift, perseveration, regression, neurotype) %>%
  distinct()

#Fit the model where relative log learning rate (RLLR) are predicted by MASQ scores by neurotype:
sim_modRM <- brm(
  RLLR ~ MASQ*neurotype,
  data = data,
  backend = "cmdstan",
  family = gaussian(),
  prior = c(
    prior(normal(0, 1), class = "Intercept"),
    prior(normal(0, 1), class = "b"),
    prior(exponential(1), class = "sigma")
  ),
  control = list(adapt_delta = 0.99),
  cores = 4,
  save_pars = save_pars(all = TRUE),
  sig_figs = 10,
  file = "sim_modRM_output.rds"
  )

#Fit the model where relative log learning rate (RLLR) are predicted by MASQ and EDA-QA scores by neurotype:
sim_modRME <- brm(
  RLLR ~ MASQ*neurotype + EDAQ*neurotype,
  data = data,
  backend = "cmdstan",
  family = gaussian(),
  prior = c(
    prior(normal(0, 1), class = "Intercept"),
    prior(normal(0, 1), class = "b"),
    prior(exponential(1), class = "sigma")
  ),
  control = list(adapt_delta = 0.99),
  cores = 4,
  sig_figs = 10,
  file = "sim_modRME_output.rds"
  )
```

Inspect output for both models:

```{r}
#Load the model output from a file:
sim_modRM <- readRDS("sim_modRM_output.rds")
sim_modRME <- readRDS("sim_modRME_output.rds")

#Return model output:
summary(sim_modRM)
summary(sim_modRME)

#We can also manually check the range of Pareto-k values; anything near or above 0.7 is likely problematic:
#range(loo(sim_modRM)$diagnostics$pareto_k)
#range(loo(sim_modRME)$diagnostics$pareto_k)

#Also, run model comparison (set reloo = TRUE if problematic observations are returned; IMPORTANT - make sure sig_figs = at least 10, otherwise add_criterion returns error: https://discourse.mc-stan.org/t/simplex-variable-error-during-bridgesampling/30811):
sim_modRM <- add_criterion(sim_modRM, "loo", moment_match = TRUE, reloo = TRUE, recompile = TRUE)
sim_modRME <- add_criterion(sim_modRME, "loo", moment_match = TRUE, reloo = TRUE, recompile = TRUE)
loo_compare(sim_modRM, sim_modRME, criterion = "loo")
```

Interpreting the LOO output above - this will vary slightly each time the analysis is run:

-   **`elpd_diff`**: This is the difference in the expected log predictive density (elpd) between the two models. The higher the elpd, the better the model is at predicting new data. Here, `sim_modRME` has an elpd difference of 0.0, which means it's used as the reference model. `sim_modRM` has an elpd difference of -35.8, meaning it is 35.8 units worse in terms of predictive performance compared to `sim_modRME`.

-   **`se_diff`**: This is the standard error of the elpd difference. It quantifies the uncertainty in the elpd difference. A standard error of 8.7 for `sim_modRM` suggests that the estimate of the elpd difference has some variability, but the large difference (-35.8) still indicates that `sim_modRME` is likely much better at predicting new data than `sim_modRM`.

To plot parameter distributions, first extract posterior samples:

```{r}
#Extract posterior samples:
sim_modRM_posterior <- posterior_samples(sim_modRM)
sim_modRME_posterior <- posterior_samples(sim_modRME)

#To visualise later, save to .csv:
write.table(sim_modRM_posterior, file="sim_modRM_posterior.csv",sep=",",row.names=F)
write.table(sim_modRME_posterior, file="sim_modRME_posterior.csv",sep=",",row.names=F)
```

Plot parameter distributions with credible intervals:

```{r}
#Read in posterior samples .csv to data frame:
sim_modRM_posterior <- read.csv("sim_modRM_posterior.csv")
sim_modRME_posterior <- read.csv("sim_modRME_posterior.csv")


#Filter out 'lprior' and 'lp__':
sim_modRM_posterior <- sim_modRM_posterior[, c("b_Intercept", "b_MASQ", "b_neurotypeNT", "b_MASQ.neurotypeNT", "sigma")]
sim_modRME_posterior <- sim_modRME_posterior[, c("b_Intercept", "b_MASQ", "b_neurotypeNT","b_EDAQ", "b_MASQ.neurotypeNT", "b_neurotypeNT.EDAQ", "sigma")]

#Convert the data frame to long format:
sim_modRM_posterior_long <- pivot_longer(sim_modRM_posterior, 
                                        cols = everything(), 
                                        names_to = "Parameter", 
                                        values_to = "Estimate")
sim_modRME_posterior_long <- pivot_longer(sim_modRME_posterior, 
                                        cols = everything(), 
                                        names_to = "Parameter", 
                                        values_to = "Estimate")

#Rename parameters to 'Intercept', 'MASQ', 'EDAQ', and 'sigma':
sim_modRM_posterior_long$Parameter <- recode(sim_modRM_posterior_long$Parameter,
                                            "b_Intercept" = "Intercept",
                                            "b_MASQ" = "MASQ", 
                                            "b_neurotypeNT" = "neurotypeNT",
                                            "b_EDAQ" = "EDAQ", 
                                            "b_MASQ.neurotypeNT" = "MASQ:neurotypeNT", 
                                            "b_neurotypeNT.EDAQ" = "neurotypeNT:EDAQ", 
                                            "sigma" = "Sigma")
sim_modRME_posterior_long$Parameter <- recode(sim_modRME_posterior_long$Parameter,
                                            "b_Intercept" = "Intercept",
                                            "b_MASQ" = "MASQ", 
                                            "b_neurotypeNT" = "neurotypeNT",
                                            "b_EDAQ" = "EDAQ", 
                                            "b_MASQ.neurotypeNT" = "MASQ:neurotypeNT", 
                                            "b_neurotypeNT.EDAQ" = "neurotypeNT:EDAQ", 
                                            "sigma" = "Sigma")

#Extract group information from parameter names:
sim_modRM_posterior_long$Group <- sub(":.*", "", sim_modRM_posterior_long$Parameter)
sim_modRME_posterior_long$Group <- sub(":.*", "", sim_modRME_posterior_long$Parameter)

#Reorder the parameters and flip the order:
sim_modRM_posterior_long$Parameter <- factor(sim_modRM_posterior_long$Parameter, 
                                            levels = rev(c("Intercept","MASQ","neurotypeNT","MASQ:neurotypeNT","Sigma")))
sim_modRME_posterior_long$Parameter <- factor(sim_modRME_posterior_long$Parameter, 
                                            levels = rev(c("Intercept","MASQ","neurotypeNT","EDAQ","MASQ:neurotypeNT","neurotypeNT:EDAQ","Sigma")))

#Plot marginal posterior distributions with specified colors:
plot_title <- ggtitle("Posterior distributions",
                      subtitle = "with means and 95% HDI")

ggplot(sim_modRM_posterior_long, aes(x = Estimate, y = Parameter, fill = neurotype)) +
  stat_halfeye(point_interval = mean_hdi, .width = c(0.95), size = 0.5, , height = 3, fill = "#9ED4D1") +  # Adjusting the size of the points
  #scale_fill_manual(values = colors) +
  labs(x = "Parameter estimates", y = "Parameters", fill = "Neurotype") +
  plot_title +
  theme_minimal() +  # Using theme_minimal() instead of theme_clean()
  theme(legend.position = "right",
        panel.grid.major = element_blank(),  # Remove major grid lines
        panel.grid.minor = element_blank(),  # Remove minor grid lines
        axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14),
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 12),
    plot.title = element_text(size = 16),
    legend.title = element_text(size = 14),
    legend.text = element_text(size = 12)) +  # Increase font size of axis titles) +  # Add a single line at 0 on the x-axis
  geom_vline(xintercept = 0, linetype = "dashed")  # Add a dashed line at x = 0

ggplot(sim_modRME_posterior_long, aes(x = Estimate, y = Parameter, fill = neurotype)) +
  stat_halfeye(point_interval = mean_hdi, .width = c(0.95), size = 0.5, , height = 3, fill = "#9ED4D1") +  # Adjusting the size of the points
  #scale_fill_manual(values = colors) +
  labs(x = "Parameter estimates", y = "Parameters", fill = "Neurotype") +
  plot_title +
  theme_minimal() +  # Using theme_minimal() instead of theme_clean()
  theme(legend.position = "right",
        panel.grid.major = element_blank(),  # Remove major grid lines
        panel.grid.minor = element_blank(),  # Remove minor grid lines
        axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14),
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 12),
    plot.title = element_text(size = 16),
    legend.title = element_text(size = 14),
    legend.text = element_text(size = 12)) +  # Increase font size of axis titles) +  # Add a single line at 0 on the x-axis
  geom_vline(xintercept = 0, linetype = "dashed")  # Add a dashed line at x = 0
```

Finally, extract predicted RLLR values:

```{r}
#First, extract predicted values:
sim_modRM_preds <- data.frame(fitted(sim_modRM))
sim_modRME_preds <- data.frame(fitted(sim_modRME))

#As above, to visualise later, save to .csv:
write.table(sim_modRM_preds, file="sim_modRM_preds.csv",sep=",",row.names=F)
write.table(sim_modRME_preds, file="sim_modRME_preds.csv",sep=",",row.names=F)
```

Visualise model-predicted RLLR values for MASQ and EDA-QA scores and their interaction with neurotype:

```{r}
#Read in saved data file:
sim_data <- read.csv("Sim_Data.csv")

#Prepare and standardise variables:
data <- sim_data %>%
  mutate(
    EDAQ = standardize(EDAQ),
    MASQ = standardize(MASQ),
    RLLR = standardize(RLLR),
    perseveration = standardize(perseveration),
    regression = standardize(regression),
    loseShift = standardize(loseShift)
  ) %>%
  select(id, EDAQ, MASQ, RLLR, loseShift, perseveration, regression, neurotype) %>%
  distinct()

#Load the model output from a file:
sim_modRM <- readRDS("sim_modRM_output.rds")
sim_modRME <- readRDS("sim_modRME_output.rds")

#Extract conditional effects:
ce_RM <- conditional_effects(sim_modRM)
ce_RME <- conditional_effects(sim_modRME)

#Convert the specific effect to a data frames:
ce_RM_MASQ <- as.data.frame(ce_RM$`MASQ:neurotype`)
ce_RME_MASQ <- as.data.frame(ce_RME$`MASQ:neurotype`)
ce_RME_EDAQ <- as.data.frame(ce_RME$`EDAQ:neurotype`)

#Select relevant columns:
ce_RM_MASQ <- ce_RM_MASQ %>% 
  select(MASQ, neurotype, estimate__, lower__, upper__)
ce_RME_MASQ <- ce_RME_MASQ %>% 
  select(MASQ, neurotype, estimate__, lower__, upper__)
ce_RME_EDAQ <- ce_RME_EDAQ %>% 
  select(EDAQ, neurotype, estimate__, lower__, upper__)

#Plot for MASQ for sim_modRM:
ggplot(ce_RM_MASQ, aes(x = MASQ, y = estimate__, color = neurotype)) +
  geom_point(data = data, aes(x = MASQ, y = RLLR, color = neurotype)) +
  geom_line(aes(y = estimate__),size = 1) +  # Line for estimated effects
  geom_ribbon(aes(ymin = lower__, ymax = upper__, fill = neurotype), alpha = 0.3, color = NA) +  # Ribbons for uncertainty
  theme_minimal() +  # Use a minimal theme
  labs(title = "Effect Of MASQ Scores On Relative Log Learning Rate By Neurotype",
       x = "MASQ",
       y = "Estimated Effect") +
  scale_color_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) +
  scale_fill_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) 

#Plot for MASQ for sim_modRME:
RMEplot_masq <- ggplot(ce_RME_MASQ, aes(x = MASQ, y = estimate__, color = neurotype)) +
  geom_point(data = data, aes(x = MASQ, y = RLLR, color = neurotype)) +
  geom_line(aes(y = estimate__),size = 1) +  # Line for estimated effects
  geom_ribbon(aes(ymin = lower__, ymax = upper__, fill = neurotype), alpha = 0.3, color = NA) +  # Ribbons for uncertainty
  theme_minimal() +  # Use a minimal theme
  labs(x = "MASQ",
       y = "Estimated Effect") +
  scale_color_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) +
  scale_fill_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) 

#Plot for EDAQ for sim_modRME:
RMEplot_edaq <- ggplot(ce_RME_EDAQ, aes(x = EDAQ, y = estimate__, color = neurotype)) +
  geom_point(data = data, aes(x = EDAQ, y = RLLR, color = neurotype)) +
  geom_line(aes(y = estimate__),size = 1) +  # Line for estimated effects
  geom_ribbon(aes(ymin = lower__, ymax = upper__, fill = neurotype), alpha = 0.3, color = NA) +  # Ribbons for uncertainty
  theme_minimal() +  # Use a minimal theme
  labs(x = "EDAQ",
       y = "") +
  scale_color_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) +
  scale_fill_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) 

#Combine the plots:
(RMEplot_masq + RMEplot_edaq) + plot_annotation(title = "Effect Of MASQ And EDAQ Scores Relative Log Learning Rate By Neurotype")
```

The plot above depicts the estimated effect of MASQ and EDA-QA scores on relative log learning rate. Here, we expect that 1) relative log learning rates (i.e., log(LR in volatile block) - log(LR in stable block)) will be smaller in the ASC group compared to the NT group, 2) anxiety and PDA will be negatively associated with relative log learning rate., and 3) relative log learning rates for the ASC group will be similar irrespective of anxiety or PDA. Once again, these assumptions built into our simulated data are evident in our model's predictive output suggesting that our model fits our simulated data well.

# Prior predictive checks

"A prior predictive check displays simulated data that are generated from parameter values in the prior distribution. The simulated data from the mathematically specified prior should show trends that match the trends assumed by prior knowledge" (Kruschke, 2021).

We want to know that our choice of priors accurately represents our assumptions about our parameters. To do this, we can simulate priors from our model and relate them to observed values (in this case, simulated observations).

We have chosen weakly informative priors to begin with - because all of our variables are standardized, we can start with the priors $Normal(0,1)$.

## Behaviour predicted by neurotype, PDA and anxiety

### Lose-shift behaviour

We use our simulated data to model lose-shift predicted by MASQ and EDA-QA scores:

```{r}
#Read in saved data file:
sim_data <- read.csv("Sim_Data.csv")

#Prepare and standardise variables:
data <- sim_data %>%
  mutate(
    EDAQ = standardize(EDAQ),
    MASQ = standardize(MASQ),
    RLLR = standardize(RLLR),
    perseveration = standardize(perseveration),
    regression = standardize(regression),
    loseShift = standardize(loseShift)
  ) %>%
  select(id, EDAQ, MASQ, RLLR, loseShift, perseveration, regression, neurotype) %>%
  distinct()

#A model with broad priors that acommodate uncertainty pertaining to the relationship between loseShift and MASQ scores by neurotype:
sim_modLSM_prior <- brm(
  loseShift ~ MASQ*neurotype,
  data = data,
  backend = "cmdstan",
  family = gaussian(),
  prior = c(
    prior(normal(0, 1), class = "Intercept"),
    prior(normal(0, 1), class = "b"),
    prior(exponential(1), class = "sigma")),
  sample_prior = "only",
  control = list(adapt_delta = 0.99),
  cores = 4,
  file = "sim_modLSM_prior_output.rds"
  )

#A model with broad priors that acommodate uncertainty pertaining to the relationship between loseShift and MASQ and EDA-QA scores by neurotype:
sim_modLSME_prior <- brm(
  loseShift ~ MASQ*neurotype + EDAQ*neurotype,
  data = data,
  backend = "cmdstan",
  family = gaussian(),
  prior = c(
    prior(normal(0, 1), class = "Intercept"),
    prior(normal(0, 1), class = "b"),
    prior(exponential(1), class = "sigma")),
  sample_prior = "only",
  control = list(adapt_delta = 0.99),
  cores = 4,
  file = "sim_modLSME_prior_output.rds"
  )
```

We can inspect the output here:

```{r}
#Load the model output from a file:
sim_modLSM_prior <- readRDS("sim_modLSM_prior_output.rds")
sim_modLSME_prior <- readRDS("sim_modLSME_prior_output.rds")

#Return model output:
summary(sim_modLSM_prior)
summary(sim_modLSME_prior)
```

Draw samples from the prior predictive simulation above and plot against our simulated data:

```{r}
#Run a prior predictive check that compares the distribution of prior predicted values to the distribution of observed (in this case, simulated) values:
pp_check(sim_modLSM_prior, ndraws = 100) + ggtitle("Prior Predictive Check Plot for loseShift ~ MASQ*neurotype")
pp_check(sim_modLSME_prior, ndraws = 100) + ggtitle("Prior Predictive Check Plot for loseShift ~ MASQ*neurotype + EDAQ*neurotype")
```

The 'y' line represents the distribution of our observed (in this case, simulated) data, while the 'y_rep' lines represent the distribution of data simulated from the model (based on a 100 draws from the prior distribution of the model parameters). Both distributions appear to be a mixture of Gaussian distributions and centered around 0. Importantly, they overlap each other, which suggests that model predictions are consistent with the observed data.

### Perseverative behaviour

We use our simulated data to model perseveration predicted by MASQ and EDA-QA scores:

```{r}
#Read in saved data file:
sim_data <- read.csv("Sim_Data.csv")

#Prepare and standardise variables:
data <- sim_data %>%
  mutate(
    EDAQ = standardize(EDAQ),
    MASQ = standardize(MASQ),
    RLLR = standardize(RLLR),
    perseveration = standardize(perseveration),
    regression = standardize(regression),
    loseShift = standardize(loseShift)
  ) %>%
  select(id, EDAQ, MASQ, RLLR, loseShift, perseveration, regression, neurotype) %>%
  distinct()

#A model with broad priors that acommodate uncertainty pertaining to the relationship between perseveration and MASQ scores by neurotype:
sim_modPM_prior <- brm(
  perseveration ~ MASQ*neurotype,
  data = data,
  backend = "cmdstan",
  family = gaussian(),
  prior = c(
    prior(normal(0, 1), class = "Intercept"),
    prior(normal(0, 1), class = "b"),
    prior(exponential(1), class = "sigma")),
  sample_prior = "only",
  control = list(adapt_delta = 0.99),
  cores = 4,
  file = "sim_modPM_prior_output.rds"
  )

#A model with broad priors that acommodate uncertainty pertaining to the relationship between perseveration and MASQ and EDA-QA scores by neurotype:
sim_modPME_prior <- brm(
  perseveration ~ MASQ*neurotype + EDAQ*neurotype,
  data = data,
  backend = "cmdstan",
  family = gaussian(),
  prior = c(
    prior(normal(0, 1), class = "Intercept"),
    prior(normal(0, 1), class = "b"),
    prior(exponential(1), class = "sigma")),
  sample_prior = "only",
  control = list(adapt_delta = 0.99),
  cores = 4,
  file = "sim_modPME_prior_output.rds"
  )
```

We can inspect the output here:

```{r}
#Load the model output from a file:
sim_modPM_prior <- readRDS("sim_modPM_prior_output.rds")
sim_modPME_prior <- readRDS("sim_modPME_prior_output.rds")

#Return model output:
summary(sim_modPM_prior)
summary(sim_modPME_prior)
```

Draw samples from the prior predictive simulation above and plot against our simulated data:

```{r}
#Run a prior predictive check that compares the distribution of prior predicted values to the distribution of observed (in this case, simulated) values:
pp_check(sim_modPM_prior, ndraws = 100) + ggtitle("Prior Predictive Check Plot for perseveration ~ MASQ*neurotype")
pp_check(sim_modPME_prior, ndraws = 100) + ggtitle("Prior Predictive Check Plot for perseveration ~ MASQ*neurotype + EDAQ*neurotype")
```

Again, the 'y' line represents the distribution of our observed (in this case, simulated) data, while the 'y_rep' lines represent the distribution of data simulated from the model (based on a 100 draws from the prior distribution of the model parameters). Both distributions appear to be a mixture of Gaussian distributions and centered around 0. Importantly, they overlap each other, which suggests that model predictions are consistent with the observed data.

### Regressive behaviour

We use our simulated data to model regression predicted by MASQ and EDA-QA scores:

```{r}
#Read in saved data file:
sim_data <- read.csv("Sim_Data.csv")

#Prepare and standardise variables:
data <- sim_data %>%
  mutate(
    EDAQ = standardize(EDAQ),
    MASQ = standardize(MASQ),
    RLLR = standardize(RLLR),
    perseveration = standardize(perseveration),
    regression = standardize(regression),
    loseShift = standardize(loseShift)
  ) %>%
  select(id, EDAQ, MASQ, RLLR, loseShift, perseveration, regression, neurotype) %>%
  distinct()

#A model with broad priors that acommodate uncertainty pertaining to the relationship between regression and MASQ scores by neurotype:
sim_modReM_prior <- brm(
  regression ~ MASQ*neurotype,
  data = data,
  backend = "cmdstan",
  family = gaussian(),
  prior = c(
    prior(normal(0, 1), class = "Intercept"),
    prior(normal(0, 1), class = "b"),
    prior(exponential(1), class = "sigma")),
  sample_prior = "only",
  control = list(adapt_delta = 0.99),
  cores = 4,
  file = "sim_modReM_prior_output.rds"
  )

#A model with broad priors that acommodate uncertainty pertaining to the relationship between regression and MASQ and EDA-QA scores by neurotype:
sim_modReME_prior <- brm(
  regression ~ MASQ*neurotype + EDAQ*neurotype,
  data = data,
  backend = "cmdstan",
  family = gaussian(),
  prior = c(
    prior(normal(0, 1), class = "Intercept"),
    prior(normal(0, 1), class = "b"),
    prior(exponential(1), class = "sigma")),
  sample_prior = "only",
  control = list(adapt_delta = 0.99),
  cores = 4,
  file = "sim_modReME_prior_output.rds"
  )
```

We can inspect the output here:

```{r}
#Load the model output from a file:
sim_modReM_prior <- readRDS("sim_modReM_prior_output.rds")
sim_modReME_prior <- readRDS("sim_modReME_prior_output.rds")

#Return model output:
summary(sim_modReM_prior)
summary(sim_modReME_prior)
```

Draw samples from the prior predictive simulation above and plot against our simulated data:

```{r}
#Run a prior predictive check that compares the distribution of prior predicted values to the distribution of observed (in this case, simulated) values:
pp_check(sim_modReM_prior, ndraws = 100) + ggtitle("Prior Predictive Check Plot for regression ~ MASQ*neurotype")
pp_check(sim_modReME_prior, ndraws = 100) + ggtitle("Prior Predictive Check Plot for regression ~ MASQ*neurotype + EDAQ*neurotype")
```

Again, the 'y' line represents the distribution of our observed (in this case, simulated) data, while the 'y_rep' lines represent the distribution of data simulated from the model (based on a 100 draws from the prior distribution of the model parameters). Both distributions appear to be a mixture of Gaussian distributions and centered around 0. Importantly, they overlap each other, which suggests that model predictions are consistent with the observed data.

## Learning rate predicted by neurotype, PDA and anxiety

### Effect of block order on RLLR

We use our simulated data to model RLLR predicted by blockorder:

```{r}
#Read in saved data file:
sim_data <- read.csv("Sim_Data.csv")

#Prepare and standardise variables:
data <- sim_data %>%
  mutate(
    EDAQ = standardize(EDAQ),
    MASQ = standardize(MASQ),
    RLLR = standardize(RLLR),
    perseveration = standardize(perseveration),
    regression = standardize(regression),
    loseShift = standardize(loseShift)
  ) %>%
  select(id, EDAQ, MASQ, RLLR, loseShift, perseveration, regression, neurotype, blockorder) %>%
  distinct()

#A model with broad priors that acommodate uncertainty pertaining to the relationship between RLLR and MASQ scores by neurotype:
sim_modRB_prior <- brm(
  RLLR ~ blockorder:neurotype,
  data = data,
  backend = "cmdstan",
  family = gaussian(),
  prior = c(
    prior(normal(0, 0.5), class = "Intercept"),
    prior(normal(0, 0.5), class = "b"),
    prior(exponential(1), class = "sigma")),
  sample_prior = "only",
  control = list(adapt_delta = 0.99),
  cores = 4,
  file = "sim_modRB_prior_output.rds"
  )
```

We can inspect the output here:

```{r}
#Load the model output from a file:
sim_modRB_prior <- readRDS("sim_modRB_prior_output.rds")

#Return model output:
summary(sim_modRB_prior)
```

Draw samples from the prior predictive simulation above and plot against our simulated data:

```{r}
#Run a prior predictive check that compares the distribution of prior predicted values to the distribution of observed (in this case, simulated) values:
pp_check(sim_modRB_prior, ndraws = 100) + ggtitle("Prior Predictive Check Plot for RLLR ~ blockorder:neurotype")
```

Again, the 'y' line represents the distribution of our observed (in this case, simulated) data, while the 'y_rep' lines represent the distribution of data simulated from the model (based on a 100 draws from the prior distribution of the model parameters). Both distributions appear to be a mixture of Gaussian distributions centered around 0. Importantly, they overlap each other, which suggests that model predictions are consistent with the observed data.

### Effect of EDA-QA and MASQ on RLLR

We use our simulated data to model RLLR predicted by MASQ and EDA-QA scores:

```{r}
#Read in saved data file:
sim_data <- read.csv("Sim_Data.csv")

#Prepare and standardise variables:
data <- sim_data %>%
  mutate(
    EDAQ = standardize(EDAQ),
    MASQ = standardize(MASQ),
    RLLR = standardize(RLLR),
    perseveration = standardize(perseveration),
    regression = standardize(regression),
    loseShift = standardize(loseShift)
  ) %>%
  select(id, EDAQ, MASQ, RLLR, loseShift, perseveration, regression, neurotype) %>%
  distinct()

#A model with broad priors that acommodate uncertainty pertaining to the relationship between RLLR and MASQ scores by neurotype:
sim_modRM_prior <- brm(
  RLLR ~ MASQ*neurotype,
  data = data,
  backend = "cmdstan",
  family = gaussian(),
  prior = c(
    prior(normal(0, 1), class = "Intercept"),
    prior(normal(0, 1), class = "b"),
    prior(exponential(1), class = "sigma")),
  sample_prior = "only",
  control = list(adapt_delta = 0.99),
  cores = 4,
  file = "sim_modRM_prior_output.rds"
  )

#A model with broad priors that acommodate uncertainty pertaining to the relationship between RLLR and MASQ and EDA-QA scores by neurotype:
sim_modRME_prior <- brm(
  RLLR ~ MASQ*neurotype + EDAQ*neurotype,
  data = data,
  backend = "cmdstan",
  family = gaussian(),
  prior = c(
    prior(normal(0, 1), class = "Intercept"),
    prior(normal(0, 1), class = "b"),
    prior(exponential(1), class = "sigma")),
  sample_prior = "only",
  control = list(adapt_delta = 0.99),
  cores = 4,
  file = "sim_modRME_prior_output.rds"
  )
```

We can inspect the output here:

```{r}
#Load the model output from a file:
sim_modRM_prior <- readRDS("sim_modRM_prior_output.rds")
sim_modRME_prior <- readRDS("sim_modRME_prior_output.rds")

#Return model output:
summary(sim_modRM_prior)
summary(sim_modRME_prior)
```

Draw samples from the prior predictive simulation above and plot against our simulated data:

```{r}
#Run a prior predictive check that compares the distribution of prior predicted values to the distribution of observed (in this case, simulated) values:
pp_check(sim_modRM_prior, ndraws = 100) + ggtitle("Prior Predictive Check Plot for RLLR ~ MASQ*neurotype")
pp_check(sim_modRME_prior, ndraws = 100) + ggtitle("Prior Predictive Check Plot for RLLR ~ MASQ*neurotype + EDAQ*neurotype")
```

Again, the 'y' line represents the distribution of our observed (in this case, simulated) data, while the 'y_rep' lines represent the distribution of data simulated from the model (based on a 100 draws from the prior distribution of the model parameters). Both distributions for both models appear to be a mixture of Gaussian distributions centered around 0. Importantly, they overlap each other, which suggests that model predictions are consistent with the observed data.

# Computation and posterior distribution

## Details of the computation

All computations to derive posterior distributions for all three models were conducted using the brms() package (source details available in Package install_20.05.24.r- see packages and libraries); this includes ˆR and effective sample size (ESS).

Again, chapter 12 of the following webpage provides some useful guidance on how brms() models are specified: [Chapter 12 Bayesian estimation with brms \| An R companion to Statistics: data analysis and modelling (mspeekenbrink.github.io)](https://mspeekenbrink.github.io/sdam-r-companion/bayesian-estimation-with-brms.html)

We must check that the MCMC chains for every parameter have converged and are long enough to provide stable estimates.

Convergence here is indicated by ˆR, which must be near 1.0 to indicate convergence. When ˆR is above 1.00, it usually indicates that the chain has not yet converged, and probably you shouldn't trust the samples.

The effective length of an MCMC chain is indicated by the effective sample size (ESS), which refers to the sample size of the MCMC chain not to the sample size of the data. When n_eff is much lower than the actual number of iterations (minus warm-up) of your chains, it means the chains are inefficient, but possibly still okay.

### Behaviour predicted by neurotype, PDA and anxiety

#### Lose-shift behaviour

And again for lose-shift behaviours predicted by MASQ and EDA-QA scores by neurotype:

```{r}
#Load the model output from file:
sim_modLSM <- readRDS("sim_modLSM_output.rds")
sim_modLSME <- readRDS("sim_modLSME_output.rds")

#Return model output:
summary(sim_modLSM)
summary(sim_modLSME)

#We can also get model parameters:
get_prior(sim_modLSM)
get_prior(sim_modLSME)
```

ˆR and n_eff (ESS) look ok; ˆR is 1 for each parameter, and n_eff is \> than the actual number of iterations (minus warm-up) of the chain.

We can also inspect the MCMC with a trace plot.

```{r}
#Generate trace plots for each model:
mcmc_trace(sim_modLSM)
mcmc_trace(sim_modLSME)
```

Again, all chains look good.

#### Perseverative behaviour

And again for perseverative behaviours predicted by MASQ and EDA-QA scores by neurotype:

```{r}
#Load the model output from file:
sim_modPM <- readRDS("sim_modPM_output.rds")
sim_modPME <- readRDS("sim_modPME_output.rds")

#Return model output:
summary(sim_modPM)
summary(sim_modPME)

#We can also get model parameters:
get_prior(sim_modPM)
get_prior(sim_modPME)
```

ˆR and n_eff (ESS) look ok; ˆR is 1 for each parameter, and n_eff is \> than the actual number of iterations (minus warm-up) of the chain.

We can also inspect the MCMC with a trace plot.

```{r}
#Generate trace plots for each model:
mcmc_trace(sim_modPM)
mcmc_trace(sim_modPME)
```

Again, all chains look good.

#### Regerssive behaviour

And again for regressive behaviours predicted by MASQ and EDA-QA scores by neurotype:

```{r}
#Load the model output from file:
sim_modReM <- readRDS("sim_modReM_output.rds")
sim_modReME <- readRDS("sim_modReME_output.rds")

#Return model output:
summary(sim_modReM)
summary(sim_modReME)

#We can also get model parameters:
get_prior(sim_modReM)
get_prior(sim_modReME)
```

ˆR and n_eff (ESS) look ok; ˆR is 1 for each parameter, and n_eff is \> than the actual number of iterations (minus warm-up) of the chain.

We can also inspect the MCMC with a trace plot.

```{r}
#Generate trace plots for each model:
mcmc_trace(sim_modReM)
mcmc_trace(sim_modReME)
```

Again, all chains look good.

### Learning rate predicted by neurotype, PDA and anxiety

#### Effect of block order on RLLR

And finally for RLLR predicted by blockorder by neurotype:

```{r}
#Load the model output from a file:
sim_modRB <- readRDS("sim_modRB_output.rds")

#Return model output:
summary(sim_modRB)

#We can also get model parameters:
get_prior(sim_modRB)
```

For both models, ˆR and n_eff (ESS) look ok; ˆR is 1 for each parameter, and n_eff is \> than the actual number of iterations (minus warm-up) of the chain.

We can also inspect the MCMC with a trace plot.

```{r}
#Generate trace plots for each model:
mcmc_trace(sim_modRB)
```

Again, all chains look good.

#### Effect of EDA-QA and MASQ on RLLR

And finally for RLLR predicted by MASQ and EDA-QA scores by neurotype:

```{r}
#Load the model output from a file:
sim_modRM <- readRDS("sim_modRM_output.rds")
sim_modRME <- readRDS("sim_modRME_output.rds")

#Return model output:
summary(sim_modRM)
summary(sim_modRME)

#We can also get model parameters:
get_prior(sim_modRM)
get_prior(sim_modRME)
```

For both models, ˆR and n_eff (ESS) look ok; ˆR is 1 for each parameter, and n_eff is \> than the actual number of iterations (minus warm-up) of the chain.

We can also inspect the MCMC with a trace plot.

```{r}
#Generate trace plots for each model:
mcmc_trace(sim_modRM)
mcmc_trace(sim_modRME)
```

Again, for both models, all chains look good.

## Posterior predictive check

### Behaviour predicted by neurotype, PDA and anxiety

#### Lose-shift behaviour

Below we view the posterior predictions plotted against our (simulated) data for lose-shift predicted by MASQ and EDA-QA scores.

```{r}
#Perform a graphical posterior predictive check for both models:
pp_check(sim_modLSM, ndraws = 100) + ggtitle("Posterior Predictive Check Plot for loseShift ~ MASQ*neurotype")
pp_check(sim_modLSME, ndraws = 100) + ggtitle("Posterior Predictive Check Plot for loseShift ~ MASQ*neurotype + EDAQ*neurotype")
```

As with out prior predictive checks, the 'y' line of the pp_check output represents the distribution of our observed (in this case, simulated) data, while the 'y_rep' lines represent the distribution of data simulated from the model (based on a 100 draws from the posterior distribution of the model parameters). For both models, both distributions appear to be a mixture of Gaussian distributions centered around 0. Importantly, they closely overlap each other, which suggests that model predictions are consistent with the observed data.

#### Perseverative behaviour

Below we view the posterior predictions plotted against our (simulated) data for perseveration predicted by MASQ and EDA-QA scores.

```{r}
#Perform a graphical posterior predictive check for both models:
pp_check(sim_modPM, ndraws = 100) + ggtitle("Posterior Predictive Check Plot for perseveration ~ MASQ*neurotype")
pp_check(sim_modPME, ndraws = 100) + ggtitle("Posterior Predictive Check Plot for perseveration ~ MASQ*neurotype + EDAQ*neurotype")
```

For both models, both distributions appear to be a mixture of Gaussian distributions centered around 0. Importantly, they closely overlap each other, which suggests that model predictions are consistent with the observed data.

#### Regressive behaviour

Below we view the posterior predictions plotted against our (simulated) data for regression predicted by MASQ and EDA-QA scores.

```{r}
#Perform a graphical posterior predictive check for both models:
pp_check(sim_modReM, ndraws = 100) + ggtitle("Posterior Predictive Check Plot for regression ~ MASQ*neurotype")
pp_check(sim_modReME, ndraws = 100) + ggtitle("Posterior Predictive Check Plot for regression ~ MASQ*neurotype + EDAQ*neurotype")
```

For both models, both distributions appear to be a mixture of Gaussian distributions centered around 0. Importantly, they closely overlap each other, which suggests that model predictions are consistent with the observed data.

### Learning rate predicted by neurotype, PDA and anxiety

#### Effect of block order on RLLR

Below we view the posterior predictions plotted against our (simulated) data for RLLR predicted by blockorder.

```{r}
#Perform a graphical posterior predictive check for both models:
pp_check(sim_modRB, ndraws = 100) + ggtitle("Posterior Predictive Check Plot for RLLR ~ blockorder:neurotype")
```

For both distributions appear a mixture of Gaussian distributions centered around 0. Importantly, they closely overlap each other, which suggests that model predictions are consistent with the observed data.

#### Effect of EDA-QA and MASQ on RLLR

Below we view the posterior predictions plotted against our (simulated) data for RLLR predicted by MASQ and EDA-QA scores.

```{r}
#Perform a graphical posterior predictive check for both models:
pp_check(sim_modRM, ndraws = 100) + ggtitle("Posterior Predictive Check Plot for RLLR ~ MASQ*neurotype")
pp_check(sim_modRME, ndraws = 100) + ggtitle("Posterior Predictive Check Plot for RLLR ~ MASQ*neurotype + EDAQ*neurotype")
```

For both models, both distributions appear a mixture of Gaussian distributions centered around 0. Importantly, they closely overlap each other, which suggests that model predictions are consistent with the observed data.

Note: in an attempt to find the best modelling approach to recovering our simulated parameters, we also used a Gaussian mixture model (GMM). Both GMM and interaction (i.e., the models described above) approaches produced similar prior and posterior predictive fits. However, the interaction models were computationally lighter. Also model comparisons between GMM and interaction models suggested that the interaction models fit the data better.

## Marginal posterior distribution

### Behaviour predicted by neurotype, PDA and anxiety

#### Lose-shift behaviour

Again, we can inspect the output for lose-shift values for MASQ and EDA-QA scores and their interaction with neurotype, this time we will consider the marginal posterior distribution of each parameter (central tendency and credible intervals):

```{r}
#Extract posterior samples:
sim_modLSM_posterior <- posterior_samples(sim_modLSM)
sim_modLSME_posterior <- posterior_samples(sim_modLSME)


#Filter out 'lprior' and 'lp__':
sim_modLSM_posterior <- sim_modLSM_posterior[, c("b_Intercept", "b_MASQ", "b_neurotypeNT", "b_MASQ:neurotypeNT", "sigma")]
sim_modLSME_posterior <- sim_modLSME_posterior[, c("b_Intercept", "b_MASQ", "b_neurotypeNT","b_EDAQ", "b_MASQ:neurotypeNT", "b_neurotypeNT:EDAQ", "sigma")]

#Convert the data frame to long format:
sim_modLSM_posterior_long <- pivot_longer(sim_modLSM_posterior, 
                                        cols = everything(), 
                                        names_to = "Parameter", 
                                        values_to = "Estimate")
sim_modLSME_posterior_long <- pivot_longer(sim_modLSME_posterior, 
                                        cols = everything(), 
                                        names_to = "Parameter", 
                                        values_to = "Estimate")

#Rename parameters to 'Intercept', 'MASQ', 'EDAQ', and 'sigma':
sim_modLSM_posterior_long$Parameter <- recode(sim_modLSM_posterior_long$Parameter,
                                            "b_Intercept" = "Intercept",
                                            "b_MASQ" = "MASQ", 
                                            "b_neurotypeNT" = "neurotypeNT",
                                            "b_EDAQ" = "EDAQ", 
                                            "b_MASQ:neurotypeNT" = "MASQ:neurotypeNT", 
                                            "b_neurotypeNT.EDAQ" = "neurotypeNT:EDAQ", 
                                            "sigma" = "Sigma")
sim_modLSME_posterior_long$Parameter <- recode(sim_modLSME_posterior_long$Parameter,
                                            "b_Intercept" = "Intercept",
                                            "b_MASQ" = "MASQ", 
                                            "b_neurotypeNT" = "neurotypeNT",
                                            "b_EDAQ" = "EDAQ", 
                                            "b_MASQ:neurotypeNT" = "MASQ:neurotypeNT", 
                                            "b_neurotypeNT:EDAQ" = "neurotypeNT:EDAQ", 
                                            "sigma" = "Sigma")

#Extract group information from parameter names:
sim_modLSM_posterior_long$Group <- sub(":.*", "", sim_modLSM_posterior_long$Parameter)
sim_modLSME_posterior_long$Group <- sub(":.*", "", sim_modLSME_posterior_long$Parameter)

#Reorder the parameters and flip the order:
sim_modLSM_posterior_long$Parameter <- factor(sim_modLSM_posterior_long$Parameter, 
                                            levels = rev(c("Intercept","MASQ","neurotypeNT","MASQ:neurotypeNT","Sigma")))
sim_modLSME_posterior_long$Parameter <- factor(sim_modLSME_posterior_long$Parameter, 
                                            levels = rev(c("Intercept","MASQ","neurotypeNT","EDAQ","MASQ:neurotypeNT","neurotypeNT:EDAQ","Sigma")))

#Plot marginal posterior distributions with specified colors:
plot_title <- ggtitle("Posterior distributions",
                      subtitle = "with means and 95% HDI")

ggplot(sim_modLSM_posterior_long, aes(x = Estimate, y = Parameter, fill = neurotype)) +
  stat_halfeye(point_interval = mean_hdi, .width = c(0.95), size = 0.5, , height = 3, fill = "#9ED4D1") +  # Adjusting the size of the points
  #scale_fill_manual(values = colors) +
  labs(x = "Parameter estimates", y = "Parameters", fill = "Neurotype") +
  plot_title +
  theme_minimal() +  # Using theme_minimal() instead of theme_clean()
  theme(legend.position = "right",
        panel.grid.major = element_blank(),  # Remove major grid lines
        panel.grid.minor = element_blank(),  # Remove minor grid lines
        axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14),
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 12),
    plot.title = element_text(size = 16),
    legend.title = element_text(size = 14),
    legend.text = element_text(size = 12)) +  # Increase font size of axis titles) +  # Add a single line at 0 on the x-axis
  geom_vline(xintercept = 0, linetype = "dashed")  # Add a dashed line at x = 0

ggplot(sim_modLSME_posterior_long, aes(x = Estimate, y = Parameter, fill = neurotype)) +
  stat_halfeye(point_interval = mean_hdi, .width = c(0.95), size = 0.5, , height = 3, fill = "#9ED4D1") +  # Adjusting the size of the points
  #scale_fill_manual(values = colors) +
  labs(x = "Parameter estimates", y = "Parameters", fill = "Neurotype") +
  plot_title +
  theme_minimal() +  # Using theme_minimal() instead of theme_clean()
  theme(legend.position = "right",
        panel.grid.major = element_blank(),  # Remove major grid lines
        panel.grid.minor = element_blank(),  # Remove minor grid lines
        axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14),
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 12),
    plot.title = element_text(size = 16),
    legend.title = element_text(size = 14),
    legend.text = element_text(size = 12)) +  # Increase font size of axis titles) +  # Add a single line at 0 on the x-axis
  geom_vline(xintercept = 0, linetype = "dashed")  # Add a dashed line at x = 0
```

For the first model, loseShift \~ MASQ\*neurotype:

-   **Intercept**: This is the estimated baseline value of `loseShift` when all other predictors are zero. The distribution is centered below 1 with narrow HDI, suggesting a strong baseline level of `loseShift`.

-   **MASQ and neurotypeNT**: These represent the effects of `MASQ` and `neurotypeNT` on `loseShift` , respectively. `MASQ` has a distribution centered just around 0, and a narrow HDI - this suggests the model is certain that `MASQ` has no effect on `loseShift`. `neurotypeNT` has a distribution centered below -1, and HDI far from 0 - `neurotypeNT` has a strong negative effect on `loseShift`- NTs demonstrate fewer lose-shift behaviours than ASC.

-   **MASQ:neurotypeNT**: This is the interaction term, indicating whether the effect of `MASQ` on `loseShift` differs across neurotypes. `MASQ:neurotype` has a distribution centered around 0.5, with HDI far from 0 - this suggests that the effect of `MASQ` on `loseShift` varies by neurotype- anxiety is associated with greater lose-shift behaviours in NT compared to ASC.

-   **Sigma**: This represents the standard deviation of the residuals (the variability not explained by the model). A larger sigma indicates more variability in `RLLR` that isn’t accounted for by the predictors - here the distribution for sigma sits above 0 with very narrow HDI - much of the variance in `loseShift` is being captured by the model.

For the second model, loseShift \~ MASQ\*neurotype + EDAQ\*neurotype:

-   **Intercept**: This is the estimated baseline value of `loseShift` when all other predictors are zero. The distribution is centered above 0.5 with narrow HDI, suggesting a strong baseline level of loseShift.

-   **MASQ, neurotypeNT, and EDAQ**: These represent the effects of `MASQ`, `neurotypeNT`, and `EDAQ` on `loseShift`, respectively. `MASQ` has a distribution centered around 0, and HDI overlapping 0, which suggests the model is fairly certain that `MASQ` does not have an effect on `loseShift.``neurotypeNT`has a distribution centered below -1, and narrow HDI, indicating strong negative effect of `neurotypeNT`on `loseShift.`- NTs demonstrate fewer lose-shift behaviours than ASC. `EDAQ` has a distribution centered just above 0, and HDI that almost overlap 0 - `EDAQ` is positively associated with `loseShift`, however, we shuld be cautious when interpreting this relationship as the tail of this distribution stills close to 0.

-   **MASQ:neurotypeNT and neurotypeNT:EDAQ**: These are the interaction terms, indicating whether the effect of `MASQ` and `EDAQ` on `loseShift` differs across neurotypes. `MASQ:neurotype` has a distribution centered just below 0.5, with HDI well above 0 - this suggests that the effect of `MASQ` on `loseShift` varies by neurotype. Similarly, `neurotype:EDAQ` has a distribution that sits just above 0.5, with HDI well above 0, indicating that the effect of `EDAQ` on `loseShift` differs across neurotypes- anxiety and PDA are associated with greater lose-shift behaviours in NT compared to ASC.

-   **Sigma**: This represents the standard deviation of the residuals (the variability not explained by the model). A larger sigma indicates more variability in `loseShift` that isn’t accounted for by the predictors - here the distribution for sigma sits above 0 with ver narrow HDI - much of the variance in `loseShift` is being captured by the model.

Visualise model-predicted lose-shift values for MASQ and EDA-QA scores by neurotype:

```{r}
#Read in saved data file:
sim_data <- read.csv("Sim_Data.csv")

#Prepare and standardise variables:
data <- sim_data %>%
  mutate(
    EDAQ = standardize(EDAQ),
    MASQ = standardize(MASQ),
    RLLR = standardize(RLLR),
    perseveration = standardize(perseveration),
    regression = standardize(regression),
    loseShift = standardize(loseShift)
  ) %>%
  select(id, EDAQ, MASQ, RLLR, loseShift, perseveration, regression, neurotype) %>%
  distinct()

#Load the model output from a file:
sim_modLSM <- readRDS("sim_modLSM_output.rds")
sim_modLSME <- readRDS("sim_modLSME_output.rds")

#Extract conditional effects:
ce_LSM <- conditional_effects(sim_modLSM)
ce_LSME <- conditional_effects(sim_modLSME)

#Convert the specific effect to a data frames:
ce_LSM_MASQ <- as.data.frame(ce_LSM$`MASQ:neurotype`)
ce_LSME_MASQ <- as.data.frame(ce_LSME$`MASQ:neurotype`)
ce_LSME_EDAQ <- as.data.frame(ce_LSME$`EDAQ:neurotype`)

#Select relevant columns:
ce_LSM_MASQ <- ce_LSM_MASQ %>% 
  select(MASQ, neurotype, estimate__, lower__, upper__)
ce_LSME_MASQ <- ce_LSME_MASQ %>% 
  select(MASQ, neurotype, estimate__, lower__, upper__)
ce_LSME_EDAQ <- ce_LSME_EDAQ %>% 
  select(EDAQ, neurotype, estimate__, lower__, upper__)

#Plot for MASQ for sim_modRM:
ggplot(ce_LSM_MASQ, aes(x = MASQ, y = estimate__, color = neurotype)) +
  geom_point(data = data, aes(x = MASQ, y = loseShift, color = neurotype)) +
  geom_line(aes(y = estimate__),size = 1) +  # Line for estimated effects
  geom_ribbon(aes(ymin = lower__, ymax = upper__, fill = neurotype), alpha = 0.3, color = NA) +  # Ribbons for uncertainty
  theme_minimal() +  # Use a minimal theme
  labs(title = "Effect Of MASQ Scores On Lose-Shift Behaviour By Neurotype",
       x = "MASQ",
       y = "Estimated Effect") +
  scale_color_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) +
  scale_fill_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) 

#Plot for MASQ for sim_modRME:
LSMEplot_masq <- ggplot(ce_LSME_MASQ, aes(x = MASQ, y = estimate__, color = neurotype)) +
  geom_point(data = data, aes(x = MASQ, y = loseShift, color = neurotype)) +
  geom_line(aes(y = estimate__),size = 1) +  # Line for estimated effects
  geom_ribbon(aes(ymin = lower__, ymax = upper__, fill = neurotype), alpha = 0.3, color = NA) +  # Ribbons for uncertainty
  theme_minimal() +  # Use a minimal theme
  labs(x = "MASQ",
       y = "Estimated Effect") +
  scale_color_manual(values = c("#cc99ff", "#66cccc"),  guide = "none") +
  scale_fill_manual(values = c("#cc99ff", "#66cccc"),  guide = "none") 

#Plot for EDAQ for sim_modRME:
LSMEplot_edaq <- ggplot(ce_LSME_EDAQ, aes(x = EDAQ, y = estimate__, color = neurotype)) +
  geom_point(data = data, aes(x = EDAQ, y = loseShift, color = neurotype)) +
  geom_line(aes(y = estimate__),size = 1) +  # Line for estimated effects
  geom_ribbon(aes(ymin = lower__, ymax = upper__, fill = neurotype), alpha = 0.3, color = NA) +  # Ribbons for uncertainty
  theme_minimal() +  # Use a minimal theme
  labs(x = "EDAQ",
       y = "") +
  scale_color_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) +
  scale_fill_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) 

#Combine the plots:
(LSMEplot_masq + LSMEplot_edaq) + plot_annotation(title = "Effect Of MASQ And EDAQ Scores On Lose-Shift behaviour By Neurotype")
```

The plots above plot regression lines for the model-predicted estimates (with HDI ribbons) over our simulated data. These plots demonstrate that the number of lose-shift behaviours produced by the ASC group do not vary as a function of anxiety (MASQ) and PDA (EDAQ), while for the NT group, the number of lose-shift behaviours are positively associated with both anxiety (MASQ) and PDA (EDAQ). This reflects our assumptions that 1) the number of lose-shift behaviours (i.e., a response switch made after receiving negative feedback, reported as a proportion of total negative feedback trials) to be greater for the ASC group compared to the NT group - this is based on Crawley et al. (2020) and D'Crus et al. (2013). Similarly, 2) the number of lose-shift behaviours will be positively associated with anxiety- this is based on Piray and Daw (2021) theoretical model, as well as findings from Huang et al. (2017) and [Hein et al. (2023)](http://nature.com/articles/s42003-023-04628-1.pdf). 3) the number of lose-shift behaviours produced by the ASC group will be similar irrespective of anxiety - this reflects previous findings that suggest autism is associated with lose-shift behaviours (Crawley et al., 2020; D'Crus et al., 2013). For the NT group, we predict that lose-shift behaviours will be positively associated with anxiety - this is supported by literature that suggests anxiety is associated with more lose-shift behaviours (Huang et al., 2017; [Hein et al. (2023](http://nature.com/articles/s42003-023-04628-1.pdf))*.* We predict a similar pattern of lose-shift behaviours as a function of PDA behaviours such that the number of lose-shift behaviours produced by the ASC group will be similar irrespective of PDA behaviours, while for the NT group, lose-shift behaviours will be positively associated with PDA behaviours - we assume that PDA is underpinned by anxiety and thus, findings that suggest anxiety is associated with more lose-shift behaviours may also apply to PDA.

#### Perseverative behaviour

We can also inspect the output for perseveration values for MASQ and EDA-QA scores and their interaction with neurotype, this time we will consider the marginal posterior distribution of each parameter (central tendency and credible intervals):

```{r}
#Extract posterior samples:
sim_modPM_posterior <- posterior_samples(sim_modPM)
sim_modPME_posterior <- posterior_samples(sim_modPME)


#Filter out 'lprior' and 'lp__':
sim_modPM_posterior <- sim_modPM_posterior[, c("b_Intercept", "b_MASQ", "b_neurotypeNT", "b_MASQ:neurotypeNT", "sigma")]
sim_modPME_posterior <- sim_modPME_posterior[, c("b_Intercept", "b_MASQ", "b_neurotypeNT","b_EDAQ", "b_MASQ:neurotypeNT", "b_neurotypeNT:EDAQ", "sigma")]

#Convert the data frame to long format:
sim_modPM_posterior_long <- pivot_longer(sim_modPM_posterior, 
                                        cols = everything(), 
                                        names_to = "Parameter", 
                                        values_to = "Estimate")
sim_modPME_posterior_long <- pivot_longer(sim_modPME_posterior, 
                                        cols = everything(), 
                                        names_to = "Parameter", 
                                        values_to = "Estimate")

#Rename parameters to 'Intercept', 'MASQ', 'EDAQ', and 'sigma':
sim_modPM_posterior_long$Parameter <- recode(sim_modPM_posterior_long$Parameter,
                                            "b_Intercept" = "Intercept",
                                            "b_MASQ" = "MASQ", 
                                            "b_neurotypeNT" = "neurotypeNT",
                                            "b_EDAQ" = "EDAQ", 
                                            "b_MASQ:neurotypeNT" = "MASQ:neurotypeNT", 
                                            "b_neurotypeNT.EDAQ" = "neurotypeNT:EDAQ", 
                                            "sigma" = "Sigma")
sim_modPME_posterior_long$Parameter <- recode(sim_modPME_posterior_long$Parameter,
                                            "b_Intercept" = "Intercept",
                                            "b_MASQ" = "MASQ", 
                                            "b_neurotypeNT" = "neurotypeNT",
                                            "b_EDAQ" = "EDAQ", 
                                            "b_MASQ:neurotypeNT" = "MASQ:neurotypeNT", 
                                            "b_neurotypeNT:EDAQ" = "neurotypeNT:EDAQ", 
                                            "sigma" = "Sigma")

#Extract group information from parameter names:
sim_modPM_posterior_long$Group <- sub(":.*", "", sim_modPM_posterior_long$Parameter)
sim_modPME_posterior_long$Group <- sub(":.*", "", sim_modPME_posterior_long$Parameter)

#Reorder the parameters and flip the order:
sim_modPM_posterior_long$Parameter <- factor(sim_modPM_posterior_long$Parameter, 
                                            levels = rev(c("Intercept","MASQ","neurotypeNT","MASQ:neurotypeNT","Sigma")))
sim_modPME_posterior_long$Parameter <- factor(sim_modPME_posterior_long$Parameter, 
                                            levels = rev(c("Intercept","MASQ","neurotypeNT","EDAQ","MASQ:neurotypeNT","neurotypeNT:EDAQ","Sigma")))

#Plot marginal posterior distributions with specified colors:
plot_title <- ggtitle("Posterior distributions",
                      subtitle = "with means and 95% HDI")

ggplot(sim_modPM_posterior_long, aes(x = Estimate, y = Parameter, fill = neurotype)) +
  stat_halfeye(point_interval = mean_hdi, .width = c(0.95), size = 0.5, , height = 3, fill = "#9ED4D1") +  # Adjusting the size of the points
  #scale_fill_manual(values = colors) +
  labs(x = "Parameter estimates", y = "Parameters", fill = "Neurotype") +
  plot_title +
  theme_minimal() +  # Using theme_minimal() instead of theme_clean()
  theme(legend.position = "right",
        panel.grid.major = element_blank(),  # Remove major grid lines
        panel.grid.minor = element_blank(),  # Remove minor grid lines
        axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14),
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 12),
    plot.title = element_text(size = 16),
    legend.title = element_text(size = 14),
    legend.text = element_text(size = 12)) +  # Increase font size of axis titles) +  # Add a single line at 0 on the x-axis
  geom_vline(xintercept = 0, linetype = "dashed")  # Add a dashed line at x = 0

ggplot(sim_modPME_posterior_long, aes(x = Estimate, y = Parameter, fill = neurotype)) +
  stat_halfeye(point_interval = mean_hdi, .width = c(0.95), size = 0.5, , height = 3, fill = "#9ED4D1") +  # Adjusting the size of the points
  #scale_fill_manual(values = colors) +
  labs(x = "Parameter estimates", y = "Parameters", fill = "Neurotype") +
  plot_title +
  theme_minimal() +  # Using theme_minimal() instead of theme_clean()
  theme(legend.position = "right",
        panel.grid.major = element_blank(),  # Remove major grid lines
        panel.grid.minor = element_blank(),  # Remove minor grid lines
        axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14),
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 12),
    plot.title = element_text(size = 16),
    legend.title = element_text(size = 14),
    legend.text = element_text(size = 12)) +  # Increase font size of axis titles) +  # Add a single line at 0 on the x-axis
  geom_vline(xintercept = 0, linetype = "dashed")  # Add a dashed line at x = 0
```

For the first model, perseveration \~ MASQ\*neurotype:

-   **Intercept**: This is the estimated baseline value of `perseveration` when all other predictors are zero. The distribution is centered around 0.5 with narrow HDI, suggesting a strong baseline level of `perseveration`.

-   **MASQ and neurotypeNT**: These represent the effects of `MASQ` and `neurotypeNT` on `perseveration`, respectively. `MASQ` has a distribution centered just below 0, and HDI overlapping 0 - this suggests that `MASQ` has no effect on `perseveration`. `neurotypeNT` has a distribution centered below -1, and HDI far from 0 - `neurotypeNT` has a strong negative effect on `perseveration` - NTs perseverate less than ASC.

-   **MASQ:neurotypeNT**: This is the interaction term, indicating whether the effect of `MASQ` on `perseveration` differs across neurotypes. `MASQ:neurotype` has a distribution centered just above -1, with HDI far from 0 - this suggests that the effect of `MASQ` on `perseveration` varies by neurotype - anxiety is associated with fewer perseverations in NT compared to ASC.

-   **Sigma**: This represents the standard deviation of the residuals (the variability not explained by the model). A larger sigma indicates more variability in `perseveration` that isn’t accounted for by the predictors - here the distribution for sigma sits above 0 with very narrow HDI - much of the variance in `perseveration` is being captured by the model.

For the second model, perseveration \~ MASQ\*neurotype + EDAQ\*neurotype:

-   **Intercept**: This is the estimated baseline value of `perseveration` when all other predictors are zero. The distribution is centered above 0 with narrow HDI, suggesting a strong baseline level of `perseveration`.

-   **MASQ, neurotypeNT, and EDAQ**: These represent the effects of `MASQ`, `neurotypeNT`, and `EDAQ` on `perseveration`, respectively. `MASQ` has a distribution centered just below 0, and HDI almost overlapping 0 - `MASQ` is negatively associated with `perseveration`, however, we should be cautious when interpreting this relationship as the tail of this distribution sits close to 0. `neurotypeNT`has a distribution centered below -1, and HDI far from 0, indicating a strong negative effect of `neurotypeNT`on `perseveration`- NTs perseverate less than ASC. `EDAQ` has a distribution centered around 0, and HDI overlapping 0 - `EDAQ` does not have an effect on `perseveration.`

-   **MASQ:neurotypeNT and neurotypeNT:EDAQ**: These are the interaction terms, indicating whether the effect of `MASQ` and `EDAQ` on `perseveration` differs across neurotypes. `MASQ:neurotype` has a distribution centered just below 0, with HDI well below 0 - this suggests that the effect of `MASQ` on `perseveration` varies by neurotype. Similarly, `neurotype:EDAQ` has a distribution that sits around -1, with HDI well below 0, indicating that the effect of `EDAQ` on `perseveration` differs across neurotypes- anxiety and PDA are associated with fewer perseverations in NT compared to ASC.

-   **Sigma**: This represents the standard deviation of the residuals (the variability not explained by the model). A larger sigma indicates more variability in `perseveration` that isn’t accounted for by the predictors - here the distribution for sigma sits above 0 with very narrow HDI - much of the variance in `perseveration` is being captured by the model.

Visualise model-predicted perseveration values for MASQ and EDA-QA scores by neurotype:

```{r}
#Read in saved data file:
sim_data <- read.csv("Sim_Data.csv")

#Prepare and standardise variables:
data <- sim_data %>%
  mutate(
    EDAQ = standardize(EDAQ),
    MASQ = standardize(MASQ),
    RLLR = standardize(RLLR),
    perseveration = standardize(perseveration),
    regression = standardize(regression),
    loseShift = standardize(loseShift)
  ) %>%
  select(id, EDAQ, MASQ, RLLR, loseShift, perseveration, regression, neurotype) %>%
  distinct()

#Load the model output from a file:
sim_modPM <- readRDS("sim_modPM_output.rds")
sim_modPME <- readRDS("sim_modPME_output.rds")

#Extract conditional effects:
ce_PM <- conditional_effects(sim_modPM)
ce_PME <- conditional_effects(sim_modPME)

#Convert the specific effect to a data frames:
ce_PM_MASQ <- as.data.frame(ce_PM$`MASQ:neurotype`)
ce_PME_MASQ <- as.data.frame(ce_PME$`MASQ:neurotype`)
ce_PME_EDAQ <- as.data.frame(ce_PME$`EDAQ:neurotype`)

#Select relevant columns:
ce_PM_MASQ <- ce_PM_MASQ %>% 
  select(MASQ, neurotype, estimate__, lower__, upper__)
ce_PME_MASQ <- ce_PME_MASQ %>% 
  select(MASQ, neurotype, estimate__, lower__, upper__)
ce_PME_EDAQ <- ce_PME_EDAQ %>% 
  select(EDAQ, neurotype, estimate__, lower__, upper__)

#Plot for MASQ for sim_modRM:
ggplot(ce_PM_MASQ, aes(x = MASQ, y = estimate__, color = neurotype)) +
  geom_point(data = data, aes(x = MASQ, y = perseveration, color = neurotype)) +
  geom_line(aes(y = estimate__),size = 1) +  # Line for estimated effects
  geom_ribbon(aes(ymin = lower__, ymax = upper__, fill = neurotype), alpha = 0.3, color = NA) +  # Ribbons for uncertainty
  theme_minimal() +  # Use a minimal theme
  labs(title = "Effect Of MASQ Scores On Perseverative behaviours By Neurotype",
       x = "MASQ",
       y = "Estimated Effect") +
  scale_color_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) +
  scale_fill_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) 

#Plot for MASQ for sim_modRME:
PMEplot_masq <- ggplot(ce_PME_MASQ, aes(x = MASQ, y = estimate__, color = neurotype)) +
  geom_point(data = data, aes(x = MASQ, y = perseveration, color = neurotype)) +
  geom_line(aes(y = estimate__),size = 1) +  # Line for estimated effects
  geom_ribbon(aes(ymin = lower__, ymax = upper__, fill = neurotype), alpha = 0.3, color = NA) +  # Ribbons for uncertainty
  theme_minimal() +  # Use a minimal theme
  labs(x = "MASQ",
       y = "Estimated Effect") +
  scale_color_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) +
  scale_fill_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) 

#Plot for EDAQ for sim_modRME:
PMEplot_edaq <- ggplot(ce_PME_EDAQ, aes(x = EDAQ, y = estimate__, color = neurotype)) +
  geom_point(data = data, aes(x = EDAQ, y = perseveration, color = neurotype)) +
  geom_line(aes(y = estimate__),size = 1) +  # Line for estimated effects
  geom_ribbon(aes(ymin = lower__, ymax = upper__, fill = neurotype), alpha = 0.3, color = NA) +  # Ribbons for uncertainty
  theme_minimal() +  # Use a minimal theme
  labs(x = "EDAQ",
       y = "") +
  scale_color_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) +
  scale_fill_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) 

#Combine the plots:
(PMEplot_masq + PMEplot_edaq) + plot_annotation(title = "Effect Of MASQ And EDAQ Scores On Perseverative behaviours By Neurotype")
```

The plots above plot regression lines for the model-predicted estimates (with HDI ribbons) over our simulated data. These plots show that the number of perseverative behaviours produced by the ASC group do not vary as a function of anxiety (MASQ) and PDA (EDAQ), while for the NT group, the number of perseverative behaviours are negatively associated with both anxiety (MASQ) and PDA (EDAQ). This reflects our assumptions that 1) the number of perseverative behaviours will be greater for the ASC group compared to the NT gorup - this is based on Crawley et al. (2020) and Coldren & Halloran (2010). Similarly, 2) anxiety will be negatively associated with perseverative behaviours - this is based on Fang et al. (2024) and Zhukovsky et al. (2017) who both found perseveration to be negatively correlated with anxiety, with the former noting that the severity of anxiety symptoms was negatively associated with a tendency for perseverative strategies. Because PDA is thought to be underpinned by anxiety (Johnson & Saunderson, 2023; Stuart et al., 2020), we assume PDA behaviours will also be negatively associated with perseverative behaviours. Though, it is important to note that there is a dearth of literature that reports perseverative tendencies (positive or negative) in anxious cohorts.

#### Regressive behaviour

Once again, we can inspect the output for regression values for MASQ and EDA-QA scores and their interaction with neurotype, this time we will consider the marginal posterior distribution of each parameter (central tendency and credible intervals):

```{r}
#Extract posterior samples:
sim_modReM_posterior <- posterior_samples(sim_modReM)
sim_modReME_posterior <- posterior_samples(sim_modReME)


#Filter out 'lprior' and 'lp__':
sim_modReM_posterior <- sim_modReM_posterior[, c("b_Intercept", "b_MASQ", "b_neurotypeNT", "b_MASQ:neurotypeNT", "sigma")]
sim_modReME_posterior <- sim_modReME_posterior[, c("b_Intercept", "b_MASQ", "b_neurotypeNT","b_EDAQ", "b_MASQ:neurotypeNT", "b_neurotypeNT:EDAQ", "sigma")]

#Convert the data frame to long format:
sim_modReM_posterior_long <- pivot_longer(sim_modReM_posterior, 
                                        cols = everything(), 
                                        names_to = "Parameter", 
                                        values_to = "Estimate")
sim_modReME_posterior_long <- pivot_longer(sim_modReME_posterior, 
                                        cols = everything(), 
                                        names_to = "Parameter", 
                                        values_to = "Estimate")

#Rename parameters to 'Intercept', 'MASQ', 'EDAQ', and 'sigma':
sim_modReM_posterior_long$Parameter <- recode(sim_modReM_posterior_long$Parameter,
                                            "b_Intercept" = "Intercept",
                                            "b_MASQ" = "MASQ", 
                                            "b_neurotypeNT" = "neurotypeNT",
                                            "b_EDAQ" = "EDAQ", 
                                            "b_MASQ:neurotypeNT" = "MASQ:neurotypeNT", 
                                            "b_neurotypeNT.EDAQ" = "neurotypeNT:EDAQ", 
                                            "sigma" = "Sigma")
sim_modReME_posterior_long$Parameter <- recode(sim_modReME_posterior_long$Parameter,
                                            "b_Intercept" = "Intercept",
                                            "b_MASQ" = "MASQ", 
                                            "b_neurotypeNT" = "neurotypeNT",
                                            "b_EDAQ" = "EDAQ", 
                                            "b_MASQ:neurotypeNT" = "MASQ:neurotypeNT", 
                                            "b_neurotypeNT:EDAQ" = "neurotypeNT:EDAQ", 
                                            "sigma" = "Sigma")

#Extract group information from parameter names:
sim_modReM_posterior_long$Group <- sub(":.*", "", sim_modReM_posterior_long$Parameter)
sim_modReME_posterior_long$Group <- sub(":.*", "", sim_modReME_posterior_long$Parameter)

#Reorder the parameters and flip the order:
sim_modReM_posterior_long$Parameter <- factor(sim_modReM_posterior_long$Parameter, 
                                            levels = rev(c("Intercept","MASQ","neurotypeNT","MASQ:neurotypeNT","Sigma")))
sim_modReME_posterior_long$Parameter <- factor(sim_modReME_posterior_long$Parameter, 
                                            levels = rev(c("Intercept","MASQ","neurotypeNT","EDAQ","MASQ:neurotypeNT","neurotypeNT:EDAQ","Sigma")))

#Plot marginal posterior distributions with specified colors:
plot_title <- ggtitle("Posterior distributions",
                      subtitle = "with means and 95% HDI")

ggplot(sim_modReM_posterior_long, aes(x = Estimate, y = Parameter, fill = neurotype)) +
  stat_halfeye(point_interval = mean_hdi, .width = c(0.95), size = 0.5, , height = 3, fill = "#9ED4D1") +  # Adjusting the size of the points
  #scale_fill_manual(values = colors) +
  labs(x = "Parameter estimates", y = "Parameters", fill = "Neurotype") +
  plot_title +
  theme_minimal() +  # Using theme_minimal() instead of theme_clean()
  theme(legend.position = "right",
        panel.grid.major = element_blank(),  # Remove major grid lines
        panel.grid.minor = element_blank(),  # Remove minor grid lines
        axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14),
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 12),
    plot.title = element_text(size = 16),
    legend.title = element_text(size = 14),
    legend.text = element_text(size = 12)) +  # Increase font size of axis titles) +  # Add a single line at 0 on the x-axis
  geom_vline(xintercept = 0, linetype = "dashed")  # Add a dashed line at x = 0

ggplot(sim_modReME_posterior_long, aes(x = Estimate, y = Parameter, fill = neurotype)) +
  stat_halfeye(point_interval = mean_hdi, .width = c(0.95), size = 0.5, , height = 3, fill = "#9ED4D1") +  # Adjusting the size of the points
  #scale_fill_manual(values = colors) +
  labs(x = "Parameter estimates", y = "Parameters", fill = "Neurotype") +
  plot_title +
  theme_minimal() +  # Using theme_minimal() instead of theme_clean()
  theme(legend.position = "right",
        panel.grid.major = element_blank(),  # Remove major grid lines
        panel.grid.minor = element_blank(),  # Remove minor grid lines
        axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14),
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 12),
    plot.title = element_text(size = 16),
    legend.title = element_text(size = 14),
    legend.text = element_text(size = 12)) +  # Increase font size of axis titles) +  # Add a single line at 0 on the x-axis
  geom_vline(xintercept = 0, linetype = "dashed")  # Add a dashed line at x = 0
```

For the first model, regression \~ MASQ\*neurotype:

-   **Intercept**: This is the estimated baseline value of `regression` when all other predictors are zero. The distribution is centered around 0.5 with narrow HDI, suggesting a strong baseline level of `regression`.

-   **MASQ and neurotypeNT**: These represent the effects of `MASQ` and `neurotypeNT` on `regression`, respectively. `MASQ` has a distribution centered just below 0, and HDI overlapping 0 - this suggests that `MASQ` has no effect on `regression`. `neurotypeNT` has a distribution centered below -1, and HDI far from 0 - `neurotypeNT` has a strong negative effect on `regression` - NTs regress less than ASC.

-   **MASQ:neurotypeNT**: This is the interaction term, indicating whether the effect of `MASQ` on `regression` differs across neurotypes. `MASQ:neurotype` has a distribution centered below -0.5, with HDI far from 0 - this suggests that the effect of `MASQ` on `regression` varies by neurotype - anxiety is associated with fewer regressions in NT compared to ASC.

-   **Sigma**: This represents the standard deviation of the residuals (the variability not explained by the model). A larger sigma indicates more variability in `regression` that isn’t accounted for by the predictors - here the distribution for sigma sits above 0 with very narrow HDI - much of the variance in `regression` is being captured by the model.

For the second model, regression \~ MASQ\*neurotype+ EDAQ\*neurotype:

-   **Intercept**: This is the estimated baseline value of `regression` when all other predictors are zero. The distribution is centered above 0 with narrow HDI, suggesting a strong baseline level of `regression`.

-   **MASQ, neurotypeNT, and EDAQ**: These represent the effects of `MASQ`, `neurotypeNT`, and `EDAQ` on `regression`, respectively. `MASQ` has a distribution centered just below 0, and HDI overlapping 0 - `MASQ` does not have a reliable effect on `regression.` `neurotypeNT`has a distribution centered below -1, and HDI far from 0, indicating a strong negative effect of `neurotypeNT`on `regression`- NTs regress less than ASC.`EDAQ` has a distribution centered around 0, and HDI overlapping 0 - `EDAQ` does not have a reliable effect on `regression.`

-   **MASQ:neurotypeNT and neurotypeNT:EDAQ**: These are the interaction terms, indicating whether the effect of `MASQ` and `EDAQ` on `regression` differs across neurotypes. `MASQ:neurotype` has a distribution centered just below 0, with HDI close to 0 - this suggests that the effect of `MASQ` on `regression` varies by neurotype, however, we should be cautious when interpreting this relationship as the tail of this distribution sits close to 0. `neurotype:EDAQ` has a distribution that sits around -1, with HDI well below 0, indicating that the effect of `EDAQ` on `regression` differs across neurotypes- anxiety and PDA are associated with fewer regressions in NT compared to ASC.

-   **Sigma**: This represents the standard deviation of the residuals (the variability not explained by the model). A larger sigma indicates more variability in `regression` that isn’t accounted for by the predictors - here the distribution for sigma sits above 0 with very narrow HDI - much of the variance in `regression` is being captured by the model.

Visualise model-predicted regression values for MASQ and EDA-QA scores by neurotype:

```{r}
#Read in saved data file:
sim_data <- read.csv("Sim_Data.csv")

#Prepare and standardise variables:
data <- sim_data %>%
  mutate(
    EDAQ = standardize(EDAQ),
    MASQ = standardize(MASQ),
    RLLR = standardize(RLLR),
    perseveration = standardize(perseveration),
    regression = standardize(regression),
    loseShift = standardize(loseShift)
  ) %>%
  select(id, EDAQ, MASQ, RLLR, loseShift, perseveration, regression, neurotype) %>%
  distinct()

#Load the model output from a file:
sim_modReM <- readRDS("sim_modReM_output.rds")
sim_modReME <- readRDS("sim_modReME_output.rds")

#Extract conditional effects:
ce_ReM <- conditional_effects(sim_modReM)
ce_ReME <- conditional_effects(sim_modReME)

#Convert the specific effect to a data frames:
ce_ReM_MASQ <- as.data.frame(ce_ReM$`MASQ:neurotype`)
ce_ReME_MASQ <- as.data.frame(ce_ReME$`MASQ:neurotype`)
ce_ReME_EDAQ <- as.data.frame(ce_ReME$`EDAQ:neurotype`)

#Select relevant columns:
ce_ReM_MASQ <- ce_ReM_MASQ %>% 
  select(MASQ, neurotype, estimate__, lower__, upper__)
ce_ReME_MASQ <- ce_ReME_MASQ %>% 
  select(MASQ, neurotype, estimate__, lower__, upper__)
ce_ReME_EDAQ <- ce_ReME_EDAQ %>% 
  select(EDAQ, neurotype, estimate__, lower__, upper__)

#Plot for MASQ for sim_modRM:
ggplot(ce_ReM_MASQ, aes(x = MASQ, y = estimate__, color = neurotype)) +
  geom_point(data = data, aes(x = MASQ, y = regression, color = neurotype)) +
  geom_line(aes(y = estimate__),size = 1) +  # Line for estimated effects
  geom_ribbon(aes(ymin = lower__, ymax = upper__, fill = neurotype), alpha = 0.3, color = NA) +  # Ribbons for uncertainty
  theme_minimal() +  # Use a minimal theme
  labs(title = "Effect Of MASQ Scores On Regressive behaviours By Neurotype",
       x = "MASQ",
       y = "Estimated Effect") +
  scale_color_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) +
  scale_fill_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) 

#Plot for MASQ for sim_modRME:
ReMEplot_masq <- ggplot(ce_ReME_MASQ, aes(x = MASQ, y = estimate__, color = neurotype)) +
  geom_point(data = data, aes(x = MASQ, y = regression, color = neurotype)) +
  geom_line(aes(y = estimate__),size = 1) +  # Line for estimated effects
  geom_ribbon(aes(ymin = lower__, ymax = upper__, fill = neurotype), alpha = 0.3, color = NA) +  # Ribbons for uncertainty
  theme_minimal() +  # Use a minimal theme
  labs(x = "MASQ",
       y = "Estimated Effect") +
  scale_color_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) +
  scale_fill_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) 

#Plot for EDAQ for sim_modRME:
ReMEplot_edaq <- ggplot(ce_ReME_EDAQ, aes(x = EDAQ, y = estimate__, color = neurotype)) +
  geom_point(data = data, aes(x = EDAQ, y = regression, color = neurotype)) +
  geom_line(aes(y = estimate__),size = 1) +  # Line for estimated effects
  geom_ribbon(aes(ymin = lower__, ymax = upper__, fill = neurotype), alpha = 0.3, color = NA) +  # Ribbons for uncertainty
  theme_minimal() +  # Use a minimal theme
  labs(x = "EDAQ",
       y = "") +
  scale_color_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) +
  scale_fill_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) 

#Combine the plots:
(ReMEplot_masq + ReMEplot_edaq) + plot_annotation(title = "Effect Of MASQ And EDAQ Scores On Regressive behaviours By Neurotype")
```

Again, the plots above plot regression lines for the model-predicted estimates (with HDI ribbons) over our simulated data. These plots show that the number of regressive behaviours produced by the ASC group do not vary as a function of anxiety (MASQ) and PDA (EDAQ), while for the NT group, the number of regressive behaviours are negatively associated with both anxiety (MASQ) and PDA (EDAQ). This fits with our assumptions that 1) the number of regressive behaviours will be greater for the ASC group compared to the NT group - this is based on Crawley et al. (2020) and Coldren & Halloran (2010). Similarly, 2) anxiety will be negatively associated with regressive behaviours - this is based on Fang et al. (2024) and Zhukovsky et al. (2017). Because PDA is thought to be underpinned by anxiety (Johnson & Saunderson, 2023; Stuart et al., 2020), we assume PDA behaviours will also be negatively associated with regressive behaviours. Again, much like perseverative behaviours, it is important to note that there is a dearth of literature that reports regressive tendencies (positive or negative) in anxious cohorts.

### Learning rate predicted by neurotype, PDA and anxiety

#### Effect of block order on RLLR

Inspect the output for model-predicted RLLR values for blockorder and its interaction with neurotype, this time we will consider the marginal posterior distribution of each parameter (central tendency and credible intervals):

```{r}
#Read in posterior samples .csv to data frame:
sim_modRB_posterior <- read.csv("sim_modRB_posterior.csv")


#Filter out 'lprior' and 'lp__':
sim_modRB_posterior <- sim_modRB_posterior[, c("b_blockorderSDV.neurotypeASC", "b_blockorderVDS.neurotypeASC", "b_blockorderSDV.neurotypeNT", "b_blockorderVDS.neurotypeNT", "sigma")]

#Convert the data frame to long format:
sim_modRB_posterior_long <- pivot_longer(sim_modRB_posterior, 
                                        cols = everything(), 
                                        names_to = "Parameter", 
                                        values_to = "Estimate")

#Rename parameters to 'Intercept', 'MASQ', 'EDAQ', and 'sigma':
sim_modRB_posterior_long$Parameter <- recode(sim_modRB_posterior_long$Parameter,
                                            "b_blockorderSDV.neurotypeASC" = "ASC:S/V", 
                                            "b_blockorderVDS.neurotypeASC" = "ASC:V/S",
                                            "b_blockorderSDV.neurotypeNT" = "NT:S/V", 
                                            "b_blockorderVDS.neurotypeNT" = "NT:V/S", 
                                            "sigma" = "Sigma")

#Extract group information from parameter names:
sim_modRB_posterior_long$Group <- sub(":.*", "", sim_modRB_posterior_long$Parameter)

#Reorder the parameters and flip the order:
sim_modRB_posterior_long$Parameter <- factor(sim_modRB_posterior_long$Parameter, 
                                            levels = rev(c("ASC:S/V","ASC:V/S","NT:S/V","NT:V/S", "Sigma")))

#Plot marginal posterior distributions with specified colors:
plot_title <- ggtitle("Posterior distributions",
                      subtitle = "with means and 95% HDI")

ggplot(sim_modRB_posterior_long, aes(x = Estimate, y = Parameter, fill = neurotype)) +
  stat_halfeye(point_interval = mean_hdi, .width = c(0.95), size = 0.5, , height = 3, fill = "#9ED4D1") +  # Adjusting the size of the points
  #scale_fill_manual(values = colors) +
  labs(x = "Parameter estimates", y = "Parameters", fill = "Neurotype") +
  plot_title +
  theme_minimal() +  # Using theme_minimal() instead of theme_clean()
  theme(legend.position = "right",
        panel.grid.major = element_blank(),  # Remove major grid lines
        panel.grid.minor = element_blank(),  # Remove minor grid lines
        axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14),
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 12),
    plot.title = element_text(size = 16),
    legend.title = element_text(size = 14),
    legend.text = element_text(size = 12)) +  # Increase font size of axis titles) +  # Add a single line at 0 on the x-axis
  geom_vline(xintercept = 0, linetype = "dashed")  # Add a dashed line at x = 0
```

For the first model, RLLR \~ blockOrder:neurotype:

-   **ASC:S/V**: `ASC:S/V` has a distribution centered around -1 with a wide HDI that overlaps 0, suggesting that `RLLR` in the ASC group under `S/V` conditions might be lower relative to the NT group, but not reliably so.

-   **ASC:V/S:** `ASC:V/S` has a distribution centerted around -1 with a wide HDI that overlaps 0 - that `ASC:V/S` and `ASC:S/V` have very similar posterior distributions suggests that, for the ASC group, blockorder does not effect RLLRs.

-   **NT:S/V**: `NT:S/V` has a distribution centered around 0.5 with a wide HDI that overlaps 0, suggesting that `RLLR` in the NT group under `S/V` conditions higher than that of the ASC group, but not reliably so.

    **NT:V/S**: `NT:V/S` has a distribution centered around 1 with a wide HDI that overlaps 0 - that `NT:V/S` and `NT:S/V` have very similar posterior distributions suggests that, for the NT group, blockorder does not effect RLLRs.

-   **Sigma**: This represents the standard deviation of the residuals (the variability not explained by the model). A larger sigma indicates more variability in `RLLR` that isn’t accounted for by the predictors - here the distribution for sigma sits above 0 with very narrow HDI - much of the variance in `RLLR` is being captured by the model.

Visualise model-predicted RLLR values for blockorder by neurotype:

```{r}
#Read in saved data file:
sim_data <- read.csv("Sim_Data.csv")

#Prepare and standardise variables:
data <- sim_data %>%
  mutate(
    EDAQ = standardize(EDAQ),
    MASQ = standardize(MASQ),
    RLLR = standardize(RLLR),
    perseveration = standardize(perseveration),
    regression = standardize(regression),
    loseShift = standardize(loseShift)
  ) %>%
  select(id, EDAQ, MASQ, RLLR, loseShift, perseveration, regression, neurotype, blockorder) %>%
  distinct()

#Load the model output from a file:
sim_modRB <- readRDS("sim_modRB_output.rds")

#Extract conditional effects:
ce_RB <- conditional_effects(sim_modRB)

#Convert the specific effect to a data frames:
ce_RB <- as.data.frame(ce_RB$`blockorder:neurotype`)

#Select relevant columns:
ce_RB <- ce_RB %>% 
  select(blockorder, neurotype, estimate__, lower__, upper__)

#Calculate means for each condition:
mean_estimates <- ce_RB %>%
  group_by(blockorder, neurotype) %>%
  dplyr::summarize(mean_est = mean(estimate__, na.rm = TRUE))

#Plot for MASQ for sim_modRM:
ggplot(ce_RB, aes(x = factor(blockorder), y = estimate__, color = neurotype)) +
  geom_jitter(data = data, aes(x = factor(blockorder), y = RLLR, color = neurotype)) +
  geom_line(aes(group = interaction(neurotype, blockorder)),size = 1) +  # Line for estimated effects
  geom_ribbon(aes(ymin = lower__, ymax = upper__, fill = neurotype), alpha = 0.3, color = NA) +  # Ribbons for uncertainty
  theme_minimal() +  # Use a minimal theme
  labs(title = "Effect Of Block Order On Relative Log Learning Rate By Neurotype",
       x = "Block Order",
       y = "Estimated Effect") +
  scale_color_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) +
  scale_fill_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) +
  # Add error bars
  geom_errorbar(data = ce_RB, aes(x = blockorder, ymin = lower__, ymax = upper__), 
                width = 0.2, size = 1) +
  # Add lines connecting the mean points for each diagnostic neurotype
  geom_line(data = mean_estimates, aes(x = blockorder, y = mean_est, group = neurotype),
             size = 1) +
  # Add mean points for each diagnostic neurotype
  geom_point(data = mean_estimates, aes(x = blockorder, y = mean_est), 
             color = "#336666", size = 4, shape = 18)  # Shape 18 for diamond
```

Again, the above plot shows model estimates for the effect of block order on RLLRs by neurotype - diamonds and lines show mean estimates for each block presentation by neurotype. Together with posterior distributions, it is evident that the order participants complete each condition (stable and volatile) does not impact learning rates. This is true for both NT and ASC groups. There is a difference between RLLRs predicted by each neurotype - RLLRs are higher for the NT group compared to the ASC group, but this is to be expected - this is an assumption that is built into our simulation.

#### Effect of EDA-QA and MASQ on RLLR

Finally, we can inspect the output for model-predicted RLLR values for MASQ and EDA-QA scores and their interaction with neurotype, this time we will consider the marginal posterior distribution of each parameter (central tendency and credible intervals):

```{r}
#Read in posterior samples .csv to data frame:
sim_modRM_posterior <- read.csv("sim_modRM_posterior.csv")
sim_modRME_posterior <- read.csv("sim_modRME_posterior.csv")


#Filter out 'lprior' and 'lp__':
sim_modRM_posterior <- sim_modRM_posterior[, c("b_Intercept", "b_MASQ", "b_neurotypeNT", "b_MASQ.neurotypeNT", "sigma")]
sim_modRME_posterior <- sim_modRME_posterior[, c("b_Intercept", "b_MASQ", "b_neurotypeNT","b_EDAQ", "b_MASQ.neurotypeNT", "b_neurotypeNT.EDAQ", "sigma")]

#Convert the data frame to long format:
sim_modRM_posterior_long <- pivot_longer(sim_modRM_posterior, 
                                        cols = everything(), 
                                        names_to = "Parameter", 
                                        values_to = "Estimate")
sim_modRME_posterior_long <- pivot_longer(sim_modRME_posterior, 
                                        cols = everything(), 
                                        names_to = "Parameter", 
                                        values_to = "Estimate")

#Rename parameters to 'Intercept', 'MASQ', 'EDAQ', and 'sigma':
sim_modRM_posterior_long$Parameter <- recode(sim_modRM_posterior_long$Parameter,
                                            "b_Intercept" = "Intercept",
                                            "b_MASQ" = "MASQ", 
                                            "b_neurotypeNT" = "neurotypeNT",
                                            "b_EDAQ" = "EDAQ", 
                                            "b_MASQ.neurotypeNT" = "MASQ:neurotypeNT", 
                                            "b_neurotypeNT.EDAQ" = "neurotypeNT:EDAQ", 
                                            "sigma" = "Sigma")
sim_modRME_posterior_long$Parameter <- recode(sim_modRME_posterior_long$Parameter,
                                            "b_Intercept" = "Intercept",
                                            "b_MASQ" = "MASQ", 
                                            "b_neurotypeNT" = "neurotypeNT",
                                            "b_EDAQ" = "EDAQ", 
                                            "b_MASQ.neurotypeNT" = "MASQ:neurotypeNT", 
                                            "b_neurotypeNT.EDAQ" = "neurotypeNT:EDAQ", 
                                            "sigma" = "Sigma")

#Extract group information from parameter names:
sim_modRM_posterior_long$Group <- sub(":.*", "", sim_modRM_posterior_long$Parameter)
sim_modRME_posterior_long$Group <- sub(":.*", "", sim_modRME_posterior_long$Parameter)

#Reorder the parameters and flip the order:
sim_modRM_posterior_long$Parameter <- factor(sim_modRM_posterior_long$Parameter, 
                                            levels = rev(c("Intercept","MASQ","neurotypeNT","MASQ:neurotypeNT","Sigma")))
sim_modRME_posterior_long$Parameter <- factor(sim_modRME_posterior_long$Parameter, 
                                            levels = rev(c("Intercept","MASQ","neurotypeNT","EDAQ","MASQ:neurotypeNT","neurotypeNT:EDAQ","Sigma")))

#Plot marginal posterior distributions with specified colors:
plot_title <- ggtitle("Posterior distributions",
                      subtitle = "with means and 95% HDI")

ggplot(sim_modRM_posterior_long, aes(x = Estimate, y = Parameter, fill = neurotype)) +
  stat_halfeye(point_interval = mean_hdi, .width = c(0.95), size = 0.5, , height = 3, fill = "#9ED4D1") +  # Adjusting the size of the points
  #scale_fill_manual(values = colors) +
  labs(x = "Parameter estimates", y = "Parameters", fill = "Neurotype") +
  plot_title +
  theme_minimal() +  # Using theme_minimal() instead of theme_clean()
  theme(legend.position = "right",
        panel.grid.major = element_blank(),  # Remove major grid lines
        panel.grid.minor = element_blank(),  # Remove minor grid lines
        axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14),
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 12),
    plot.title = element_text(size = 16),
    legend.title = element_text(size = 14),
    legend.text = element_text(size = 12)) +  # Increase font size of axis titles) +  # Add a single line at 0 on the x-axis
  geom_vline(xintercept = 0, linetype = "dashed")  # Add a dashed line at x = 0

ggplot(sim_modRME_posterior_long, aes(x = Estimate, y = Parameter, fill = neurotype)) +
  stat_halfeye(point_interval = mean_hdi, .width = c(0.95), size = 0.5, , height = 3, fill = "#9ED4D1") +  # Adjusting the size of the points
  #scale_fill_manual(values = colors) +
  labs(x = "Parameter estimates", y = "Parameters", fill = "Neurotype") +
  plot_title +
  theme_minimal() +  # Using theme_minimal() instead of theme_clean()
  theme(legend.position = "right",
        panel.grid.major = element_blank(),  # Remove major grid lines
        panel.grid.minor = element_blank(),  # Remove minor grid lines
        axis.title.x = element_text(size = 14),
    axis.title.y = element_text(size = 14),
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 12),
    plot.title = element_text(size = 16),
    legend.title = element_text(size = 14),
    legend.text = element_text(size = 12)) +  # Increase font size of axis titles) +  # Add a single line at 0 on the x-axis
  geom_vline(xintercept = 0, linetype = "dashed")  # Add a dashed line at x = 0
```

For the first model, RLLR \~ MASQ\*neurotype:

-   **Intercept**: This is the estimated baseline value of `RLLR` when all other predictors are zero. The distribution is centered below -0.5 with narrow HDI, suggesting a strong baseline level of `RLLR`.

-   **MASQ and neurotypeNT**: These represent the effects of `MASQ` and `neurotypeNT` on `RLLR`, respectively. `MASQ` has a distribution centered just below 0, and HDI close to 0 - - this suggests that `MASQ` has a negative effect on `RLLR`, however, we should be cautious when interpreting this relationship as the tail of this distribution sits close to 0. `neurotypeNT` has a distribution centered above 1, and HDI far from 0 - `neurotypeNT` has a strong positive effect on `RLLR`- NTs have larger RLLR than ASC.

-   **MASQ:neurotypeNT**: This is the interaction term, indicating whether the effect of `MASQ` on `RLLR` differs across neurotypes. `MASQ:neurotype` has a distribution centered jaround 0.5, with HDI far from 0 - this suggests that the effect of `MASQ` on `RLLR` varies by neurotype- anxiety is associated with smaller RLLR in NT compared to ASC.

-   **Sigma**: This represents the standard deviation of the residuals (the variability not explained by the model). A larger sigma indicates more variability in `RLLR` that isn’t accounted for by the predictors - here the distribution for sigma sits above 0 with very narrow HDI - much of the variance in `RLLR` is being captured by the model.

For the second model, RLLR \~ MASQ\*neurotype+ EDAQ\*neurotype:

-   **Intercept**: This is the estimated baseline value of `RLLR` when all other predictors are zero. The distribution is centered above 0 with narrow HDI, suggesting a strong baseline level of `RLLR`.

-   **MASQ, neurotypeNT, and EDAQ**: These represent the effects of `MASQ`, `neurotypeNT`, and `EDAQ` on `RLLR`, respectively. `MASQ` has a distribution centered just below 0, and HDI almost overlapping 0 - `MASQ` does not have a reliable effect on `RLLR.` `neurotypeNT`has a distribution centered above 1, and HDI far from 0, indicating a strong negative effect of `neurotypeNT`on `RLLR`- NTs have larger RLLR than ASC. `EDAQ` has a distribution centered around 0, and HDI overlapping 0 - `EDAQ` does not have a reliable effect on `RLLR.`

-   **MASQ:neurotypeNT and neurotypeNT:EDAQ**: These are the interaction terms, indicating whether the effect of `MASQ` and `EDAQ` on `RLLR` differs across neurotypes. `MASQ:neurotype` has a distribution centered just below 0, with HDI close to 0 - this suggests that the effect of `MASQ` on `RLLR` varies by neurotype, however, we should be cautious when interpreting this relationship as the tail of this distribution sits close to 0. `neurotype:EDAQ` has a distribution that sits around -0.5, with HDI well below 0, indicating that the effect of `EDAQ` on `RLLR` differs across neurotypes- anxiety and PDA are associated with smaller RLLR in NT compared to ASC.

-   **Sigma**: This represents the standard deviation of the residuals (the variability not explained by the model). A larger sigma indicates more variability in `RLLR` that isn’t accounted for by the predictors - here the distribution for sigma sits above 0 with very narrow HDI - much of the variance in `RLLR` is being captured by the model.

Visualise model-predicted RLLR values for MASQ and EDA-QA scores by neurotype:

```{r}
#Read in saved data file:
sim_data <- read.csv("Sim_Data.csv")

#Prepare and standardise variables:
data <- sim_data %>%
  mutate(
    EDAQ = standardize(EDAQ),
    MASQ = standardize(MASQ),
    RLLR = standardize(RLLR),
    perseveration = standardize(perseveration),
    regression = standardize(regression),
    loseShift = standardize(loseShift)
  ) %>%
  select(id, EDAQ, MASQ, RLLR, loseShift, perseveration, regression, neurotype) %>%
  distinct()

#Load the model output from a file:
sim_modRM <- readRDS("sim_modRM_output.rds")
sim_modRME <- readRDS("sim_modRME_output.rds")

#Extract conditional effects:
ce_RM <- conditional_effects(sim_modRM)
ce_RME <- conditional_effects(sim_modRME)

#Convert the specific effect to a data frames:
ce_RM_MASQ <- as.data.frame(ce_RM$`MASQ:neurotype`)
ce_RME_MASQ <- as.data.frame(ce_RME$`MASQ:neurotype`)
ce_RME_EDAQ <- as.data.frame(ce_RME$`EDAQ:neurotype`)

#Select relevant columns:
ce_RM_MASQ <- ce_RM_MASQ %>% 
  select(MASQ, neurotype, estimate__, lower__, upper__)
ce_RME_MASQ <- ce_RME_MASQ %>% 
  select(MASQ, neurotype, estimate__, lower__, upper__)
ce_RME_EDAQ <- ce_RME_EDAQ %>% 
  select(EDAQ, neurotype, estimate__, lower__, upper__)

#Plot for MASQ for sim_modRM:
ggplot(ce_RM_MASQ, aes(x = MASQ, y = estimate__, color = neurotype)) +
  geom_point(data = data, aes(x = MASQ, y = RLLR, color = neurotype)) +
  geom_line(aes(y = estimate__),size = 1) +  # Line for estimated effects
  geom_ribbon(aes(ymin = lower__, ymax = upper__, fill = neurotype), alpha = 0.3, color = NA) +  # Ribbons for uncertainty
  theme_minimal() +  # Use a minimal theme
  labs(title = "Effect Of MASQ Scores On Relative Log Learning Rate By Neurotype",
       x = "MASQ",
       y = "Estimated Effect") +
  scale_color_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) +
  scale_fill_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) 

#Plot for MASQ for sim_modRME:
RMEplot_masq <- ggplot(ce_RME_MASQ, aes(x = MASQ, y = estimate__, color = neurotype)) +
  geom_point(data = data, aes(x = MASQ, y = RLLR, color = neurotype)) +
  geom_line(aes(y = estimate__),size = 1) +  # Line for estimated effects
  geom_ribbon(aes(ymin = lower__, ymax = upper__, fill = neurotype), alpha = 0.3, color = NA) +  # Ribbons for uncertainty
  theme_minimal() +  # Use a minimal theme
  labs(x = "MASQ",
       y = "Estimated Effect") +
  scale_color_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) +
  scale_fill_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) 

#Plot for EDAQ for sim_modRME:
RMEplot_edaq <- ggplot(ce_RME_EDAQ, aes(x = EDAQ, y = estimate__, color = neurotype)) +
  geom_point(data = data, aes(x = EDAQ, y = RLLR, color = neurotype)) +
  geom_line(aes(y = estimate__),size = 1) +  # Line for estimated effects
  geom_ribbon(aes(ymin = lower__, ymax = upper__, fill = neurotype), alpha = 0.3, color = NA) +  # Ribbons for uncertainty
  theme_minimal() +  # Use a minimal theme
  labs(x = "EDAQ",
       y = "") +
  scale_color_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) +
  scale_fill_manual(values = c("ASC" = "#cc99ff", "NT" = "#66cccc"), name = "Neurotype", breaks = c("NT", "ASC")) 

#Combine the plots:
(RMEplot_masq + RMEplot_edaq) + plot_annotation(title = "Effect Of MASQ And EDAQ Scores Relative Log Learning Rate By Neurotype")
```

Once again, the plots above plot regression lines for the model-predicted estimates (with HDI ribbons) over our simulated data. These plots show that RLLR produced by the ASC group do not vary as a function of anxiety (MASQ) and/or PDA (EDAQ), while for the NT group, the number of regressive behaviours are negatively associated with both anxiety (MASQ) and PDA (EDAQ). This reflects our assumptions that PDA and anxiety are associated with reduced change in learning rates (i.e., learning rates for stable and volatile conditions are similar), indicating reduced flexibility. These assumptions are based on literature that suggests both autism ((Crawley et al., 2020; D’Cruz et al., 2013) and anxiety (Browning et al., 2015) might be associated with aberrant probabilistic learning, and literature that suggests PDA is underpinned by anxiety (Johnson & Saunderson 2023; Stuart et al., 2020).

# Sensitivity analysis

"A sensitivity analysis explores how changes in assumptions influence inference. If none of the alternative assumptions you consider have much impact on inference, that's worth reporting. Likewise, if the alternatives you consider do have an important impact on inference, that's also worth reporting. The same sort of advice follows for other modeling assumptions: likelihoods, linear models, priors, and even how the model is fit to data" - McElreath (2020).

## Behaviour predicted by neurotype, PDA and anxiety

### Lose-shift behaviour

First, read in the data:

```{r}
#Read in saved data file:
sim_data <- read.csv("Sim_Data.csv")

#Prepare and standardise variables:
data <- sim_data %>%
  mutate(
    EDAQ = standardize(EDAQ),
    MASQ = standardize(MASQ),
    RLLR = standardize(RLLR),
    perseveration = standardize(perseveration),
    regression = standardize(regression),
    loseShift = standardize(loseShift)
  ) %>%
  select(id, EDAQ, MASQ, RLLR, loseShift, perseveration, regression, neurotype) %>%
  distinct()
```

We will begin with three models that consider different priors for $α$ , $β$, and $σ$ default (the prior we used in our model), narrow, and broad:

```{r}
#Fit the model with default priors:
sim_modLSM_default <- brm(
  loseShift ~ MASQ*neurotype,
  data = data,
  backend = "cmdstan",
  family = gaussian(),
  prior = c(
    prior(normal(0, 1), class = "Intercept"),
    prior(normal(0, 1), class = "b"),
    prior(exponential(1), class = "sigma")
  ),
  control = list(adapt_delta = 0.99),
  cores = 4,
  file = "sim_modLSM_default_output.rds"
  )
sim_modLSME_default <- brm(
  loseShift ~ MASQ*neurotype + EDAQ*neurotype,
  data = data,
  backend = "cmdstan",
  family = gaussian(),
  prior = c(
    prior(normal(0, 1), class = "Intercept"),
    prior(normal(0, 1), class = "b"),
    prior(exponential(1), class = "sigma")
  ),
  control = list(adapt_delta = 0.99),
  cores = 4,
  file = "sim_modLSME_default_output.rds"
  )

#Fit the model with narrow priors:
sim_modLSM_narrow <- brm(
  loseShift ~ MASQ*neurotype,
  data = data,
  backend = "cmdstan",
  family = gaussian(),
  prior = c(
    prior(normal(0, 0.2), class = "Intercept"),
    prior(normal(0, 0.2), class = "b"),
    prior(exponential(1), class = "sigma")
  ),
  control = list(adapt_delta = 0.99),
  cores = 4,
  file = "sim_modLSM_narrow_output.rds"
  )
sim_modLSME_narrow <- brm(
  loseShift ~ MASQ*neurotype + EDAQ*neurotype,
  data = data,
  backend = "cmdstan",
  family = gaussian(),
  prior = c(
    prior(normal(0, 0.2), class = "Intercept"),
    prior(normal(0, 0.2), class = "b"),
    prior(exponential(1), class = "sigma")
  ),
  control = list(adapt_delta = 0.99),
  cores = 4,
  file = "sim_modLSME_narrow_output.rds"
  )

#Fit the model with broad priors:
sim_modLSM_broad <- brm(
  loseShift ~ MASQ*neurotype,
  data = data,
  backend = "cmdstan",
  family = gaussian(),
  prior = c(
    prior(normal(0, 2), class = "Intercept"),
    prior(normal(0, 2), class = "b"),
    prior(exponential(1), class = "sigma")
  ),
  control = list(adapt_delta = 0.99),
  cores = 4,
  file = "sim_modLSM_broad_output.rds"
  )
sim_modLSME_broad <- brm(
  loseShift ~ MASQ*neurotype + EDAQ*neurotype,
  data = data,
  backend = "cmdstan",
  family = gaussian(),
  prior = c(
    prior(normal(0, 2), class = "Intercept"),
    prior(normal(0, 2), class = "b"),
    prior(exponential(1), class = "sigma")
  ),
  control = list(adapt_delta = 0.99),
  cores = 4,
  file = "sim_modLSME_broad_output.rds"
  )
```

We can visualise the output of the above models to compare the impact of differing prior assumptions for each parameter:

```{r}
#Load models output from files:
sim_modLSM_default <- readRDS("sim_modLSM_default_output.rds")
sim_modLSM_narrow <- readRDS("sim_modLSM_narrow_output.rds")
sim_modLSM_broad <- readRDS("sim_modLSM_broad_output.rds")
sim_modLSME_default <- readRDS("sim_modLSME_default_output.rds")
sim_modLSME_narrow <- readRDS("sim_modLSME_narrow_output.rds")
sim_modLSME_broad <- readRDS("sim_modLSME_broad_output.rds")

#Return model output:
modelsLSM <- list(sim_modLSM_default, sim_modLSM_narrow, sim_modLSM_broad)
modelsLSME <- list(sim_modLSME_default, sim_modLSME_narrow, sim_modLSME_broad)

#Iterate summary over the models:
for(i in 1:length(modelsLSM)) {
  # Print model summary
  print(summary(modelsLSM[[i]]))
}
for(i in 1:length(modelsLSME)) {
  # Print model summary
  print(summary(modelsLSME[[i]]))
}

#Put models in a list:
modelsLSM <- list(Default = sim_modLSM_default, Narrow = sim_modLSM_narrow, Broad = sim_modLSM_broad)
modelsLSME <- list(Default = sim_modLSME_default, Narrow = sim_modLSME_narrow, Broad = sim_modLSME_broad)

#Create a data frame to hold coefficients:
dfLSM <- data.frame(Model = character(), Parameters = character(), Estimate = numeric(), SE = numeric())
dfLSME <- data.frame(Model = character(), Parameters = character(), Estimate = numeric(), SE = numeric())

#Extract coefficients and add to data frame:
for (model_name in names(modelsLSM)) {
  coefsLSM <- fixef(modelsLSM[[model_name]])
  temp_dfLSM <- data.frame(Model = model_name, Parameters = rownames(coefsLSM), Estimate = coefsLSM[, 1], SE = coefsLSM[, 2])
  dfLSM <- rbind(dfLSM, temp_dfLSM)
}
for (model_name in names(modelsLSME)) {
  coefsLSME <- fixef(modelsLSME[[model_name]])
  temp_dfLSME <- data.frame(Model = model_name, Parameters = rownames(coefsLSME), Estimate = coefsLSME[, 1], SE = coefsLSME[, 2])
  dfLSME <- rbind(dfLSME, temp_dfLSME)
}

# Order coefficients by the order they appear in the first model, then reverse the order
dfLSM$Parameters <- factor(dfLSM$Parameters, levels = rev(rownames(fixef(modelsLSM[[1]]))))
dfLSME$Parameters <- factor(dfLSME$Parameters, levels = rev(rownames(fixef(modelsLSME[[1]]))))

#Plot using ggplot:
ggplot(dfLSM, aes(x = Estimate, y = Parameters, color = Model)) +
  geom_point() +
  geom_errorbarh(aes(xmin = Estimate - SE, xmax = Estimate + SE), height = 0.2) +
  labs(title = "Comparison of Coefficients Across Models", x = "Estimate", y = "Parameters") +
  scale_color_manual(values = c("Broad" = "#66cccc", "Default" = "#336666", "Narrow" = "#cc99ff")) +
  theme_minimal()
ggplot(dfLSME, aes(x = Estimate, y = Parameters, color = Model)) +
  geom_point() +
  geom_errorbarh(aes(xmin = Estimate - SE, xmax = Estimate + SE), height = 0.2) +
  labs(title = "Comparison of Coefficients Across Models", x = "Estimate", y = "Parameters") +
  scale_color_manual(values = c("Broad" = "#66cccc", "Default" = "#336666", "Narrow" = "#cc99ff")) +
  theme_minimal()
```

All six models show comparable estimates for each parameter; we can conclude that our default priors are acceptable to capture our expected range of parameter estimates.

### Perseverative behaviour

Repeat for model 2. First, read in the data:

```{r}
#Read in saved data file:
sim_data <- read.csv("Sim_Data.csv")

#Prepare and standardise variables:
data <- sim_data %>%
  mutate(
    EDAQ = standardize(EDAQ),
    MASQ = standardize(MASQ),
    RLLR = standardize(RLLR),
    perseveration = standardize(perseveration),
    regression = standardize(regression),
    loseShift = standardize(loseShift)
  ) %>%
  select(id, EDAQ, MASQ, RLLR, loseShift, perseveration, regression, neurotype) %>%
  distinct()
```

We will begin with three models that consider different priors for $α$ , $β$, and $σ$ default (the prior we used in our model), narrow, and broad:

```{r}
#Fit the model with default priors:
sim_modPM_default <- brm(
  perseveration ~ MASQ*neurotype,
  data = data,
  backend = "cmdstan",
  family = gaussian(),
  prior = c(
    prior(normal(0, 1), class = "Intercept"),
    prior(normal(0, 1), class = "b"),
    prior(exponential(1), class = "sigma")
  ),
  control = list(adapt_delta = 0.99),
  cores = 4,
  file = "sim_modPM_default_output.rds"
  )
sim_modPME_default <- brm(
  perseveration ~ MASQ*neurotype + EDAQ*neurotype,
  data = data,
  backend = "cmdstan",
  family = gaussian(),
  prior = c(
    prior(normal(0, 1), class = "Intercept"),
    prior(normal(0, 1), class = "b"),
    prior(exponential(1), class = "sigma")
  ),
  control = list(adapt_delta = 0.99),
  cores = 4,
  file = "sim_modPME_default_output.rds"
  )

#Fit the model with narrow priors:
sim_modPM_narrow <- brm(
  perseveration ~ MASQ*neurotype,
  data = data,
  backend = "cmdstan",
  family = gaussian(),
  prior = c(
    prior(normal(0, 0.2), class = "Intercept"),
    prior(normal(0, 0.2), class = "b"),
    prior(exponential(1), class = "sigma")
  ),
  control = list(adapt_delta = 0.99),
  cores = 4,
  file = "sim_modPM_narrow_output.rds"
  )
sim_modPME_narrow <- brm(
  perseveration ~ MASQ*neurotype + EDAQ*neurotype,
  data = data,
  backend = "cmdstan",
  family = gaussian(),
  prior = c(
    prior(normal(0, 0.2), class = "Intercept"),
    prior(normal(0, 0.2), class = "b"),
    prior(exponential(1), class = "sigma")
  ),
  control = list(adapt_delta = 0.99),
  cores = 4,
  file = "sim_modPME_narrow_output.rds"
  )

#Fit the model with broad priors:
sim_modPM_broad <- brm(
  perseveration ~ MASQ*neurotype,
  data = data,
  backend = "cmdstan",
  family = gaussian(),
  prior = c(
    prior(normal(0, 2), class = "Intercept"),
    prior(normal(0, 2), class = "b"),
    prior(exponential(1), class = "sigma")
  ),
  control = list(adapt_delta = 0.99),
  cores = 4,
  file = "sim_modPM_broad_output.rds"
  )
sim_modPME_broad <- brm(
  perseveration ~ MASQ*neurotype + EDAQ*neurotype,
  data = data,
  backend = "cmdstan",
  family = gaussian(),
  prior = c(
    prior(normal(0, 2), class = "Intercept"),
    prior(normal(0, 2), class = "b"),
    prior(exponential(1), class = "sigma")
  ),
  control = list(adapt_delta = 0.99),
  cores = 4,
  file = "sim_modPME_broad_output.rds"
  )
```

We can visualise the output of the above models to compare the impact of differing prior assumptions for each parameter:

```{r}
#Load models output from files:
sim_modPM_default <- readRDS("sim_modPM_default_output.rds")
sim_modPM_narrow <- readRDS("sim_modPM_narrow_output.rds")
sim_modPM_broad <- readRDS("sim_modPM_broad_output.rds")
sim_modPME_default <- readRDS("sim_modPME_default_output.rds")
sim_modPME_narrow <- readRDS("sim_modPME_narrow_output.rds")
sim_modPME_broad <- readRDS("sim_modPME_broad_output.rds")

#Return model output:
modelsPM <- list(sim_modPM_default, sim_modPM_narrow, sim_modPM_broad)
modelsPME <- list(sim_modPME_default, sim_modPME_narrow, sim_modPME_broad)

#Iterate summary over the models:
for(i in 1:length(modelsPM)) {
  # Print model summary
  print(summary(modelsPM[[i]]))
}
for(i in 1:length(modelsPME)) {
  # Print model summary
  print(summary(modelsPME[[i]]))
}

#Put models in a list:
modelsPM <- list(Default = sim_modPM_default, Narrow = sim_modPM_narrow, Broad = sim_modPM_broad)
modelsPME <- list(Default = sim_modPME_default, Narrow = sim_modPME_narrow, Broad = sim_modPME_broad)

#Create a data frame to hold coefficients:
dfPM <- data.frame(Model = character(), Parameters = character(), Estimate = numeric(), SE = numeric())
dfPME <- data.frame(Model = character(), Parameters = character(), Estimate = numeric(), SE = numeric())

#Extract coefficients and add to data frame:
for (model_name in names(modelsPM)) {
  coefsPM <- fixef(modelsPM[[model_name]])
  temp_dfPM <- data.frame(Model = model_name, Parameters = rownames(coefsPM), Estimate = coefsPM[, 1], SE = coefsPM[, 2])
  dfPM <- rbind(dfPM, temp_dfPM)
}
for (model_name in names(modelsPME)) {
  coefsPME <- fixef(modelsPME[[model_name]])
  temp_dfPME <- data.frame(Model = model_name, Parameters = rownames(coefsPME), Estimate = coefsPME[, 1], SE = coefsPME[, 2])
  dfPME <- rbind(dfPME, temp_dfPME)
}

# Order coefficients by the order they appear in the first model, then reverse the order
dfPM$Parameters <- factor(dfPM$Parameters, levels = rev(rownames(fixef(modelsPM[[1]]))))
dfPME$Parameters <- factor(dfPME$Parameters, levels = rev(rownames(fixef(modelsPME[[1]]))))

#Plot using ggplot:
ggplot(dfPM, aes(x = Estimate, y = Parameters, color = Model)) +
  geom_point() +
  geom_errorbarh(aes(xmin = Estimate - SE, xmax = Estimate + SE), height = 0.2) +
  labs(title = "Comparison of Coefficients Across Models", x = "Estimate", y = "Parameters") +
  scale_color_manual(values = c("Broad" = "#66cccc", "Default" = "#336666", "Narrow" = "#cc99ff")) +
  theme_minimal()
ggplot(dfPME, aes(x = Estimate, y = Parameters, color = Model)) +
  geom_point() +
  geom_errorbarh(aes(xmin = Estimate - SE, xmax = Estimate + SE), height = 0.2) +
  labs(title = "Comparison of Coefficients Across Models", x = "Estimate", y = "Parameters") +
  scale_color_manual(values = c("Broad" = "#66cccc", "Default" = "#336666", "Narrow" = "#cc99ff")) +
  theme_minimal()
```

All six models show comparable estimates for each parameter; we can conclude that our default priors are acceptable to capture our expected range of parameter estimates.

### Regressive behaviour

Read in the data:

```{r}
#Read in saved data file:
sim_data <- read.csv("Sim_Data.csv")

#Prepare and standardise variables:
data <- sim_data %>%
  mutate(
    EDAQ = standardize(EDAQ),
    MASQ = standardize(MASQ),
    RLLR = standardize(RLLR),
    perseveration = standardize(perseveration),
    regression = standardize(regression),
    loseShift = standardize(loseShift)
  ) %>%
  select(id, EDAQ, MASQ, RLLR, loseShift, perseveration, regression, neurotype) %>%
  distinct()
```

We will begin with three models that consider different priors for $α$ , $β$, and $σ$ default (the prior we used in our model), narrow, and broad:

```{r}
#Fit the model with default priors:
sim_modReM_default <- brm(
  regression ~ MASQ*neurotype,
  data = data,
  backend = "cmdstan",
  family = gaussian(),
  prior = c(
    prior(normal(0, 1), class = "Intercept"),
    prior(normal(0, 1), class = "b"),
    prior(exponential(1), class = "sigma")
  ),
  control = list(adapt_delta = 0.99),
  cores = 4,
  file = "sim_modReM_default_output.rds"
  )
sim_modReME_default <- brm(
  regression ~ MASQ*neurotype + EDAQ*neurotype,
  data = data,
  backend = "cmdstan",
  family = gaussian(),
  prior = c(
    prior(normal(0, 1), class = "Intercept"),
    prior(normal(0, 1), class = "b"),
    prior(exponential(1), class = "sigma")
  ),
  control = list(adapt_delta = 0.99),
  cores = 4,
  file = "sim_modReME_default_output.rds"
  )

#Fit the model with narrow priors:
sim_modReM_narrow <- brm(
  regression ~ MASQ*neurotype,
  data = data,
  backend = "cmdstan",
  family = gaussian(),
  prior = c(
    prior(normal(0, 0.2), class = "Intercept"),
    prior(normal(0, 0.2), class = "b"),
    prior(exponential(1), class = "sigma")
  ),
  control = list(adapt_delta = 0.99),
  cores = 4,
  file = "sim_modReM_narrow_output.rds"
  )
sim_modReME_narrow <- brm(
  regression ~ MASQ*neurotype + EDAQ*neurotype,
  data = data,
  backend = "cmdstan",
  family = gaussian(),
  prior = c(
    prior(normal(0, 0.2), class = "Intercept"),
    prior(normal(0, 0.2), class = "b"),
    prior(exponential(1), class = "sigma")
  ),
  control = list(adapt_delta = 0.99),
  cores = 4,
  file = "sim_modReME_narrow_output.rds"
  )

#Fit the model with broad priors:
sim_modReM_broad <- brm(
  regression ~ MASQ*neurotype,
  data = data,
  backend = "cmdstan",
  family = gaussian(),
  prior = c(
    prior(normal(0, 2), class = "Intercept"),
    prior(normal(0, 2), class = "b"),
    prior(exponential(1), class = "sigma")
  ),
  control = list(adapt_delta = 0.99),
  cores = 4,
  file = "sim_modReM_broad_output.rds"
  )
sim_modReME_broad <- brm(
  regression ~ MASQ*neurotype + EDAQ*neurotype,
  data = data,
  backend = "cmdstan",
  family = gaussian(),
  prior = c(
    prior(normal(0, 2), class = "Intercept"),
    prior(normal(0, 2), class = "b"),
    prior(exponential(1), class = "sigma")
  ),
  control = list(adapt_delta = 0.99),
  cores = 4,
  file = "sim_modReME_broad_output.rds"
  )
```

We can visualise the output of the above models to compare the impact of differing prior assumptions for each parameter:

```{r}
#Load models output from files:
sim_modReM_default <- readRDS("sim_modReM_default_output.rds")
sim_modReM_narrow <- readRDS("sim_modReM_narrow_output.rds")
sim_modReM_broad <- readRDS("sim_modReM_broad_output.rds")
sim_modReME_default <- readRDS("sim_modReME_default_output.rds")
sim_modReME_narrow <- readRDS("sim_modReME_narrow_output.rds")
sim_modReME_broad <- readRDS("sim_modReME_broad_output.rds")

#Return model output:
modelsReM <- list(sim_modReM_default, sim_modReM_narrow, sim_modReM_broad)
modelsReME <- list(sim_modReME_default, sim_modReME_narrow, sim_modReME_broad)

#Iterate summary over the models:
for(i in 1:length(modelsReM)) {
  # Print model summary
  print(summary(modelsReM[[i]]))
}
for(i in 1:length(modelsReME)) {
  # Print model summary
  print(summary(modelsReME[[i]]))
}

#Put models in a list:
modelsReM <- list(Default = sim_modReM_default, Narrow = sim_modReM_narrow, Broad = sim_modReM_broad)
modelsReME <- list(Default = sim_modReME_default, Narrow = sim_modReME_narrow, Broad = sim_modReME_broad)

#Create a data frame to hold coefficients:
dfReM <- data.frame(Model = character(), Parameters = character(), Estimate = numeric(), SE = numeric())
dfReME <- data.frame(Model = character(), Parameters = character(), Estimate = numeric(), SE = numeric())

#Extract coefficients and add to data frame:
for (model_name in names(modelsReM)) {
  coefsReM <- fixef(modelsReM[[model_name]])
  temp_dfReM <- data.frame(Model = model_name, Parameters = rownames(coefsReM), Estimate = coefsReM[, 1], SE = coefsReM[, 2])
  dfReM <- rbind(dfReM, temp_dfReM)
}
for (model_name in names(modelsReME)) {
  coefsReME <- fixef(modelsReME[[model_name]])
  temp_dfReME <- data.frame(Model = model_name, Parameters = rownames(coefsReME), Estimate = coefsReME[, 1], SE = coefsReME[, 2])
  dfReME <- rbind(dfReME, temp_dfReME)
}

# Order coefficients by the order they appear in the first model, then reverse the order
dfReM$Parameters <- factor(dfReM$Parameters, levels = rev(rownames(fixef(modelsReM[[1]]))))
dfReME$Parameters <- factor(dfReME$Parameters, levels = rev(rownames(fixef(modelsReME[[1]]))))

#Plot using ggplot:
ggplot(dfReM, aes(x = Estimate, y = Parameters, color = Model)) +
  geom_point() +
  geom_errorbarh(aes(xmin = Estimate - SE, xmax = Estimate + SE), height = 0.2) +
  labs(title = "Comparison of Coefficients Across Models", x = "Estimate", y = "Parameters") +
  scale_color_manual(values = c("Broad" = "#66cccc", "Default" = "#336666", "Narrow" = "#cc99ff")) +
  theme_minimal()
ggplot(dfReME, aes(x = Estimate, y = Parameters, color = Model)) +
  geom_point() +
  geom_errorbarh(aes(xmin = Estimate - SE, xmax = Estimate + SE), height = 0.2) +
  labs(title = "Comparison of Coefficients Across Models", x = "Estimate", y = "Parameters") +
  scale_color_manual(values = c("Broad" = "#66cccc", "Default" = "#336666", "Narrow" = "#cc99ff")) +
  theme_minimal()
```

All six models show comparable estimates for each parameter; we can conclude that our default priors are acceptable to capture our expected range of parameter estimates.

## Learning rate predicted by neurotype, PDA and anxiety

### Effect of block order on RLLR

Read in the data:

```{r}
#Read in saved data file:
sim_data <- read.csv("Sim_Data.csv")

#Prepare and standardise variables:
data <- sim_data %>%
  mutate(
    EDAQ = standardize(EDAQ),
    MASQ = standardize(MASQ),
    RLLR = standardize(RLLR),
    perseveration = standardize(perseveration),
    regression = standardize(regression),
    loseShift = standardize(loseShift)
  ) %>%
  select(id, EDAQ, MASQ, RLLR, loseShift, perseveration, regression, neurotype, blockorder) %>%
  distinct()
```

We will begin with three models that consider different priors for $α$ , $β$, and $σ$ default (the prior we used in our model), narrow, and broad:

```{r}
#Fit the model with default priors:
sim_modRB_default <- brm(
  RLLR ~ blockorder:neurotype,
  data = data,
  backend = "cmdstan",
  family = gaussian(),
  prior = c(
    prior(normal(0, 1), class = "Intercept"),
    prior(normal(0, 1), class = "b"),
    prior(exponential(1), class = "sigma")
  ),
  control = list(adapt_delta = 0.99),
  cores = 4,
  file = "sim_modRB_default_output.rds"
  )

#Fit the model with narrow priors:
sim_modRB_narrow <- brm(
  RLLR ~ blockorder:neurotype,
  data = data,
  backend = "cmdstan",
  family = gaussian(),
  prior = c(
    prior(normal(0, 0.2), class = "Intercept"),
    prior(normal(0, 0.2), class = "b"),
    prior(exponential(1), class = "sigma")
  ),
  control = list(adapt_delta = 0.99),
  cores = 4,
  file = "sim_modRB_narrow_output.rds"
  )

#Fit the model with broad priors:
sim_modRB_broad <- brm(
  RLLR ~ blockorder:neurotype,
  data = data,
  backend = "cmdstan",
  family = gaussian(),
  prior = c(
    prior(normal(0, 2), class = "Intercept"),
    prior(normal(0, 2), class = "b"),
    prior(exponential(1), class = "sigma")
  ),
  control = list(adapt_delta = 0.99),
  cores = 4,
  file = "sim_modRB_broad_output.rds"
  )
```

We can visualise the output of the above models to compare the impact of differing prior assumptions for each parameter:

```{r}
#Load models output from files:
sim_modRB_default <- readRDS("sim_modRB_default_output.rds")
sim_modRB_narrow <- readRDS("sim_modRB_narrow_output.rds")
sim_modRB_broad <- readRDS("sim_modRB_broad_output.rds")

#Return model output:
modelsRB <- list(sim_modRB_default, sim_modRB_narrow, sim_modRB_broad)

#Iterate summary over the models:
for(i in 1:length(modelsRB)) {
  # Print model summary
  print(summary(modelsRB[[i]]))
}

#Put models in a list:
modelsRB <- list(Default = sim_modRB_default, Narrow = sim_modRB_narrow, Broad = sim_modRB_broad)

#Create a data frame to hold coefficients:
dfRB <- data.frame(Model = character(), Parameters = character(), Estimate = numeric(), SE = numeric())

#Extract coefficients and add to data frame:
for (model_name in names(modelsRB)) {
  coefsRB <- fixef(modelsRB[[model_name]])
  temp_dfRB <- data.frame(Model = model_name, Parameters = rownames(coefsRB), Estimate = coefsRB[, 1], SE = coefsRB[, 2])
  dfRB <- rbind(dfRB, temp_dfRB)
}

# Order coefficients by the order they appear in the first model, then reverse the order
dfRB$Parameters <- factor(dfRB$Parameters, levels = rev(rownames(fixef(modelsRB[[1]]))))

#Plot using ggplot:
ggplot(dfRB, aes(x = Estimate, y = Parameters, color = Model)) +
  geom_point() +
  geom_errorbarh(aes(xmin = Estimate - SE, xmax = Estimate + SE), height = 0.2) +
  labs(title = "Comparison of Coefficients Across Models", x = "Estimate", y = "Parameters") +
  scale_color_manual(values = c("Broad" = "#66cccc", "Default" = "#336666", "Narrow" = "#cc99ff")) +
  theme_minimal()
```

All three models show comparable estimates for each parameter; we can conclude that our default priors are acceptable to capture our expected range of parameter estimates.

### Effect of EDA-QA and MASQ on RLLR

Read in the data:

```{r}
#Read in saved data file:
sim_data <- read.csv("Sim_Data.csv")

#Prepare and standardise variables:
data <- sim_data %>%
  mutate(
    EDAQ = standardize(EDAQ),
    MASQ = standardize(MASQ),
    RLLR = standardize(RLLR),
    perseveration = standardize(perseveration),
    regression = standardize(regression),
    loseShift = standardize(loseShift)
  ) %>%
  select(id, EDAQ, MASQ, RLLR, loseShift, perseveration, regression, neurotype) %>%
  distinct()
```

We will begin with three models that consider different priors for $α$ , $β$, and $σ$ default (the prior we used in our model), narrow, and broad:

```{r}
#Fit the model with default priors:
sim_modRM_default <- brm(
  RLLR ~ MASQ*neurotype,
  data = data,
  backend = "cmdstan",
  family = gaussian(),
  prior = c(
    prior(normal(0, 1), class = "Intercept"),
    prior(normal(0, 1), class = "b"),
    prior(exponential(1), class = "sigma")
  ),
  control = list(adapt_delta = 0.99),
  cores = 4,
  file = "sim_modRM_default_output.rds"
  )
sim_modRME_default <- brm(
  RLLR ~ MASQ*neurotype + EDAQ*neurotype,
  data = data,
  backend = "cmdstan",
  family = gaussian(),
  prior = c(
    prior(normal(0, 1), class = "Intercept"),
    prior(normal(0, 1), class = "b"),
    prior(exponential(1), class = "sigma")
  ),
  control = list(adapt_delta = 0.99),
  cores = 4,
  file = "sim_modRME_default_output.rds"
  )

#Fit the model with narrow priors:
sim_modRM_narrow <- brm(
  RLLR ~ MASQ*neurotype,
  data = data,
  backend = "cmdstan",
  family = gaussian(),
  prior = c(
    prior(normal(0, 0.2), class = "Intercept"),
    prior(normal(0, 0.2), class = "b"),
    prior(exponential(1), class = "sigma")
  ),
  control = list(adapt_delta = 0.99),
  cores = 4,
  file = "sim_modRM_narrow_output.rds"
  )
sim_modRME_narrow <- brm(
  RLLR ~ MASQ*neurotype + EDAQ*neurotype,
  data = data,
  backend = "cmdstan",
  family = gaussian(),
  prior = c(
    prior(normal(0, 0.2), class = "Intercept"),
    prior(normal(0, 0.2), class = "b"),
    prior(exponential(1), class = "sigma")
  ),
  control = list(adapt_delta = 0.99),
  cores = 4,
  file = "sim_modRME_narrow_output.rds"
  )

#Fit the model with broad priors:
sim_modRM_broad <- brm(
  RLLR ~ MASQ*neurotype,
  data = data,
  backend = "cmdstan",
  family = gaussian(),
  prior = c(
    prior(normal(0, 2), class = "Intercept"),
    prior(normal(0, 2), class = "b"),
    prior(exponential(1), class = "sigma")
  ),
  control = list(adapt_delta = 0.99),
  cores = 4,
  file = "sim_modRM_broad_output.rds"
  )
sim_modRME_broad <- brm(
  RLLR ~ MASQ*neurotype + EDAQ*neurotype,
  data = data,
  backend = "cmdstan",
  family = gaussian(),
  prior = c(
    prior(normal(0, 2), class = "Intercept"),
    prior(normal(0, 2), class = "b"),
    prior(exponential(1), class = "sigma")
  ),
  control = list(adapt_delta = 0.99),
  cores = 4,
  file = "sim_modRME_broad_output.rds"
  )
```

We can visualise the output of the above models to compare the impact of differing prior assumptions for each parameter:

```{r}
#Load models output from files:
sim_modRM_default <- readRDS("sim_modRM_default_output.rds")
sim_modRM_narrow <- readRDS("sim_modRM_narrow_output.rds")
sim_modRM_broad <- readRDS("sim_modRM_broad_output.rds")
sim_modRME_default <- readRDS("sim_modRME_default_output.rds")
sim_modRME_narrow <- readRDS("sim_modRME_narrow_output.rds")
sim_modRME_broad <- readRDS("sim_modRME_broad_output.rds")

#Return model output:
modelsRM <- list(sim_modRM_default, sim_modRM_narrow, sim_modRM_broad)
modelsRME <- list(sim_modRME_default, sim_modRME_narrow, sim_modRME_broad)

#Iterate summary over the models:
for(i in 1:length(modelsRM)) {
  # Print model summary
  print(summary(modelsRM[[i]]))
}
for(i in 1:length(modelsRME)) {
  # Print model summary
  print(summary(modelsRME[[i]]))
}

#Put models in a list:
modelsRM <- list(Default = sim_modRM_default, Narrow = sim_modRM_narrow, Broad = sim_modRM_broad)
modelsRME <- list(Default = sim_modRME_default, Narrow = sim_modRME_narrow, Broad = sim_modRME_broad)

#Create a data frame to hold coefficients:
dfRM <- data.frame(Model = character(), Parameters = character(), Estimate = numeric(), SE = numeric())
dfRME <- data.frame(Model = character(), Parameters = character(), Estimate = numeric(), SE = numeric())

#Extract coefficients and add to data frame:
for (model_name in names(modelsRM)) {
  coefsRM <- fixef(modelsRM[[model_name]])
  temp_dfRM <- data.frame(Model = model_name, Parameters = rownames(coefsRM), Estimate = coefsRM[, 1], SE = coefsRM[, 2])
  dfRM <- rbind(dfRM, temp_dfRM)
}
for (model_name in names(modelsRME)) {
  coefsRME <- fixef(modelsRME[[model_name]])
  temp_dfRME <- data.frame(Model = model_name, Parameters = rownames(coefsRME), Estimate = coefsRME[, 1], SE = coefsRME[, 2])
  dfRME <- rbind(dfRME, temp_dfRME)
}

# Order coefficients by the order they appear in the first model, then reverse the order
dfRM$Parameters <- factor(dfRM$Parameters, levels = rev(rownames(fixef(modelsRM[[1]]))))
dfRME$Parameters <- factor(dfRME$Parameters, levels = rev(rownames(fixef(modelsRME[[1]]))))

#Plot using ggplot:
ggplot(dfRM, aes(x = Estimate, y = Parameters, color = Model)) +
  geom_point() +
  geom_errorbarh(aes(xmin = Estimate - SE, xmax = Estimate + SE), height = 0.2) +
  labs(title = "Comparison of Coefficients Across Models", x = "Estimate", y = "Parameters") +
  scale_color_manual(values = c("Broad" = "#66cccc", "Default" = "#336666", "Narrow" = "#cc99ff")) +
  theme_minimal()
ggplot(dfRME, aes(x = Estimate, y = Parameters, color = Model)) +
  geom_point() +
  geom_errorbarh(aes(xmin = Estimate - SE, xmax = Estimate + SE), height = 0.2) +
  labs(title = "Comparison of Coefficients Across Models", x = "Estimate", y = "Parameters") +
  scale_color_manual(values = c("Broad" = "#66cccc", "Default" = "#336666", "Narrow" = "#cc99ff")) +
  theme_minimal()
```

All six models show comparable estimates for each parameter; we can conclude that our default priors are acceptable to capture our expected range of parameter estimates.
